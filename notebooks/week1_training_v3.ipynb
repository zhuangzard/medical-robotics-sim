{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Robotics - Week 1 Training\n",
    "\n",
    "**Project**: Medical Robotics Simulation  \n",
    "**Target**: ICRA 2027 / CoRL 2026  \n",
    "**Task**: 2-DOF Robot Arm Box Pushing\n",
    "\n",
    "## Methods Compared\n",
    "1. **Pure PPO** - Standard RL (200K timesteps)\n",
    "2. **GNS** - Graph networks (80K timesteps)\n",
    "3. **PhysRobot** - Physics-informed (16K timesteps) \u2190 12.5x more efficient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!pip install mujoco gymnasium stable-baselines3[extra] torch torch-geometric tensorboard matplotlib -q\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "SAVE_DIR = '/content/drive/MyDrive/medical-robotics-sim'\n",
    "for d in ['models', 'results', 'logs']:\n",
    "    os.makedirs(f'{SAVE_DIR}/{d}', exist_ok=True)\n",
    "print(f\"Save dir: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PushBoxEnv - 16-dim observation, fully self-contained\n",
    "import numpy as np\n",
    "import mujoco\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import os, tempfile\n",
    "\n",
    "PUSH_BOX_XML = \"\"\"<mujoco model=\"push_box\">\n",
    "  <compiler angle=\"degree\" coordinate=\"local\" inertiafromgeom=\"true\"/>\n",
    "  <option timestep=\"0.002\" integrator=\"Euler\" gravity=\"0 0 -9.81\"><flag warmstart=\"enable\"/></option>\n",
    "  <asset>\n",
    "    <texture builtin=\"checker\" height=\"100\" name=\"texplane\" rgb1=\"0.2 0.2 0.2\" rgb2=\"0.3 0.3 0.3\" type=\"2d\" width=\"100\"/>\n",
    "    <material name=\"MatPlane\" reflectance=\"0.3\" shininess=\"0.5\" specular=\"0.5\" texrepeat=\"3 3\" texture=\"texplane\"/>\n",
    "  </asset>\n",
    "  <default>\n",
    "    <joint armature=\"0.01\" damping=\"0.1\" limited=\"true\"/>\n",
    "    <geom conaffinity=\"1\" condim=\"3\" contype=\"1\" friction=\"0.3 0.005 0.0001\" margin=\"0.001\" rgba=\"0.8 0.6 0.4 1\"/>\n",
    "  </default>\n",
    "  <worldbody>\n",
    "    <light directional=\"true\" diffuse=\"0.8 0.8 0.8\" pos=\"0 0 3\" dir=\"0 0 -1\"/>\n",
    "    <geom name=\"floor\" type=\"plane\" size=\"3 3 0.1\" rgba=\"0.8 0.8 0.8 1\" material=\"MatPlane\"/>\n",
    "    <body name=\"arm_base\" pos=\"0 0 0.5\">\n",
    "      <geom name=\"base_geom\" type=\"cylinder\" size=\"0.05 0.02\" rgba=\"0.3 0.3 0.3 1\"/>\n",
    "      <body name=\"upper_arm\" pos=\"0 0 0.02\">\n",
    "        <joint name=\"shoulder\" type=\"hinge\" axis=\"0 0 1\" range=\"-180 180\" damping=\"0.5\"/>\n",
    "        <geom name=\"upper_arm_geom\" type=\"capsule\" fromto=\"0 0 0 0.3 0 0\" size=\"0.025\" rgba=\"0.5 0.5 0.8 1\"/>\n",
    "        <body name=\"forearm\" pos=\"0.3 0 0\">\n",
    "          <joint name=\"elbow\" type=\"hinge\" axis=\"0 0 1\" range=\"-180 180\" damping=\"0.5\"/>\n",
    "          <geom name=\"forearm_geom\" type=\"capsule\" fromto=\"0 0 0 0.3 0 0\" size=\"0.025\" rgba=\"0.5 0.5 0.8 1\"/>\n",
    "          <site name=\"endeffector\" pos=\"0.3 0 0\" size=\"0.02\" rgba=\"1 0.5 0 0.8\"/>\n",
    "        </body>\n",
    "      </body>\n",
    "    </body>\n",
    "    <body name=\"box\" pos=\"0.5 0 0.05\">\n",
    "      <freejoint name=\"box_freejoint\"/>\n",
    "      <geom name=\"box_geom\" type=\"box\" size=\"0.05 0.05 0.05\" mass=\"1.0\" rgba=\"0.2 0.8 0.2 1\" friction=\"0.3 0.005 0.0001\"/>\n",
    "    </body>\n",
    "    <site name=\"goal\" pos=\"1.0 0.5 0.05\" size=\"0.06\" rgba=\"1 0 0 0.4\" type=\"sphere\"/>\n",
    "  </worldbody>\n",
    "  <actuator>\n",
    "    <motor name=\"shoulder_motor\" joint=\"shoulder\" gear=\"1.0\" ctrllimited=\"true\" ctrlrange=\"-10 10\"/>\n",
    "    <motor name=\"elbow_motor\" joint=\"elbow\" gear=\"1.0\" ctrllimited=\"true\" ctrlrange=\"-10 10\"/>\n",
    "  </actuator>\n",
    "</mujoco>\"\"\"\n",
    "\n",
    "XML_PATH = '/tmp/push_box.xml'\n",
    "with open(XML_PATH, 'w') as f:\n",
    "    f.write(PUSH_BOX_XML)\n",
    "\n",
    "class PushBoxEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 50}\n",
    "    def __init__(self, render_mode=None, box_mass=1.0):\n",
    "        super().__init__()\n",
    "        self.model = mujoco.MjModel.from_xml_path(XML_PATH)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        self.box_mass = box_mass\n",
    "        self._set_box_mass(box_mass)\n",
    "        self.action_space = spaces.Box(low=-10.0, high=10.0, shape=(2,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(16,), dtype=np.float32)\n",
    "        self.goal_pos = np.array([1.0, 0.5, 0.05])\n",
    "        self.max_episode_steps = 500\n",
    "        self.current_step = 0\n",
    "        self.success_threshold = 0.1\n",
    "        self.render_mode = render_mode\n",
    "    def _set_box_mass(self, mass):\n",
    "        bid = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_BODY, \"box\")\n",
    "        if bid >= 0: self.model.body_mass[bid] = mass\n",
    "    def set_box_mass(self, mass):\n",
    "        self.box_mass = mass; self._set_box_mass(mass)\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        mujoco.mj_resetData(self.model, self.data)\n",
    "        self.data.qpos[0] = np.random.uniform(-0.5, 0.5)\n",
    "        self.data.qpos[1] = np.random.uniform(-0.5, 0.5)\n",
    "        self.data.qpos[2] = np.random.uniform(0.4, 0.6)\n",
    "        self.data.qpos[3] = np.random.uniform(-0.2, 0.2)\n",
    "        self.data.qpos[4] = 0.05\n",
    "        self.data.qpos[5:9] = [1, 0, 0, 0]\n",
    "        self.data.qvel[:] = 0.0\n",
    "        mujoco.mj_forward(self.model, self.data)\n",
    "        self.current_step = 0\n",
    "        return self._get_obs(), self._get_info()\n",
    "    def _get_obs(self):\n",
    "        jp = self.data.qpos[:2].copy()\n",
    "        jv = self.data.qvel[:2].copy()\n",
    "        sid = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE, \"endeffector\")\n",
    "        ee = self.data.site_xpos[sid].copy()\n",
    "        bp = self.data.qpos[2:5].copy()\n",
    "        bv = self.data.qvel[2:5].copy()\n",
    "        return np.concatenate([jp, jv, ee, bp, bv, self.goal_pos]).astype(np.float32)\n",
    "    def _get_info(self):\n",
    "        bp = self.data.qpos[2:5]\n",
    "        d = np.linalg.norm(bp[:2] - self.goal_pos[:2])\n",
    "        return {'distance_to_goal': d, 'success': d < self.success_threshold, 'box_mass': self.box_mass}\n",
    "    def step(self, action):\n",
    "        self.data.ctrl[:] = action\n",
    "        mujoco.mj_step(self.model, self.data)\n",
    "        obs = self._get_obs()\n",
    "        bp = self.data.qpos[2:5]\n",
    "        d = np.linalg.norm(bp[:2] - self.goal_pos[:2])\n",
    "        reward = -d + (100.0 if d < self.success_threshold else 0.0)\n",
    "        self.current_step += 1\n",
    "        return obs, reward, d < self.success_threshold, self.current_step >= self.max_episode_steps, self._get_info()\n",
    "    def render(self): pass\n",
    "    def close(self): pass\n",
    "\n",
    "def make_push_box_env(box_mass=1.0):\n",
    "    def _init(): return PushBoxEnv(box_mass=box_mass)\n",
    "    return _init\n",
    "\n",
    "print(\"PushBoxEnv defined (16-dim obs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PushBoxEnv()\n",
    "obs, info = env.reset()\n",
    "print(f\"Obs shape: {obs.shape}, should be (16,)\")\n",
    "for _ in range(10):\n",
    "    obs, r, term, trunc, info = env.step(env.action_space.sample())\n",
    "print(f\"Reward: {r:.4f}, Dist: {info['distance_to_goal']:.4f}\")\n",
    "env.close()\n",
    "print(\"Environment works!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "try:\n",
    "    from torch_geometric.nn import MessagePassing\n",
    "    from torch_geometric.data import Data, Batch\n",
    "    HAS_PYG = True\n",
    "except ImportError:\n",
    "    HAS_PYG = False\n",
    "    print(\"torch_geometric not available, using simplified models\")\n",
    "\n",
    "class TrainingCallback(BaseCallback):\n",
    "    def __init__(self, name=\"\", eval_env_fn=None, eval_freq=10000, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.name, self.eval_env_fn, self.eval_freq = name, eval_env_fn, eval_freq\n",
    "        self.episode_count, self.first_success_ep, self.eval_history = 0, None, []\n",
    "    def _on_step(self):\n",
    "        for i, done in enumerate(self.locals.get('dones', [False])):\n",
    "            if done:\n",
    "                self.episode_count += 1\n",
    "                info = self.locals.get('infos', [{}])[min(i, len(self.locals.get('infos',[{}]))-1)]\n",
    "                if info.get('success') and self.first_success_ep is None:\n",
    "                    self.first_success_ep = self.episode_count\n",
    "                    print(f\"\\n[{self.name}] First success at ep {self.episode_count}!\")\n",
    "        if self.n_calls % self.eval_freq == 0 and self.eval_env_fn:\n",
    "            sr = self._eval()\n",
    "            self.eval_history.append({'step': self.n_calls, 'sr': sr})\n",
    "            print(f\"  [{self.name}] Step {self.n_calls}: SR={sr:.0%}\")\n",
    "        return True\n",
    "    def _eval(self, n=20):\n",
    "        env = DummyVecEnv([self.eval_env_fn]); s = 0\n",
    "        for _ in range(n):\n",
    "            obs = env.reset(); done = False\n",
    "            while not done:\n",
    "                a, _ = self.model.predict(obs, deterministic=True)\n",
    "                obs, _, dones, infos = env.step(a); done = dones[0]\n",
    "            if infos[0].get('success'): s += 1\n",
    "        env.close(); return s/n\n",
    "\n",
    "class PurePPOAgent:\n",
    "    def __init__(self, env, lr=3e-4, v=0):\n",
    "        self.model = PPO(\"MlpPolicy\", env, learning_rate=lr, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, verbose=v)\n",
    "    def train(self, steps, cb=None): self.model.learn(total_timesteps=steps, callback=cb, progress_bar=True)\n",
    "    def save(self, p): self.model.save(p)\n",
    "\n",
    "if HAS_PYG:\n",
    "    class GNL(MessagePassing):\n",
    "        def __init__(self, nd, ed, h=128):\n",
    "            super().__init__(aggr='add')\n",
    "            self.em = nn.Sequential(nn.Linear(2*nd+ed, h), nn.ReLU(), nn.Linear(h, ed))\n",
    "            self.nm = nn.Sequential(nn.Linear(nd+ed, h), nn.ReLU(), nn.Linear(h, nd))\n",
    "        def forward(self, x, ei, ea): return self.propagate(ei, x=x, edge_attr=ea)\n",
    "        def message(self, x_i, x_j, edge_attr): return self.em(torch.cat([x_i, x_j, edge_attr], -1))\n",
    "        def update(self, a, x): return self.nm(torch.cat([x, a], -1))\n",
    "\n",
    "    class GNSFeat(BaseFeaturesExtractor):\n",
    "        def __init__(self, obs_space, fd=128):\n",
    "            super().__init__(obs_space, fd)\n",
    "            self.ne = nn.Sequential(nn.Linear(6,128), nn.ReLU(), nn.Linear(128,128))\n",
    "            self.ee = nn.Sequential(nn.Linear(4,128), nn.ReLU(), nn.Linear(128,128))\n",
    "            self.gn = GNL(128,128); self.dec = nn.Sequential(nn.Linear(128,64), nn.ReLU(), nn.Linear(64,3))\n",
    "            self.proj = nn.Sequential(nn.Linear(3+16, fd), nn.ReLU())\n",
    "        def forward(self, obs):\n",
    "            gs = []\n",
    "            for i in range(obs.shape[0]):\n",
    "                o = obs[i]; ep, bp, bv = o[4:7], o[7:10], o[10:13]\n",
    "                x = torch.stack([torch.cat([torch.zeros(3,device=obs.device),ep]), torch.cat([bv,bp])])\n",
    "                ei = torch.tensor([[0],[1]], dtype=torch.long, device=obs.device)\n",
    "                rp = bp-ep; ea = torch.cat([rp, torch.norm(rp).unsqueeze(0)]).unsqueeze(0)\n",
    "                gs.append(Data(x=x, edge_index=ei, edge_attr=ea))\n",
    "            b = Batch.from_data_list(gs); h = self.ne(b.x); ea = self.ee(b.edge_attr)\n",
    "            h = h + self.gn(h, b.edge_index, ea); acc = self.dec(h)\n",
    "            return self.proj(torch.cat([acc[1::2], obs], -1))\n",
    "\n",
    "    class DynCAL(MessagePassing):\n",
    "        def __init__(self, nd, h=128):\n",
    "            super().__init__(aggr='add')\n",
    "            self.sm = nn.Sequential(nn.Linear(2*nd+3, h), nn.ReLU(), nn.Linear(h, 1))\n",
    "            self.vm = nn.Sequential(nn.Linear(2*nd+3, h), nn.ReLU(), nn.Linear(h, 2))\n",
    "            self.nu = nn.Sequential(nn.Linear(nd+3, h), nn.ReLU(), nn.Linear(h, nd))\n",
    "        def forward(self, x, ei, pos):\n",
    "            r, c = ei; pi, pj = pos[r], pos[c]; rel = pj-pi\n",
    "            inp = torch.cat([x[r], x[c], rel], -1)\n",
    "            fs, fv = self.sm(inp), self.vm(inp)\n",
    "            d = torch.norm(rel, dim=-1, keepdim=True)+1e-6; e1 = rel/d\n",
    "            up = torch.tensor([0.,0.,1.], device=e1.device).unsqueeze(0).expand_as(e1)\n",
    "            e2 = torch.cross(e1,up); e2 = e2/(torch.norm(e2,-1,True)+1e-6); e3 = torch.cross(e1,e2)\n",
    "            force = fs*e1 + fv[:,0:1]*e2 + fv[:,1:2]*e3\n",
    "            return self.propagate(ei, force=force, x=x)\n",
    "        def message(self, force): return force\n",
    "        def update(self, a, x): return self.nu(torch.cat([x, a], -1))\n",
    "\n",
    "    class PRFeat(BaseFeaturesExtractor):\n",
    "        def __init__(self, obs_space, fd=128):\n",
    "            super().__init__(obs_space, fd)\n",
    "            self.enc = nn.Sequential(nn.Linear(6,128), nn.ReLU(), nn.Linear(128,128))\n",
    "            self.lyrs = nn.ModuleList([DynCAL(128) for _ in range(3)])\n",
    "            self.dec = nn.Sequential(nn.Linear(128,64), nn.ReLU(), nn.Linear(64,3))\n",
    "            self.pol = nn.Sequential(nn.Linear(obs_space.shape[0],128), nn.ReLU(), nn.Linear(128,fd))\n",
    "            self.fuse = nn.Sequential(nn.Linear(fd+3, fd), nn.ReLU())\n",
    "        def forward(self, obs):\n",
    "            pf = self.pol(obs); gs = []\n",
    "            for i in range(obs.shape[0]):\n",
    "                o = obs[i]; ep, bp, bv = o[4:7], o[7:10], o[10:13]\n",
    "                ps = torch.stack([ep, bp])\n",
    "                nf = torch.stack([torch.cat([torch.zeros(3,device=obs.device),ep]), torch.cat([bv,bp])])\n",
    "                ei = torch.tensor([[0,1],[1,0]], dtype=torch.long, device=obs.device)\n",
    "                gs.append(Data(x=nf, pos=ps, edge_index=ei))\n",
    "            b = Batch.from_data_list(gs); h = self.enc(b.x)\n",
    "            for l in self.lyrs: h = h + l(h, b.edge_index, b.pos)\n",
    "            return self.fuse(torch.cat([pf, self.dec(h)[1::2]], -1))\n",
    "else:\n",
    "    class GNSFeat(BaseFeaturesExtractor):\n",
    "        def __init__(self, os, fd=128):\n",
    "            super().__init__(os, fd)\n",
    "            self.n = nn.Sequential(nn.Linear(os.shape[0],256), nn.ReLU(), nn.Linear(256,fd))\n",
    "        def forward(self, o): return self.n(o)\n",
    "    PRFeat = GNSFeat\n",
    "\n",
    "class GNSAgent:\n",
    "    def __init__(self, env, lr=3e-4, v=0):\n",
    "        pk = dict(features_extractor_class=GNSFeat, features_extractor_kwargs=dict(features_dim=128))\n",
    "        self.model = PPO(\"MlpPolicy\", env, learning_rate=lr, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, policy_kwargs=pk, verbose=v)\n",
    "    def train(self, steps, cb=None): self.model.learn(total_timesteps=steps, callback=cb, progress_bar=True)\n",
    "    def save(self, p): self.model.save(p)\n",
    "\n",
    "class PhysRobotAgent:\n",
    "    def __init__(self, env, lr=3e-4, v=0):\n",
    "        pk = dict(features_extractor_class=PRFeat, features_extractor_kwargs=dict(features_dim=128))\n",
    "        self.model = PPO(\"MlpPolicy\", env, learning_rate=lr, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, policy_kwargs=pk, verbose=v)\n",
    "    def train(self, steps, cb=None): self.model.learn(total_timesteps=steps, callback=cb, progress_bar=True)\n",
    "    def save(self, p): self.model.save(p)\n",
    "\n",
    "print(f\"All agents defined (PyG: {HAS_PYG})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json, traceback\n",
    "results = {}; agents_trained = {}\n",
    "env_fn = make_push_box_env(1.0)\n",
    "\n",
    "def eval_agent(agent, n=100):\n",
    "    env = DummyVecEnv([make_push_box_env(1.0)]); rews, succ = [], 0\n",
    "    for _ in range(n):\n",
    "        obs = env.reset(); done = False; er = 0\n",
    "        while not done:\n",
    "            a, _ = agent.model.predict(obs, deterministic=True)\n",
    "            obs, r, dones, infos = env.step(a); er += r[0]; done = dones[0]\n",
    "        rews.append(er)\n",
    "        if infos[0].get('success'): succ += 1\n",
    "    env.close()\n",
    "    return {'mean_reward': float(np.mean(rews)), 'success_rate': succ/n}\n",
    "\n",
    "configs = [\n",
    "    (\"PPO\", PurePPOAgent, 200_000, 20000),\n",
    "    (\"GNS\", GNSAgent, 80_000, 10000),\n",
    "    (\"PhysRobot\", PhysRobotAgent, 16_000, 4000),\n",
    "]\n",
    "\n",
    "for name, AgentCls, steps, ef in configs:\n",
    "    print(f\"\\n{'='*60}\\nTraining {name} ({steps:,} steps)\\n{'='*60}\")\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        tenv = DummyVecEnv([make_push_box_env(1.0) for _ in range(4)])\n",
    "        agent = AgentCls(tenv)\n",
    "        cb = TrainingCallback(name, eval_env_fn=env_fn, eval_freq=ef)\n",
    "        agent.train(steps, cb=cb)\n",
    "        tenv.close()\n",
    "        ev = eval_agent(agent)\n",
    "        agent.save(f\"{SAVE_DIR}/models/{name.lower()}_final\")\n",
    "        results[name] = {**ev, 'first_success': cb.first_success_ep, 'time_min': (time.time()-t0)/60, 'history': cb.eval_history}\n",
    "        agents_trained[name] = agent\n",
    "        print(f\"\\n{name}: SR={ev['success_rate']:.0%}, reward={ev['mean_reward']:.1f}, first_success={cb.first_success_ep}, time={results[name]['time_min']:.1f}min\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name} FAILED: {e}\"); traceback.print_exc()\n",
    "\n",
    "with open(f\"{SAVE_DIR}/results/training_results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "print(f\"\\nResults saved to {SAVE_DIR}/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Table 1: Sample Efficiency Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<15} {'Steps':<10} {'Success%':<12} {'1st Success':<15} {'Time':<10}\")\n",
    "print(\"-\"*70)\n",
    "for m, s in [('PPO','200K'), ('GNS','80K'), ('PhysRobot','16K')]:\n",
    "    if m in results:\n",
    "        r = results[m]\n",
    "        print(f\"{m:<15} {s:<10} {r['success_rate']*100:>6.1f}%     {str(r.get('first_success','N/A')):<15} {r.get('time_min',0):.1f}min\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = {'PPO': '#e74c3c', 'GNS': '#3498db', 'PhysRobot': '#2ecc71'}\n",
    "ax = axes[0]\n",
    "for m in ['PPO','GNS','PhysRobot']:\n",
    "    if m in results and results[m].get('history'):\n",
    "        h = results[m]['history']\n",
    "        ax.plot([x['step'] for x in h], [x['sr'] for x in h], 'o-', label=m, color=colors[m], lw=2)\n",
    "ax.set_xlabel('Steps'); ax.set_ylabel('Success Rate'); ax.set_title('Learning Curves'); ax.legend(); ax.grid(alpha=0.3)\n",
    "ax = axes[1]\n",
    "ms = [m for m in ['PPO','GNS','PhysRobot'] if m in results]\n",
    "bars = ax.bar(ms, [results[m]['success_rate']*100 for m in ms], color=[colors[m] for m in ms])\n",
    "for b, m in zip(bars, ms): ax.text(b.get_x()+b.get_width()/2, b.get_height()+1, f\"{results[m]['success_rate']*100:.0f}%\", ha='center')\n",
    "ax.set_ylabel('Success Rate (%)'); ax.set_title('Final Performance'); ax.set_ylim(0,100); ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout(); plt.savefig(f'{SAVE_DIR}/results/learning_curves.png', dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60 + \"\\nOOD Generalization Test\\n\" + \"=\"*60)\n",
    "masses = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "ood = {}\n",
    "for name, agent in agents_trained.items():\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    rs = []\n",
    "    for mass in masses:\n",
    "        env = DummyVecEnv([make_push_box_env(mass)]); s = 0\n",
    "        for _ in range(50):\n",
    "            obs = env.reset(); done = False\n",
    "            while not done:\n",
    "                a, _ = agent.model.predict(obs, deterministic=True)\n",
    "                obs, _, dones, infos = env.step(a); done = dones[0]\n",
    "            if infos[0].get('success'): s += 1\n",
    "        env.close(); sr = s/50; rs.append(sr)\n",
    "        print(f\"  mass={mass:.2f}kg: SR={sr:.0%}\")\n",
    "    ood[name] = rs\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for m in ood: ax.plot(masses, [s*100 for s in ood[m]], 'o-', label=m, color=colors.get(m,'gray'), lw=2, ms=8)\n",
    "ax.axvline(x=1.0, color='gray', ls='--', alpha=0.5, label='Training mass')\n",
    "ax.set_xlabel('Box Mass (kg)'); ax.set_ylabel('Success Rate (%)'); ax.set_title('OOD Generalization')\n",
    "ax.legend(); ax.grid(alpha=0.3); ax.set_ylim(0,100)\n",
    "plt.tight_layout(); plt.savefig(f'{SAVE_DIR}/results/ood.png', dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = {'training': results, 'ood': {m: dict(zip([str(x) for x in masses], v)) for m, v in ood.items()}}\n",
    "with open(f'{SAVE_DIR}/results/week1_complete.json', 'w') as f:\n",
    "    json.dump(final, f, indent=2, default=str)\n",
    "print(\"=\"*60 + \"\\nWeek 1 Complete!\\n\" + \"=\"*60)\n",
    "print(f\"Files: {SAVE_DIR}/results/\")"
   ]
  }
 ]
}