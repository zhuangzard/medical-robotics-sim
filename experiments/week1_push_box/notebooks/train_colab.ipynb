{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Robotics - Week 1 Training\n",
        "\n",
        "**Project**: Physics-Informed Foundation Models for Medical Robotics  \n",
        "**Goal**: Train PPO, GNS, and PhysRobot on PushBox task  \n",
        "**Target**: 12.5x sample efficiency, >95% OOD generalization  \n",
        "\n",
        "**GitHub**: https://github.com/zhuangzard/medical-robotics-sim  \n",
        "**Generated**: 2026-02-05 15:09:47  \n",
        "\n",
        "---\n",
        "\n",
        "## \u26a0\ufe0f Setup Required\n",
        "\n",
        "1. **Runtime**: Change to GPU (Runtime \u2192 Change runtime type)\n",
        "2. **GPU Type**: Select V100 or A100 (Colab Pro)\n",
        "3. **Run All**: Runtime \u2192 Run all\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd0d GPU Detection\n",
        "import subprocess\n",
        "import torch\n",
        "\n",
        "print('='*60)\n",
        "print('\ud83c\udfae GPU Configuration')\n",
        "print('='*60)\n",
        "\n",
        "# Check GPU\n",
        "try:\n",
        "    gpu_info = subprocess.check_output(\n",
        "        ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader']\n",
        "    ).decode('utf-8').strip()\n",
        "    print(f'GPU: {gpu_info}')\n",
        "except:\n",
        "    print('\u274c No GPU detected! Please change runtime to GPU.')\n",
        "\n",
        "# PyTorch check\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f'GPU Memory: {gpu_mem:.1f} GB')\n",
        "    \n",
        "    # Auto-configure\n",
        "    if 'A100' in gpu_name:\n",
        "        batch_size, workers = 128, 8\n",
        "        print('\ud83d\ude80 A100 detected: batch_size=128, workers=8')\n",
        "    elif 'V100' in gpu_name:\n",
        "        batch_size, workers = 64, 4\n",
        "        print('\ud83d\ude80 V100 detected: batch_size=64, workers=4')\n",
        "    else:\n",
        "        batch_size, workers = 32, 2\n",
        "        print('\ud83d\ude80 T4 detected: batch_size=32, workers=2')\n",
        "else:\n",
        "    batch_size, workers = 16, 2\n",
        "    print('\u26a0\ufe0f  CPU mode (slow!)')\n",
        "\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udce6 Install Dependencies\n",
        "print('Installing dependencies...')\n",
        "\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q gymnasium mujoco\n",
        "!pip install -q stable-baselines3\n",
        "!pip install -q matplotlib numpy scipy tqdm\n",
        "\n",
        "print('\u2705 Dependencies installed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udce5 Clone Project Repository\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = 'https://github.com/zhuangzard/medical-robotics-sim'\n",
        "REPO_NAME = 'medical-robotics-sim'\n",
        "\n",
        "if not Path(REPO_NAME).exists():\n",
        "    print(f'Cloning {REPO_NAME}...')\n",
        "    !git clone {REPO_URL}\n",
        "    print('\u2705 Repository cloned')\n",
        "else:\n",
        "    print(f'{REPO_NAME} exists, pulling latest...')\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "    %cd ..\n",
        "\n",
        "%cd {REPO_NAME}\n",
        "print(f'\\n\ud83d\udcc2 Working directory: {os.getcwd()}')\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca Setup Progress Tracking\n",
        "from google.colab import drive\n",
        "import json\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Mount Drive (with error handling)\n",
        "try:\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "        print('\u2705 Drive mounted')\n",
        "    else:\n",
        "        print('\u2139\ufe0f  Drive already mounted')\n",
        "except Exception as e:\n",
        "    print(f'\u26a0\ufe0f  Drive mount failed: {e}')\n",
        "    print('Continuing without Drive sync...')\n",
        "    # Create local fallback directory\n",
        "    Path('/content/progress').mkdir(exist_ok=True)\n",
        "\n",
        "# Create progress directory (Drive or local fallback)\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    progress_dir = Path('/content/drive/MyDrive/medical-robotics-progress')\n",
        "    progress_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f'\ud83d\udcc2 Progress dir: {progress_dir} (Drive)')\n",
        "else:\n",
        "    progress_dir = Path('/content/progress')\n",
        "    progress_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f'\ud83d\udcc2 Progress dir: {progress_dir} (local fallback)')\n",
        "\n",
        "progress_file = progress_dir / 'training_progress.json'\n",
        "\n",
        "def update_progress(status, **kwargs):\n",
        "    \"\"\"Update progress file in Drive\"\"\"\n",
        "    progress = {\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'status': status,\n",
        "        'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n",
        "        **kwargs\n",
        "    }\n",
        "    with open(progress_file, 'w') as f:\n",
        "        json.dump(progress, f, indent=2)\n",
        "    print(f'\ud83d\udcca Progress updated: {status}')\n",
        "\n",
        "update_progress('started', message='Training initialization complete')\n",
        "\n",
        "print(f'\u2705 Progress tracking setup')\n",
        "print(f'\ud83d\udcc1 Progress file: {progress_file}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\ude80 Start Training\n",
        "import time\n",
        "\n",
        "print('='*60)\n",
        "print(f'\ud83c\udfc1 Training Started: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "print('='*60)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Update progress\n",
        "    update_progress('training', message='Training in progress', eta_hours=8)\n",
        "    \n",
        "    # Run training script\n",
        "    !bash experiments/week1_push_box/setup_and_run.sh\n",
        "    \n",
        "    # Training complete\n",
        "    duration_sec = time.time() - start_time\n",
        "    duration_hr = duration_sec / 3600\n",
        "    \n",
        "    update_progress('complete', \n",
        "                   message='Training complete', \n",
        "                   duration_hours=duration_hr)\n",
        "    \n",
        "    print('='*60)\n",
        "    print('\u2705 Training Complete!')\n",
        "    print(f'\u23f1\ufe0f  Duration: {duration_hr:.1f} hours')\n",
        "    print('='*60)\n",
        "    \n",
        "except Exception as e:\n",
        "    update_progress('error', message=str(e))\n",
        "    print(f'\u274c Error: {e}')\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcbe Save Results to Drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "# Try Drive first, fallback to /tmp (\u907f\u514d\u9012\u5f52)\n",
        "if os.path.exists('/content/drive/MyDrive'):\n",
        "    results_dir = Path(f'/content/drive/MyDrive/medical-robotics-results/{timestamp}')\n",
        "    save_location = 'Google Drive'\n",
        "else:\n",
        "    results_dir = Path(f'/tmp/medical-robotics-results/{timestamp}')\n",
        "    save_location = '/tmp (local)'\n",
        "\n",
        "print(f'\ud83d\udcbe Saving to: {save_location}')\n",
        "\n",
        "results_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f'\ud83d\udcc1 Saving results to: {results_dir}')\n",
        "\n",
        "# Copy directories (exclude timestamp dirs to avoid recursion)\n",
        "import re\n",
        "dirs_to_save = ['results', 'models', 'data']\n",
        "\n",
        "def ignore_results_dirs(dir_path, names):\n",
        "    \"\"\"Ignore timestamp-based result directories to prevent recursion\"\"\"\n",
        "    # Ignore directories matching YYYYMMDD_HHMMSS pattern\n",
        "    return [n for n in names if re.match(r'\\d{8}_\\d{6}', n)]\n",
        "\n",
        "for dir_name in dirs_to_save:\n",
        "    src = Path(dir_name)\n",
        "    if src.exists() and src.is_dir():\n",
        "        dst = results_dir / dir_name\n",
        "        try:\n",
        "            shutil.copytree(src, dst, \n",
        "                          ignore=ignore_results_dirs,\n",
        "                          dirs_exist_ok=True)\n",
        "            print(f'  \u2705 {dir_name}/ ({sum(1 for _ in dst.rglob(\"*\"))} files)')\n",
        "        except Exception as e:\n",
        "            print(f'  \u26a0\ufe0f  {dir_name}/ skipped: {e}')\n",
        "\n",
        "# Copy key files\n",
        "files_to_save = ['*.json', '*.md', '*.png', '*.pdf', '*.tex']\n",
        "saved_count = 0\n",
        "for pattern in files_to_save:\n",
        "    for file in Path('.').glob(pattern):\n",
        "        if file.is_file():\n",
        "            shutil.copy2(file, results_dir / file.name)\n",
        "            saved_count += 1\n",
        "\n",
        "print(f'  \u2705 {saved_count} files')\n",
        "\n",
        "# Create summary\n",
        "summary = {\n",
        "    'timestamp': timestamp,\n",
        "    'duration_hours': duration_hr,\n",
        "    'gpu': torch.cuda.get_device_name(0),\n",
        "    'status': 'complete',\n",
        "    'drive_path': str(results_dir)\n",
        "}\n",
        "\n",
        "with open(results_dir / 'summary.json', 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "update_progress('saved', message='Results saved to Drive', path=str(results_dir))\n",
        "\n",
        "print(f'\\n\u2705 All results saved to Drive!')\n",
        "print(f'\ud83d\udcc2 {results_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca Display Results\n",
        "from IPython.display import Image, Markdown, display\n",
        "\n",
        "print('='*60)\n",
        "print('\ud83d\udcca Week 1 Training Results')\n",
        "print('='*60)\n",
        "\n",
        "# Display Table 1\n",
        "table1_path = 'results/tables/sample_efficiency.md'\n",
        "if Path(table1_path).exists():\n",
        "    print('\\n\ud83d\udccb Table 1: Sample Efficiency Comparison\\n')\n",
        "    with open(table1_path) as f:\n",
        "        display(Markdown(f.read()))\n",
        "\n",
        "# Display Figure 2\n",
        "fig2_path = 'results/figures/ood_generalization.png'\n",
        "if Path(fig2_path).exists():\n",
        "    print('\\n\ud83d\udcc8 Figure 2: OOD Generalization\\n')\n",
        "    display(Image(fig2_path))\n",
        "\n",
        "# Display final report\n",
        "report_path = 'results/WEEK1_FINAL_REPORT.md'\n",
        "if Path(report_path).exists():\n",
        "    print('\\n\ud83d\udcc4 Final Report (excerpt):\\n')\n",
        "    with open(report_path) as f:\n",
        "        lines = f.readlines()[:50]  # First 50 lines\n",
        "        display(Markdown(''.join(lines)))\n",
        "\n",
        "print('\\n\u2705 Training Complete! All results saved to Drive.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Medical Robotics Week 1 Training",
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}