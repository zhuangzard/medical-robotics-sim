<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 7: Historic Perspective | GDL æ·±åº¦æ•™ç¨‹</title>
  <style>
    /* ===== CSS Variables ===== */
    :root {
      --bg: #ffffff;
      --bg-secondary: #f8f9fa;
      --bg-code: #f4f4f5;
      --text: #1a1a2e;
      --text-secondary: #555;
      --accent: #2563eb;
      --accent-light: #dbeafe;
      --border: #e0e0e0;
      --sidebar-bg: #f0f4f8;
      --sidebar-width: 280px;
      --header-height: 56px;
      --callout-info-bg: #eff6ff;
      --callout-info-border: #3b82f6;
      --callout-warn-bg: #fffbeb;
      --callout-warn-border: #f59e0b;
      --callout-success-bg: #f0fdf4;
      --callout-success-border: #22c55e;
      --callout-robot-bg: #ecfdf5;
      --callout-robot-border: #10b981;
      --callout-math-bg: #faf5ff;
      --callout-math-border: #8b5cf6;
      --callout-exercise-bg: #fff7ed;
      --callout-exercise-border: #f97316;
      --callout-history-bg: #fefce8;
      --callout-history-border: #ca8a04;
      --code-keyword: #d73a49;
      --code-string: #032f62;
      --code-comment: #6a737d;
      --code-function: #6f42c1;
      --code-number: #005cc5;
      --progress-color: #2563eb;
      --shadow: 0 1px 3px rgba(0,0,0,0.1);
    }
    [data-theme="dark"] {
      --bg: #0f172a;
      --bg-secondary: #1e293b;
      --bg-code: #1e293b;
      --text: #e2e8f0;
      --text-secondary: #94a3b8;
      --accent: #60a5fa;
      --accent-light: #1e3a5f;
      --border: #334155;
      --sidebar-bg: #1e293b;
      --callout-info-bg: #172554;
      --callout-info-border: #3b82f6;
      --callout-warn-bg: #422006;
      --callout-warn-border: #f59e0b;
      --callout-success-bg: #052e16;
      --callout-success-border: #22c55e;
      --callout-robot-bg: #064e3b;
      --callout-robot-border: #10b981;
      --callout-math-bg: #2e1065;
      --callout-math-border: #8b5cf6;
      --callout-exercise-bg: #431407;
      --callout-exercise-border: #f97316;
      --callout-history-bg: #422006;
      --callout-history-border: #ca8a04;
      --code-keyword: #ff7b72;
      --code-string: #a5d6ff;
      --code-comment: #8b949e;
      --code-function: #d2a8ff;
      --code-number: #79c0ff;
      --shadow: 0 1px 3px rgba(0,0,0,0.4);
    }

    /* ===== Reset & Base ===== */
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }
    html { scroll-behavior: smooth; scroll-padding-top: calc(var(--header-height) + 16px); }
    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      background: var(--bg);
      color: var(--text);
      line-height: 1.75;
      transition: background 0.3s, color 0.3s;
    }

    /* ===== Progress Bar ===== */
    .progress-bar {
      position: fixed; top: 0; left: 0;
      width: 0%; height: 3px;
      background: linear-gradient(90deg, var(--accent), #8b5cf6);
      z-index: 1001;
      transition: width 0.1s;
    }

    /* ===== Header ===== */
    .header {
      position: fixed; top: 0; left: 0; right: 0;
      height: var(--header-height);
      background: var(--bg);
      border-bottom: 1px solid var(--border);
      display: flex; align-items: center; justify-content: space-between;
      padding: 0 24px;
      z-index: 1000;
      backdrop-filter: blur(10px);
    }
    .header-title a {
      font-weight: 700; font-size: 1.1em;
      color: var(--text); text-decoration: none;
    }
    .header-nav { display: flex; gap: 12px; align-items: center; }
    .header-nav a {
      color: var(--accent); text-decoration: none; font-size: 0.9em;
      padding: 4px 8px; border-radius: 6px;
      transition: background 0.2s;
    }
    .header-nav a:hover { background: var(--accent-light); }
    .theme-toggle {
      background: none; border: 1px solid var(--border);
      border-radius: 8px; padding: 6px 10px;
      cursor: pointer; font-size: 1.1em;
      color: var(--text);
    }

    /* ===== Sidebar ===== */
    .sidebar {
      position: fixed; top: var(--header-height); left: 0;
      width: var(--sidebar-width);
      height: calc(100vh - var(--header-height));
      background: var(--sidebar-bg);
      border-right: 1px solid var(--border);
      overflow-y: auto;
      padding: 16px 12px;
      z-index: 999;
      transition: transform 0.3s;
      font-size: 0.88em;
    }
    .sidebar h3 {
      font-size: 0.8em; text-transform: uppercase;
      letter-spacing: 0.1em; color: var(--text-secondary);
      margin: 16px 0 8px; padding-left: 8px;
    }
    .sidebar h3:first-child { margin-top: 0; }
    .sidebar a {
      display: block; padding: 5px 12px;
      color: var(--text); text-decoration: none;
      border-radius: 6px; margin: 1px 0;
      transition: background 0.2s;
      line-height: 1.5;
    }
    .sidebar a:hover { background: var(--accent-light); color: var(--accent); }
    .sidebar a.sub { padding-left: 28px; font-size: 0.92em; color: var(--text-secondary); }
    .sidebar a.active { background: var(--accent-light); color: var(--accent); font-weight: 600; }
    .sidebar-toggle {
      display: none;
      position: fixed; top: calc(var(--header-height) + 8px); left: 8px;
      z-index: 1001;
      background: var(--bg); border: 1px solid var(--border);
      border-radius: 8px; padding: 8px 12px;
      cursor: pointer; font-size: 1.2em;
      color: var(--text);
    }

    /* ===== Main Content ===== */
    .main {
      margin-left: var(--sidebar-width);
      margin-top: var(--header-height);
      max-width: 900px;
      padding: 32px 40px 80px;
    }
    .main h1 {
      font-size: 2.2em; font-weight: 800;
      margin-bottom: 24px;
      background: linear-gradient(135deg, var(--accent), #8b5cf6);
      -webkit-background-clip: text; -webkit-text-fill-color: transparent;
      background-clip: text;
      line-height: 1.3;
    }
    .main h2 {
      font-size: 1.6em; font-weight: 700;
      margin: 48px 0 16px;
      padding-bottom: 8px;
      border-bottom: 2px solid var(--accent);
      color: var(--text);
    }
    .main h3 {
      font-size: 1.25em; font-weight: 600;
      margin: 32px 0 12px;
      color: var(--text);
    }
    .main h4 {
      font-size: 1.05em; font-weight: 600;
      margin: 20px 0 8px;
    }
    .main p { margin-bottom: 12px; }
    .main ul, .main ol { margin: 8px 0 16px 24px; }
    .main li { margin-bottom: 6px; }
    .main strong { color: var(--text); }
    .term { color: var(--accent); font-weight: 600; }
    .main a { color: var(--accent); text-decoration: underline; }

    /* ===== Callout Boxes ===== */
    .callout {
      border-left: 4px solid;
      border-radius: 8px;
      padding: 16px 20px;
      margin: 20px 0;
    }
    .callout h4 { margin-top: 0; margin-bottom: 8px; }
    .callout-info { background: var(--callout-info-bg); border-color: var(--callout-info-border); }
    .callout-warn { background: var(--callout-warn-bg); border-color: var(--callout-warn-border); }
    .callout-success { background: var(--callout-success-bg); border-color: var(--callout-success-border); }
    .callout-robot { background: var(--callout-robot-bg); border-color: var(--callout-robot-border); }
    .callout-math { background: var(--callout-math-bg); border-color: var(--callout-math-border); }
    .callout-exercise { background: var(--callout-exercise-bg); border-color: var(--callout-exercise-border); }
    .callout-history { background: var(--callout-history-bg); border-color: var(--callout-history-border); }

    /* ===== Blueprint Box ===== */
    .blueprint {
      background: var(--bg-secondary);
      border: 2px solid var(--accent);
      border-radius: 12px;
      padding: 20px 24px;
      margin: 20px 0;
    }
    .blueprint h4 { color: var(--accent); margin-bottom: 12px; }

    /* ===== Math ===== */
    .math-block {
      background: var(--bg-secondary);
      border-radius: 8px;
      padding: 16px 20px;
      margin: 16px 0;
      overflow-x: auto;
    }
    .math-explain {
      margin-top: 12px;
      padding-top: 12px;
      border-top: 1px dashed var(--border);
      font-size: 0.92em;
      color: var(--text-secondary);
    }

    /* ===== Code Blocks ===== */
    .code-container {
      position: relative;
      margin: 16px 0;
      border-radius: 8px;
      overflow: hidden;
      border: 1px solid var(--border);
    }
    .code-header {
      display: flex; justify-content: space-between; align-items: center;
      background: var(--bg-secondary);
      padding: 8px 16px;
      font-size: 0.85em;
      color: var(--text-secondary);
      border-bottom: 1px solid var(--border);
    }
    .copy-btn {
      background: none; border: 1px solid var(--border);
      border-radius: 4px; padding: 2px 10px;
      cursor: pointer; font-size: 0.85em;
      color: var(--text-secondary);
      transition: all 0.2s;
    }
    .copy-btn:hover { background: var(--accent-light); color: var(--accent); }
    pre {
      margin: 0; padding: 16px;
      background: var(--bg-code);
      overflow-x: auto;
      font-family: 'JetBrains Mono', 'Fira Code', monospace;
      font-size: 0.88em;
      line-height: 1.6;
      color: var(--text);
    }
    code {
      font-family: 'JetBrains Mono', 'Fira Code', monospace;
      font-size: 0.9em;
    }
    p code, li code {
      background: var(--bg-code);
      padding: 2px 6px;
      border-radius: 4px;
    }

    /* ===== Figures ===== */
    .figure {
      margin: 24px 0;
      text-align: center;
    }
    .figure img {
      max-width: 100%;
      border-radius: 8px;
      box-shadow: var(--shadow);
    }
    .figure figcaption {
      margin-top: 8px;
      font-size: 0.9em;
      color: var(--text-secondary);
      font-style: italic;
    }

    /* ===== Bilingual ===== */
    .bilingual {
      display: grid;
      grid-template-columns: 1fr;
      gap: 8px;
      margin: 12px 0;
    }
    .bilingual .en {
      font-size: 0.9em;
      color: var(--text-secondary);
      font-style: italic;
      padding-left: 16px;
      border-left: 2px solid var(--border);
    }

    /* ===== Timeline ===== */
    .timeline {
      position: relative;
      padding-left: 32px;
      margin: 24px 0;
    }
    .timeline::before {
      content: '';
      position: absolute;
      left: 12px;
      top: 0;
      bottom: 0;
      width: 2px;
      background: var(--accent);
    }
    .timeline-item {
      position: relative;
      margin-bottom: 20px;
      padding: 12px 16px;
      background: var(--bg-secondary);
      border-radius: 8px;
      border: 1px solid var(--border);
    }
    .timeline-item::before {
      content: '';
      position: absolute;
      left: -26px;
      top: 18px;
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: var(--accent);
      border: 2px solid var(--bg);
    }
    .timeline-year {
      font-weight: 700;
      color: var(--accent);
      font-size: 0.95em;
    }
    .timeline-title {
      font-weight: 600;
      margin: 4px 0;
    }
    .timeline-desc {
      font-size: 0.92em;
      color: var(--text-secondary);
    }

    /* ===== Table ===== */
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 16px 0;
      font-size: 0.92em;
    }
    th, td {
      padding: 10px 14px;
      border: 1px solid var(--border);
      text-align: left;
    }
    th {
      background: var(--bg-secondary);
      font-weight: 600;
    }

    /* ===== Chapter Nav ===== */
    .chapter-nav {
      display: flex; justify-content: space-between;
      margin-top: 48px; padding-top: 24px;
      border-top: 2px solid var(--border);
    }
    .chapter-nav a {
      color: var(--accent); text-decoration: none;
      font-weight: 600; padding: 8px 16px;
      border-radius: 8px; border: 1px solid var(--accent);
      transition: all 0.2s;
    }
    .chapter-nav a:hover { background: var(--accent); color: white; }

    /* ===== Responsive ===== */
    @media (max-width: 768px) {
      .sidebar { transform: translateX(-100%); }
      .sidebar.open { transform: translateX(0); }
      .sidebar-toggle { display: block; }
      .main { margin-left: 0; padding: 24px 16px 60px; }
      .main h1 { font-size: 1.6em; }
      .main h2 { font-size: 1.3em; }
    }

    /* ===== Person Card ===== */
    .person-card {
      display: flex; gap: 16px; align-items: flex-start;
      background: var(--bg-secondary);
      border-radius: 10px;
      padding: 16px;
      margin: 12px 0;
      border: 1px solid var(--border);
    }
    .person-card .person-emoji {
      font-size: 2em;
      flex-shrink: 0;
    }
    .person-card .person-info h4 {
      margin: 0 0 4px; font-size: 1.05em;
    }
    .person-card .person-info p {
      margin: 0; font-size: 0.92em; color: var(--text-secondary);
    }

    /* ===== Quote ===== */
    .epigraph {
      font-style: italic;
      font-size: 1.15em;
      text-align: center;
      margin: 32px 24px;
      padding: 24px;
      border-left: 4px solid var(--accent);
      background: var(--bg-secondary);
      border-radius: 0 8px 8px 0;
      color: var(--accent);
    }
    .epigraph .attribution {
      font-size: 0.85em;
      margin-top: 8px;
      color: var(--text-secondary);
      font-style: normal;
    }

    /* ===== Comparison Grid ===== */
    .compare-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 16px;
      margin: 16px 0;
    }
    .compare-grid > div {
      background: var(--bg-secondary);
      border-radius: 8px;
      padding: 16px;
      border: 1px solid var(--border);
    }
    @media (max-width: 600px) {
      .compare-grid { grid-template-columns: 1fr; }
    }
  </style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
</head>
<body>
  <div class="progress-bar" id="progressBar"></div>

  <header class="header">
    <div class="header-title"><a href="../index.html">ğŸ“ GDL æ·±åº¦æ•™ç¨‹</a></div>
    <div class="header-nav">
      <a href="../chapter6/index.html">â† Ch.6</a>
      <a href="../index.html">ç›®å½•</a>
      <button class="theme-toggle" onclick="toggleTheme()">ğŸŒ™</button>
    </div>
  </header>

  <button class="sidebar-toggle" onclick="toggleSidebar()">â˜°</button>

  <nav class="sidebar" id="sidebar">
    <h3>Chapter 7</h3>
    <a href="#overview">ğŸ“‹ æ¦‚è¿°</a>
    <a href="#ancient-symmetry">å¤ä»£å¯¹ç§°æ€§æ€æƒ³</a>
    <a href="#platonic" class="sub">æŸæ‹‰å›¾ä½“</a>
    <a href="#kepler" class="sub">Kepler ä¸é›ªèŠ±</a>

    <h3>7.1 æ•°å­¦ä¸ç‰©ç†ä¸­çš„å¯¹ç§°æ€§</h3>
    <a href="#sec7-1">Symmetry in Math & Physics</a>
    <a href="#group-theory-origins" class="sub">ç¾¤è®ºçš„èµ·æº</a>
    <a href="#galois" class="sub">Galois & å¤šé¡¹å¼</a>
    <a href="#lie-klein" class="sub">Lie & Klein</a>
    <a href="#erlangen" class="sub">Erlangen Program</a>
    <a href="#noether" class="sub">Noether å®šç†</a>
    <a href="#noether-deriv" class="sub">ğŸ“ Noether æ¨å¯¼</a>
    <a href="#gauge-physics" class="sub">è§„èŒƒç†è®º</a>
    <a href="#standard-model" class="sub">æ ‡å‡†æ¨¡å‹</a>

    <h3>7.2 è°ƒå’Œåˆ†æä¸ä¿¡å·å¤„ç†</h3>
    <a href="#sec7-2">Harmonic Analysis</a>
    <a href="#fourier-history" class="sub">Fourier çš„é—äº§</a>
    <a href="#m-theory" class="sub">M-theory & è§†è§‰çš®å±‚</a>
    <a href="#steerable" class="sub">å¯æ§é‡‘å­—å¡”</a>
    <a href="#scattering" class="sub">æ•£å°„å˜æ¢</a>
    <a href="#gsp-history" class="sub">å›¾ä¿¡å·å¤„ç†</a>
    <a href="#computer-graphics" class="sub">è®¡ç®—æœºå›¾å½¢å­¦</a>
    <a href="#code-scattering" class="sub">ğŸ’» æ•£å°„å˜æ¢ä»£ç </a>

    <h3>7.3 æ—©æœŸ ML ä¸­çš„å¯¹ç§°æ€§</h3>
    <a href="#sec7-3">Early ML Symmetry</a>
    <a href="#invariance-theorem" class="sub">ç¾¤ä¸å˜æ€§å®šç†</a>
    <a href="#neocognitron" class="sub">Neocognitron</a>
    <a href="#lecun-cnn" class="sub">LeCun ä¸ CNN</a>
    <a href="#wood-shawe" class="sub">è¡¨ç¤ºè®ºè§†è§’</a>
    <a href="#code-cnn-symmetry" class="sub">ğŸ’» CNN å¯¹ç§°æ€§ä»£ç </a>

    <h3>7.4 GNN çš„å‘å±•å²</h3>
    <a href="#sec7-4">GNN History</a>
    <a href="#gnn-prehistory" class="sub">1990s: å‰ GNN æ—¶ä»£</a>
    <a href="#gnn-birth" class="sub">2005: GNN è¯ç”Ÿ</a>
    <a href="#gnn-chemistry" class="sub">è®¡ç®—åŒ–å­¦é©±åŠ¨</a>
    <a href="#node-embed" class="sub">èŠ‚ç‚¹åµŒå…¥</a>
    <a href="#pgm-gnn" class="sub">PGM ä¸ GNN</a>
    <a href="#spectral-gnn" class="sub">è°±åŸŸ GNN</a>
    <a href="#spatial-gnn" class="sub">ç©ºé—´åŸŸ GNN</a>
    <a href="#code-gnn-evolution" class="sub">ğŸ’» GNN æ¼”åŒ–ä»£ç </a>

    <h3>7.5 WL æµ‹è¯•ä¸è¡¨è¾¾åŠ›</h3>
    <a href="#sec7-5">WL Test & Expressivity</a>
    <a href="#wl-formalism" class="sub">WL å½¢å¼åŒ–</a>
    <a href="#wl-gnn-bound" class="sub">GNN â‰¤ WL</a>
    <a href="#gin" class="sub">GIN æ¶æ„</a>
    <a href="#higher-order" class="sub">é«˜é˜¶æ–¹æ³•</a>
    <a href="#continuous-express" class="sub">è¿ç»­ç‰¹å¾ç©ºé—´</a>
    <a href="#code-wl" class="sub">ğŸ’» WL æµ‹è¯•ä»£ç </a>

    <h3>7.6 Transformer ä¸ GNN</h3>
    <a href="#sec7-6">Transformers & GNNs</a>
    <a href="#transformer-as-gnn" class="sub">Transformer = å®Œå…¨å›¾ GNN</a>
    <a href="#latent-graph" class="sub">æ½œå›¾å­¦ä¹ </a>
    <a href="#algorithmic-reasoning" class="sub">ç®—æ³•æ¨ç†</a>

    <h3>7.7 GDL çš„è¯ç”Ÿä¸æœªæ¥</h3>
    <a href="#sec7-7">GDL: Past & Future</a>
    <a href="#gdl-name" class="sub">åå­—çš„ç”±æ¥</a>
    <a href="#5g-naming" class="sub">"5G" çš„å‘½å</a>
    <a href="#gdl-future" class="sub">æœªæ¥æ–¹å‘</a>
    <a href="#robot-future" class="sub">ğŸ¤– PhysRobot</a>

    <h3>é™„å½•</h3>
    <a href="#summary-table">ğŸ“Š å¤§äº‹å¹´è¡¨</a>
    <a href="#exercises">ğŸ“ ç»ƒä¹ é¢˜</a>
    <a href="#references">ğŸ“š å‚è€ƒæ–‡çŒ®</a>

    <h3>å¯¼èˆª</h3>
    <a href="../index.html">ğŸ“š æ€»ç›®å½•</a>
    <a href="../chapter6/index.html">â† Ch.6 åº”ç”¨</a>
  </nav>

  <!-- ============================================================ -->
  <!-- MAIN CONTENT -->
  <!-- ============================================================ -->
  <main class="main">

    <h1>Chapter 7: Historic Perspective<br><span style="font-size:0.5em;color:var(--text-secondary)">å†å²è§†è§’ï¼šä»æŸæ‹‰å›¾åˆ° Transformer çš„å¯¹ç§°æ€§ä¹‹è·¯</span></h1>

    <!-- ============================================================ -->
    <!-- OVERVIEW -->
    <!-- ============================================================ -->
    <div class="callout callout-info" id="overview">
      <h4>ğŸ“‹ æœ¬ç« æ¦‚è¿°</h4>
      <p>æœ¬ç« æ˜¯å…¨ä¹¦æœ€é•¿çš„ç« èŠ‚ï¼ˆå«å‚è€ƒæ–‡çŒ®å…± 43 é¡µï¼‰ï¼Œè¿½æº¯äº†ä»å¤ä»£å¯¹ç§°æ€§æ€æƒ³åˆ°ç°ä»£å‡ ä½•æ·±åº¦å­¦ä¹ çš„å®Œæ•´å‘å±•å†ç¨‹ã€‚å®ƒä¸ä»…æ˜¯ä¸€éƒ¨å­¦æœ¯å²ï¼Œæ›´æ˜¯ç†è§£ GDL ç»Ÿä¸€æ¡†æ¶ <strong>ä¸ºä»€ä¹ˆ</strong> æœ‰æ•ˆçš„æ€æƒ³æ ¹æºã€‚</p>
      <p><strong>è¦†ç›–ä¸»é¢˜</strong>ï¼š</p>
      <ol>
        <li>å¤ä»£å¯¹ç§°æ€§ï¼šæŸæ‹‰å›¾ä½“ã€Kepler çš„é›ªèŠ±</li>
        <li>ç¾¤è®ºçš„èµ·æºï¼šGalois â†’ Lie â†’ Klein â†’ Erlangen Program</li>
        <li>ç‰©ç†å­¦ä¸­çš„å¯¹ç§°æ€§ï¼šNoether å®šç†ã€è§„èŒƒç†è®ºã€æ ‡å‡†æ¨¡å‹</li>
        <li>è°ƒå’Œåˆ†æï¼šä» Fourier åˆ°æ•£å°„å˜æ¢</li>
        <li>ç¥ç»ç½‘ç»œä¸­çš„å¯¹ç§°æ€§ï¼šä»æ„ŸçŸ¥æœºåˆ° CNN</li>
        <li>å›¾ç¥ç»ç½‘ç»œçš„å®Œæ•´å‘å±•å²</li>
        <li>WL æµ‹è¯•ä¸è¡¨è¾¾åŠ›åˆ†æ</li>
        <li>Transformer ä¸ GNN çš„ç»Ÿä¸€è§†è§’</li>
        <li>ç®—æ³•æ¨ç†ä¸ GDL çš„æœªæ¥</li>
      </ol>
      <p><strong>é¢„è®¡é˜…è¯»æ—¶é—´</strong>ï¼š3-4 å°æ—¶ï¼ˆå«ä»£ç å®éªŒå’Œç»ƒä¹ ï¼‰</p>
    </div>

    <div class="callout callout-robot">
      <h4>ğŸ¤– PhysRobot è§†è§’ï¼šä¸ºä»€ä¹ˆå­¦å†å²ï¼Ÿ</h4>
      <p>å†å²ä¸æ˜¯è£…é¥°ã€‚ç†è§£æ¯ç§æ¶æ„çš„ <strong>æ€æƒ³èµ·æº</strong>ï¼Œæ‰èƒ½åœ¨é¢å¯¹æ–°é—®é¢˜æ—¶åšå‡ºæ­£ç¡®çš„è®¾è®¡é€‰æ‹©ï¼š</p>
      <ul>
        <li><strong>ç‰©ç†ä»¿çœŸ</strong>ä¸­çš„ç­‰å˜æ€§ â†’ ç›´æ¥æºäº Noether å®šç†ï¼ˆ1918ï¼‰å’Œè§„èŒƒç†è®º</li>
        <li><strong>ç½‘æ ¼ä¸Šçš„æ¶ˆæ¯ä¼ é€’</strong> â†’ æºäº PGM çš„ä¿¡å¿µä¼ æ’­å’Œè®¡ç®—åŒ–å­¦çš„åˆ†å­å›¾</li>
        <li><strong>å¤šå°ºåº¦æ–¹æ³•</strong> â†’ æºäºè°ƒå’Œåˆ†æå’Œå°æ³¢ç†è®º</li>
        <li><strong>æ³¨æ„åŠ›æœºåˆ¶</strong> â†’ æºäº MoNet å’Œè®¡ç®—æœºå›¾å½¢å­¦çš„å±€éƒ¨æè¿°å­</li>
      </ul>
      <p>ç†è§£å†å²ï¼Œå°±æ˜¯ç†è§£ä¸ºä»€ä¹ˆä½ é€‰æ‹©çš„æ¶æ„æ˜¯"å¯¹çš„"ã€‚</p>
    </div>

    <div class="epigraph">
      "Symmetry, as wide or as narrow as you may define its meaning, is one idea by which man through the ages has tried to comprehend and create order, beauty, and perfection."
      <div class="attribution">â€” Hermann Weyl, <em>Symmetry</em> (1952)</div>
    </div>

    <div class="bilingual">
      <div class="zh">
        <p>è¿™ä¸ªé¢‡å…·è¯—æ„çš„å¯¹ç§°æ€§å®šä¹‰æ¥è‡ªä¼Ÿå¤§çš„æ•°å­¦å®¶ <strong>Hermann Weyl</strong>ï¼Œå‡ºè‡ªä»–çš„åŒåè‘—ä½œï¼Œè¿™æ˜¯ä»–ä»æ™®æ—æ–¯é¡¿é«˜ç­‰ç ”ç©¶é™¢é€€ä¼‘å‰çš„ <span class="term">å¤©é¹…ä¹‹æ­Œ</span>ï¼ˆSchwanengesangï¼‰ã€‚Weyl è¿½æº¯äº†å¯¹ç§°æ€§åœ¨ç§‘å­¦å’Œè‰ºæœ¯ä¸­ä¸€ç›´ä»¥æ¥çš„ç‰¹æ®Šåœ°ä½â€”â€”ä»è‹ç¾å°”çš„å¯¹ç§°è®¾è®¡åˆ°æ¯•è¾¾å“¥æ‹‰æ–¯å­¦æ´¾å¯¹æ—‹è½¬å¯¹ç§°çš„å´‡æ‹œã€‚</p>
      </div>
      <div class="en">
        This somewhat poetic definition of symmetry is given in the eponymous book of Hermann Weyl, his Schwanengesang on the eve of retirement from the Institute for Advanced Study in Princeton.
      </div>
    </div>

    <!-- ============================================================ -->
    <!-- ANCIENT SYMMETRY -->
    <!-- ============================================================ -->
    <h2 id="ancient-symmetry">å¤ä»£å¯¹ç§°æ€§æ€æƒ³<br><span style="font-size:0.7em;color:var(--text-secondary)">Ancient Symmetry: From Sumeria to Kepler</span></h2>

    <h3 id="platonic">æŸæ‹‰å›¾ä½“ä¸ ÏƒÏ…Î¼Î¼ÎµÏ„ÏÎ¯Î±</h3>

    <div class="bilingual">
      <div class="zh">
        <p>è™½ç„¶ <strong>æŸæ‹‰å›¾</strong>ï¼ˆPlatoï¼‰è¢«è®¤ä¸ºåˆ›é€ äº† <span class="term">ÏƒÏ…Î¼Î¼ÎµÏ„ÏÎ¯Î±</span>ï¼ˆsymmetriaï¼Œå­—é¢æ„æ€ä¸º"åŒä¸€åº¦é‡"ï¼‰è¿™ä¸€æœ¯è¯­ï¼Œä½†ä»–åªæ˜¯æ¨¡ç³Šåœ°ç”¨å®ƒæ¥è¡¨è¾¾è‰ºæœ¯ä¸­çš„æ¯”ä¾‹ä¹‹ç¾å’ŒéŸ³ä¹ä¸­çš„å’Œè°ã€‚çœŸæ­£è®©å¯¹ç§°æ€§æˆä¸ºç§‘å­¦æ¦‚å¿µçš„ï¼Œæ˜¯ä»–å¯¹äº”ç§æ­£å¤šé¢ä½“çš„è¿·æ‹ï¼š</p>
      </div>
      <div class="en">
        Though Plato is credited with coining the term ÏƒÏ…Î¼Î¼ÎµÏ„ÏÎ¯Î±, which literally translates as 'same measure', he used it only vaguely to convey the beauty of proportion in art and harmony in music.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ äº”ç§æŸæ‹‰å›¾ä½“ (Platonic Solids)</h4>
      <table>
        <thead>
          <tr><th>å¤šé¢ä½“</th><th>é¢</th><th>é¢çš„å½¢çŠ¶</th><th>æŸæ‹‰å›¾çš„å…ƒç´ </th><th>æ—‹è½¬å¯¹ç§°ç¾¤</th><th>|G|</th></tr>
        </thead>
        <tbody>
          <tr><td>æ­£å››é¢ä½“ (Tetrahedron)</td><td>4</td><td>æ­£ä¸‰è§’å½¢</td><td>ğŸ”¥ ç«</td><td>$A_4$</td><td>12</td></tr>
          <tr><td>æ­£æ–¹ä½“ (Cube)</td><td>6</td><td>æ­£æ–¹å½¢</td><td>ğŸŒ åœŸ</td><td>$S_4$</td><td>24</td></tr>
          <tr><td>æ­£å…«é¢ä½“ (Octahedron)</td><td>8</td><td>æ­£ä¸‰è§’å½¢</td><td>ğŸ’¨ æ°”</td><td>$S_4$</td><td>24</td></tr>
          <tr><td>æ­£åäºŒé¢ä½“ (Dodecahedron)</td><td>12</td><td>æ­£äº”è¾¹å½¢</td><td>ğŸŒŒ ä»¥å¤ª</td><td>$A_5$</td><td>60</td></tr>
          <tr><td>æ­£äºŒåé¢ä½“ (Icosahedron)</td><td>20</td><td>æ­£ä¸‰è§’å½¢</td><td>ğŸ’§ æ°´</td><td>$A_5$</td><td>60</td></tr>
        </tbody>
      </table>
      <div class="math-explain">
        <p>æŸæ‹‰å›¾è®¤ä¸ºè¿™äº”ç§æ­£å¤šé¢ä½“æ˜¯æ„æˆç‰©è´¨ä¸–ç•Œçš„åŸºæœ¬æ„ä»¶ã€‚æ­£æ–¹ä½“å’Œæ­£å…«é¢ä½“å…±äº«å¯¹ç§°ç¾¤ $S_4$ï¼ˆå¯¹ç§°ç¾¤ = æ—‹è½¬ + åå°„ï¼‰ï¼Œæ­£åäºŒé¢ä½“å’Œæ­£äºŒåé¢ä½“å…±äº« $A_5$â€”â€”å®ƒä»¬æ„æˆ<strong>å¯¹å¶å¤šé¢ä½“</strong>ï¼ˆdual polyhedraï¼‰ã€‚è¿™ç§"å¯¹å¶æ€§"çš„æ¦‚å¿µåœ¨ GDL ä¸­ä»¥å›¾å¯¹å¶çš„å½¢å¼å†æ¬¡å‡ºç°ã€‚</p>
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch7_p118_img0.png" alt="Chapter 7 - Historic perspective illustrations">
      <figcaption>å›¾ 7.1ï¼šåŸä¹¦æ’å›¾ã€‚ä»å¤ä»£å¯¹ç§°å›¾æ¡ˆåˆ°æŸæ‹‰å›¾ä½“â€”â€”å¯¹ç§°æ€§ä½œä¸ºç†è§£å’Œåˆ›é€ ç§©åºã€ç¾å’Œå®Œç¾çš„æ ¸å¿ƒæ€æƒ³è´¯ç©¿äº†äººç±»æ–‡æ˜å²ã€‚</figcaption>
    </div>

    <h3 id="kepler">Kepler ä¸å…­è§’é›ªèŠ± (1611)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¤©æ–‡å­¦å®¶å’Œæ•°å­¦å®¶ <strong>Johannes Kepler</strong> å¯¹é›ªèŠ±å…­è§’å¯¹ç§°ç»“æ„è¿›è¡Œäº†é¦–æ¬¡ä¸¥æ ¼åˆ†æã€‚åœ¨ä»–çš„è®ºæ–‡ <em>Strena, Seu De Nive Sexangula</em>ï¼ˆ"æ–°å¹´ç¤¼ç‰©ï¼Œè®ºå…­è§’é›ªèŠ±"ï¼‰ä¸­â€”â€”è¿™æ˜¯ 1611 å¹´ä»–ä½œä¸ºåœ£è¯ç¤¼ç‰©å¯„ç»™ä»–çš„èµåŠ©äººå…¼å¥½å‹ Johannes MatthÃ¤us Wackher von Wackenfels çš„ä¸€æœ¬å°å†Œå­â€”â€”ä»–å°†é›ªèŠ±çš„å…­é‡äºŒé¢ä½“ç»“æ„å½’å› äºç²’å­çš„<span class="term">å…­è§’å¯†å †</span>ï¼ˆhexagonal packingï¼‰ã€‚</p>
        <p>è¿™ä¸ªæƒ³æ³•è™½ç„¶æ—©äºäººç±»å¯¹ç‰©è´¨æ„æˆæ–¹å¼çš„æ¸…æ™°ç†è§£ï¼Œä½†è‡³ä»Šä»æ˜¯<span class="term">æ™¶ä½“å­¦</span>çš„åŸºç¡€ï¼ˆBall, 2011ï¼‰ã€‚</p>
      </div>
      <div class="en">
        Kepler attributed the six-fold dihedral structure of snowflakes to hexagonal packing of particles â€” an idea that though preceded the clear understanding of how matter is formed, still holds today as the basis of crystallography.
      </div>
    </div>

    <div class="callout callout-history">
      <h4>ğŸº å†å²è¶£é—»ï¼šä»é›ªèŠ±åˆ° GNN</h4>
      <p>Kepler çš„å…­è§’å¯†å †å‡è®¾ï¼ˆ"çƒå †é—®é¢˜"ï¼‰ç›´åˆ° 2017 å¹´æ‰è¢« Thomas Hales é€šè¿‡è®¡ç®—æœºè¾…åŠ©è¯æ˜å®Œå…¨è§£å†³ã€‚æœ‰è¶£çš„æ˜¯ï¼ŒKepler è§‚å¯Ÿé›ªèŠ±å¯¹ç§°æ€§çš„æ€ç»´æ¨¡å¼â€”â€”<strong>"ä»å¯è§‚å¯Ÿçš„å¯¹ç§°æ€§æ¨æ–­åº•å±‚ç»“æ„"</strong>â€”â€”æ°æ°æ˜¯ç°ä»£ GNN åšçš„äº‹ï¼šä»å›¾çš„å¯¹ç§°ä¸å˜æ€§æ¨æ–­èŠ‚ç‚¹å’Œè¾¹çš„æ€§è´¨ã€‚</p>
    </div>

    <div class="math-block">
      <p><strong>é›ªèŠ±çš„å¯¹ç§°ç¾¤ï¼š</strong>äºŒé¢ä½“ç¾¤ $D_6$</p>
      $$D_6 = \langle r, s \mid r^6 = s^2 = e, \; srs = r^{-1} \rangle$$
      <div class="math-explain">
        <p>$r$ = æ—‹è½¬ 60Â°ï¼Œ$s$ = åå°„ã€‚$|D_6| = 12$ï¼ˆ6 ä¸ªæ—‹è½¬ + 6 ä¸ªåå°„ï¼‰ã€‚è¿™æ˜¯é›ªèŠ±ï¼ˆä»¥åŠè‹¯ç¯ï¼‰çš„ç²¾ç¡®å¯¹ç§°ç¾¤ã€‚åœ¨åˆ†å­å›¾ç½‘ç»œä¸­ï¼Œåˆ©ç”¨è¿™ç§å¯¹ç§°æ€§å¯ä»¥å¤§å¤§å‡å°‘éœ€è¦å­¦ä¹ çš„å‚æ•°ã€‚</p>
      </div>
    </div>

    <!-- ============================================================ -->
    <!-- 7.1 SYMMETRY IN MATH & PHYSICS -->
    <!-- ============================================================ -->
    <h2 id="sec7-1">7.1 æ•°å­¦ä¸ç‰©ç†ä¸­çš„å¯¹ç§°æ€§<br><span style="font-size:0.7em;color:var(--text-secondary)">Symmetry in Mathematics and Physics</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>åœ¨ç°ä»£æ•°å­¦ä¸­ï¼Œå¯¹ç§°æ€§å‡ ä¹æ— ä¸€ä¾‹å¤–åœ°ç”¨<span class="term">ç¾¤è®º</span>ï¼ˆGroup Theoryï¼‰çš„è¯­è¨€æ¥è¡¨è¾¾ã€‚ç¾¤è®ºçš„èµ·æºé€šå¸¸å½’åŠŸäº Ã‰variste Galoisï¼Œä»–åœ¨ 1830 å¹´ä»£åˆ›é€ äº†è¿™ä¸ªæœ¯è¯­å¹¶ç”¨å®ƒæ¥ç ”ç©¶å¤šé¡¹å¼æ–¹ç¨‹çš„å¯è§£æ€§ã€‚</p>
      </div>
      <div class="en">
        In modern mathematics, symmetry is almost univocally expressed in the language of group theory. The origins of this theory are usually attributed to Ã‰variste Galois, who coined the term and used it to study solvability of polynomial equations in the 1830s.
      </div>
    </div>

    <h3 id="group-theory-origins">ç¾¤è®ºçš„èµ·æº</h3>

    <h4 id="galois">Ã‰variste Galois ä¸å¤šé¡¹å¼çš„å¯è§£æ€§</h4>

    <div class="person-card">
      <div class="person-emoji">ğŸ§®</div>
      <div class="person-info">
        <h4>Ã‰variste Galois (1811-1832)</h4>
        <p>åœ¨ 20 å²æ­»äºå†³æ–—ä¹‹å‰ï¼ŒGalois åˆ›é€ äº†ç¾¤è®ºï¼ˆGroup Theoryï¼‰â€”â€”ç”¨å¯¹ç§°æ€§æ¥åˆ¤æ–­å¤šé¡¹å¼æ–¹ç¨‹æ˜¯å¦æœ‰æ ¹å¼è§£ã€‚ä»–è¯æ˜äº†äº”æ¬¡åŠä»¥ä¸Šæ–¹ç¨‹æ²¡æœ‰ä¸€èˆ¬çš„æ ¹å¼æ±‚è§£å…¬å¼ï¼Œå› ä¸ºå¯¹åº”çš„å¯¹ç§°ç¾¤ï¼ˆ$S_5$ï¼‰æ²¡æœ‰å¯è§£çš„æ­£è§„å­ç¾¤é“¾ã€‚è¿™ä¸€å‘ç°å¥ å®šäº†ç”¨"å¯¹ç§°æ€§ç»“æ„"æ¥ç†è§£"æ•°å­¦é—®é¢˜å¯è§£æ€§"çš„èŒƒå¼ã€‚</p>
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ Galois ç†è®ºçš„æ ¸å¿ƒæ€æƒ³</h4>
      <p>ç»™å®šä¸€ä¸ªå¤šé¡¹å¼ $p(x) = 0$ï¼Œå®ƒçš„æ ¹çš„<strong>ç½®æ¢å¯¹ç§°æ€§</strong>æ„æˆä¸€ä¸ªç¾¤ $\text{Gal}(p)$ï¼ˆGalois ç¾¤ï¼‰ã€‚</p>
      <ul>
        <li>$x^2 - 2 = 0$ï¼šæ ¹ä¸º $\pm\sqrt{2}$ï¼Œ$\text{Gal} = \mathbb{Z}_2$ï¼ˆäº¤æ¢ä¸¤ä¸ªæ ¹ï¼‰â†’ <strong>å¯è§£</strong></li>
        <li>$x^4 - 10x^2 + 1 = 0$ï¼š$\text{Gal} = D_4$ï¼ˆäºŒé¢ä½“ç¾¤ï¼‰â†’ <strong>å¯è§£</strong></li>
        <li>ä¸€èˆ¬äº”æ¬¡æ–¹ç¨‹ï¼š$\text{Gal} = S_5$ï¼ˆå¯¹ç§°ç¾¤ï¼‰â†’ <strong>ä¸å¯è§£</strong>ï¼ˆå› ä¸º $A_5$ æ˜¯å•ç¾¤ï¼‰</li>
      </ul>
      <p><strong>GDL è”ç³»</strong>ï¼šGalois çš„æ ¸å¿ƒæ´å¯Ÿâ€”â€”<em>ç†è§£ä¸€ä¸ªç³»ç»Ÿçš„å¯¹ç§°ç¾¤å°±ç†è§£äº†è¿™ä¸ªç³»ç»Ÿçš„æœ¬è´¨</em>â€”â€”æ­£æ˜¯ GDL è“å›¾çš„å“²å­¦åŸºç¡€ã€‚</p>
    </div>

    <h4 id="lie-klein">Lie ä¸ Kleinï¼šè¿ç»­å¯¹ç§°æ€§ä¸å‡ ä½•åˆ†ç±»</h4>

    <div class="bilingual">
      <div class="zh">
        <p>ä¸ç¾¤è®ºç›¸å…³çš„å¦å¤–ä¸¤ä¸ªåå­—æ˜¯ <strong>Sophus Lie</strong> å’Œ <strong>Felix Klein</strong>ï¼Œä»–ä»¬æ›¾åœ¨ä¸€æ®µæ—¶é—´å†…å¯†åˆ‡åˆä½œï¼ˆTobies, 2019ï¼‰ã€‚</p>
        <ul>
          <li><strong>Lie</strong> å‘å±•äº†<span class="term">è¿ç»­å¯¹ç§°æ€§</span>ç†è®ºâ€”â€”ä»Šå¤©ä»¥ä»–çš„åå­—å‘½åä¸º<strong>æç¾¤</strong>ï¼ˆLie Groupsï¼‰ã€‚æç¾¤æ˜¯åŒæ—¶å…·æœ‰ç¾¤ç»“æ„å’Œå…‰æ»‘æµå½¢ç»“æ„çš„æ•°å­¦å¯¹è±¡ï¼Œæ˜¯ç‰©ç†å­¦å’Œ GDL ä¸­ä¸å¯æˆ–ç¼ºçš„å·¥å…·ã€‚</li>
          <li><strong>Klein</strong> å®£ç§°ç¾¤è®ºæ˜¯å‡ ä½•å­¦çš„ç»„ç»‡åŸåˆ™â€”â€”è¿™å°±æ˜¯ä»–åœ¨ 1872 å¹´å‘è¡¨çš„<strong>Erlangen Program</strong>ã€‚</li>
        </ul>
      </div>
      <div class="en">
        Sophus Lie developed the theory of continuous symmetries (Lie Groups). Felix Klein proclaimed group theory to be the organising principle of geometry in his Erlangen Program.
      </div>
    </div>

    <div class="person-card">
      <div class="person-emoji">ğŸ“</div>
      <div class="person-info">
        <h4>Sophus Lie (1842-1899)</h4>
        <p>æŒªå¨æ•°å­¦å®¶ï¼Œåˆ›å»ºäº†<strong>æç¾¤ç†è®º</strong>â€”â€”å°† Galois çš„ç¦»æ•£å¯¹ç§°æ¨å¹¿åˆ°è¿ç»­å˜æ¢ã€‚ç‰©ç†å­¦ä¸­çš„å‡ ä¹æ‰€æœ‰å¯¹ç§°ç¾¤ï¼ˆæ—‹è½¬ SO(3)ã€æ´›ä¼¦å…¹ç¾¤ã€è§„èŒƒç¾¤ç­‰ï¼‰éƒ½æ˜¯æç¾¤ã€‚åœ¨ GDL ä¸­ï¼ŒSO(3)ã€SE(3)ã€E(n) ç­‰å˜ç½‘ç»œçš„æ•°å­¦åŸºç¡€éƒ½å»ºç«‹åœ¨ Lie çš„å·¥ä½œä¹‹ä¸Šã€‚</p>
      </div>
    </div>

    <h4 id="erlangen">Erlangen Program (1872)</h4>

    <div class="blueprint">
      <h4>ğŸ›ï¸ Klein's Erlangen Program â€” GDL çš„ç²¾ç¥æºå¤´</h4>
      <p>Klein çš„æ ¸å¿ƒå‘½é¢˜ï¼š<strong>æ¯ç§å‡ ä½•å­¦éƒ½å¯ä»¥ç”¨å…¶ä¸å˜é‡çš„å˜æ¢ç¾¤æ¥å®šä¹‰</strong>ã€‚</p>
      <table>
        <thead>
          <tr><th>å‡ ä½•å­¦</th><th>å˜æ¢ç¾¤</th><th>ä¸å˜é‡</th><th>GDL å¯¹åº”</th></tr>
        </thead>
        <tbody>
          <tr><td>æ¬§å‡ é‡Œå¾—å‡ ä½•</td><td>$E(d) = O(d) \ltimes T(d)$</td><td>è·ç¦»ã€è§’åº¦</td><td>E(n)-ç­‰å˜ GNN</td></tr>
          <tr><td>ä»¿å°„å‡ ä½•</td><td>$\text{Aff}(d) = GL(d) \ltimes T(d)$</td><td>å¹³è¡Œæ€§ã€é¢ç§¯æ¯”</td><td>ä»¿å°„ç­‰å˜ç½‘ç»œ</td></tr>
          <tr><td>å°„å½±å‡ ä½•</td><td>$PGL(d+1)$</td><td>äº¤æ¯”</td><td>é€è§†ä¸å˜CNN</td></tr>
          <tr><td>æ‹“æ‰‘å­¦</td><td>åŒèƒšç¾¤ $\text{Homeo}(\Omega)$</td><td>è¿é€šæ€§</td><td>æ‹“æ‰‘æ•°æ®åˆ†æ</td></tr>
        </tbody>
      </table>
      <p><strong>å±‚çº§å…³ç³»</strong>ï¼š$E(d) \subset \text{Aff}(d) \subset PGL(d+1) \subset \text{Homeo}(\Omega)$</p>
      <p>å˜æ¢ç¾¤è¶Šå¤§ â†’ ä¿æŒçš„ä¸å˜é‡è¶Šå°‘ â†’ å‡ ä½•ç»“æ„è¶Š"å¼±"ã€‚</p>
      <p><strong>é‡è¦æ³¨é‡Š</strong>ï¼šé»æ›¼å‡ ä½•è¢« Klein æ˜ç¡®æ’é™¤åœ¨ä»–çš„ç»Ÿä¸€å›¾æ™¯ä¹‹å¤–ã€‚ç›´åˆ°å¤§çº¦äº”åå¹´åï¼Œä¸»è¦å½’åŠŸäº <strong>Ã‰lie Cartan</strong> åœ¨ 1920 å¹´ä»£çš„å·¥ä½œï¼Œé»æ›¼å‡ ä½•æ‰è¢«æ•´åˆè¿›æ¥ã€‚è¿™å°±æ˜¯ Chapter 4.4ï¼ˆæµå½¢ï¼‰å’Œ 4.5ï¼ˆçº¤ç»´ä¸›/è§„èŒƒï¼‰çš„å†å²æ¥æºã€‚</p>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ ä» Erlangen Program åˆ° GDL è“å›¾</h4>
      <p>GDL è“å›¾å¯ä»¥çœ‹ä½œ Erlangen Program åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„ç°ä»£ç‰ˆæœ¬ï¼š</p>
      <div class="math-block">
        $$\text{Klein}: \quad \text{Geometry} \xrightarrow{\text{defined by}} \text{Symmetry Group } G$$
        $$\text{GDL}: \quad \text{Architecture} \xrightarrow{\text{defined by}} \text{Domain } \Omega + \text{Symmetry Group } G$$
      </div>
      <div class="math-explain">
        <p>Klein è¯´"å‡ ä½• = ç ”ç©¶åœ¨ç¾¤ $G$ ä¸‹ä¸å˜çš„æ€§è´¨"ã€‚GDL è¯´"å¥½çš„æ¶æ„ = åœ¨åŸŸ $\Omega$ å’Œç¾¤ $G$ ä¸‹ç­‰å˜/ä¸å˜çš„ç½‘ç»œ"ã€‚æ€æƒ³ä¸€è„‰ç›¸æ‰¿ã€‚</p>
      </div>
    </div>

    <h3 id="noether">Noether å®šç† (1918)</h3>

    <div class="person-card">
      <div class="person-emoji">âš¡</div>
      <div class="person-info">
        <h4>Emmy Noether (1882-1935)</h4>
        <p>Klein åœ¨å“¥å»·æ ¹çš„åŒäº‹ã€‚å¥¹è¯æ˜äº†ç‰©ç†å­¦ä¸­æœ€æ·±åˆ»çš„å®šç†ä¹‹ä¸€ï¼š<strong>ç‰©ç†ç³»ç»Ÿä½œç”¨é‡ï¼ˆactionï¼‰çš„æ¯ä¸€ä¸ªå¯å¾®å¯¹ç§°æ€§éƒ½å¯¹åº”ä¸€ä¸ªå®ˆæ’å¾‹</strong>ã€‚Nobel å¥–è·å¾—è€… Frank Wilczek ç§°ä¹‹ä¸º"20 ä¸–çºªå’Œ 21 ä¸–çºªç‰©ç†å­¦çš„æŒ‡å¯¼ä¹‹æ˜Ÿ"ã€‚</p>
      </div>
    </div>

    <div class="bilingual">
      <div class="zh">
        <p>åœ¨ç‰©ç†å­¦ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ªæƒŠäººçš„ç»“æœï¼šæ­¤å‰ï¼Œå‘ç°åŸºæœ¬å®šå¾‹ï¼ˆå¦‚èƒ½é‡å®ˆæ’ï¼‰éœ€è¦ meticulous çš„å®éªŒè§‚å¯Ÿï¼Œå³ä¾¿å¦‚æ­¤ï¼Œå®ƒä¹Ÿåªæ˜¯ä¸€ä¸ªæ²¡æœ‰æ¥æºçš„ç»éªŒç»“æœã€‚Noether å®šç†è¡¨æ˜ï¼Œ<strong>èƒ½é‡å®ˆæ’æ¥è‡ªäºæ—¶é—´çš„å¹³ç§»å¯¹ç§°æ€§</strong>â€”â€”ä¸€ä¸ªç›¸å½“ç›´è§‚çš„æƒ³æ³•ï¼šå®éªŒç»“æœä¸åº”è¯¥å–å†³äºå®ƒæ˜¯ä»Šå¤©è¿˜æ˜¯æ˜å¤©è¿›è¡Œçš„ã€‚</p>
      </div>
      <div class="en">
        Noether's Theorem showed that the conservation of energy emerges from the translational symmetry of time, a rather intuitive idea that the results of an experiment should not depend on whether it is conducted today or tomorrow.
      </div>
    </div>

    <h4 id="noether-deriv">ğŸ“ Noether å®šç†çš„æ¨å¯¼</h4>

    <div class="callout callout-math">
      <h4>Noether å®šç†ï¼šå¯¹ç§°æ€§ â†’ å®ˆæ’å¾‹</h4>
      <p><strong>è®¾ç½®</strong>ï¼šè€ƒè™‘ä¸€ä¸ªç‰©ç†ç³»ç»Ÿï¼Œå…¶åŠ¨åŠ›å­¦ç”±ä½œç”¨é‡ï¼ˆactionï¼‰æè¿°ï¼š</p>
      <div class="math-block">
        $$S[q] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt$$
        <div class="math-explain">
          $L(q, \dot{q}, t)$ æ˜¯æ‹‰æ ¼æœ—æ—¥é‡ï¼ˆLagrangianï¼‰ï¼Œ$q(t)$ æ˜¯å¹¿ä¹‰åæ ‡ï¼Œ$\dot{q}$ æ˜¯å¹¿ä¹‰é€Ÿåº¦ã€‚
        </div>
      </div>

      <p><strong>å‡è®¾</strong>ï¼šä½œç”¨é‡åœ¨æŸä¸ªè¿ç»­å˜æ¢ä¸‹ä¸å˜ï¼š$q \to q + \epsilon \delta q$</p>

      <div class="math-block">
        $$\delta S = 0 \implies \int_{t_1}^{t_2} \left[ \frac{\partial L}{\partial q} \delta q + \frac{\partial L}{\partial \dot{q}} \delta \dot{q} \right] dt = 0$$
      </div>

      <p>åˆ©ç”¨ Euler-Lagrange æ–¹ç¨‹ $\frac{\partial L}{\partial q} = \frac{d}{dt}\frac{\partial L}{\partial \dot{q}}$ å’Œåˆ†éƒ¨ç§¯åˆ†ï¼š</p>

      <div class="math-block">
        $$\delta S = \int_{t_1}^{t_2} \frac{d}{dt}\left[\frac{\partial L}{\partial \dot{q}} \delta q\right] dt = \left[\frac{\partial L}{\partial \dot{q}} \delta q\right]_{t_1}^{t_2} = 0$$
      </div>

      <p><strong>ç»“è®º</strong>ï¼šå®ˆæ’é‡ï¼ˆNoether è·ï¼‰ä¸ºï¼š</p>

      <div class="math-block">
        $$\boxed{Q = \frac{\partial L}{\partial \dot{q}} \delta q = \text{const}}$$
      </div>

      <table>
        <thead>
          <tr><th>å¯¹ç§°æ€§</th><th>å˜æ¢ $\delta q$</th><th>å®ˆæ’é‡ $Q$</th></tr>
        </thead>
        <tbody>
          <tr><td>æ—¶é—´å¹³ç§» $t \to t + \epsilon$</td><td>$\delta q = -\dot{q}\epsilon$</td><td>èƒ½é‡ $E = \dot{q}\frac{\partial L}{\partial \dot{q}} - L$</td></tr>
          <tr><td>ç©ºé—´å¹³ç§» $x \to x + \epsilon$</td><td>$\delta q = \epsilon$</td><td>åŠ¨é‡ $p = \frac{\partial L}{\partial \dot{q}}$</td></tr>
          <tr><td>æ—‹è½¬ $q \to Rq$</td><td>$\delta q = \omega \times q$</td><td>è§’åŠ¨é‡ $\mathbf{L} = q \times p$</td></tr>
          <tr><td>è§„èŒƒå˜æ¢ $\psi \to e^{i\alpha}\psi$</td><td>$\delta \psi = i\alpha\psi$</td><td>ç”µè· $Q_e$</td></tr>
        </tbody>
      </table>
    </div>

    <div class="callout callout-robot">
      <h4>ğŸ¤– PhysRobotï¼šNoether å®šç†çš„å®é™…æ„ä¹‰</h4>
      <p>å¦‚æœæˆ‘ä»¬çš„ç‰©ç†ä»¿çœŸç½‘ç»œæ˜¯ <strong>SE(3)-ç­‰å˜</strong> çš„ï¼ŒNoether å®šç†ä¿è¯å®ƒå­¦åˆ°çš„ç‰©ç†ä¼šè‡ªåŠ¨<strong>å®ˆæ’çº¿åŠ¨é‡å’Œè§’åŠ¨é‡</strong>ã€‚è¿™ä¸ä»…æ˜¯ç¾å­¦ä¸Šçš„ä¼˜åŠ¿ï¼š</p>
      <ul>
        <li><strong>èƒ½é‡å®ˆæ’</strong>ï¼ˆæ—¶é—´å¯¹ç§°ï¼‰â†’ é•¿æ—¶é—´ä»¿çœŸä¸ä¼š"çˆ†ç‚¸"æˆ–"å¡Œç¼©"</li>
        <li><strong>åŠ¨é‡å®ˆæ’</strong>ï¼ˆç©ºé—´å¯¹ç§°ï¼‰â†’ ç³»ç»Ÿè´¨å¿ƒçš„è¿åŠ¨æ˜¯ç‰©ç†æ­£ç¡®çš„</li>
        <li><strong>è§’åŠ¨é‡å®ˆæ’</strong>ï¼ˆæ—‹è½¬å¯¹ç§°ï¼‰â†’ åˆšä½“æ—‹è½¬è¡Œä¸ºæ­£ç¡®</li>
      </ul>
      <p>ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸ç­‰å˜çš„ç½‘ç»œå¿…é¡»ä»æ•°æ®ä¸­"å­¦ä¹ "è¿™äº›å®ˆæ’å¾‹ï¼Œåœ¨æœ‰é™æ•°æ®å’Œæœ‰é™è®­ç»ƒä¸‹å‡ ä¹ä¸å¯èƒ½å®Œç¾åšåˆ°ã€‚</p>
    </div>

    <h3 id="gauge-physics">è§„èŒƒç†è®º (Gauge Theory)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>ä¸ç”µè·å®ˆæ’ç›¸å…³çš„å¯¹ç§°æ€§æ˜¯ç”µç£åœºçš„<span class="term">å…¨å±€è§„èŒƒä¸å˜æ€§</span>ï¼ˆglobal gauge invarianceï¼‰ï¼Œè¿™é¦–æ¬¡å‡ºç°åœ¨ Maxwell çš„ç”µåŠ¨åŠ›å­¦å…¬å¼ä¸­ï¼ˆMaxwell, 1865ï¼‰ï¼›ç„¶è€Œï¼Œå®ƒçš„é‡è¦æ€§æœ€åˆå¹¶æœªè¢«æ³¨æ„åˆ°ã€‚</p>
        <p>æ­£æ˜¯å†™å‡º"å¯¹ç§°æ€§"å¦‚æ­¤ä¼˜ç¾å®šä¹‰çš„ <strong>Hermann Weyl</strong>ï¼Œåœ¨ 20 ä¸–çºªæ—©æœŸé¦–æ¬¡åœ¨ç‰©ç†å­¦ä¸­å¼•å…¥äº†<span class="term">è§„èŒƒä¸å˜æ€§</span>ï¼ˆgauge invarianceï¼‰çš„æ¦‚å¿µï¼Œå¼ºè°ƒå…¶ä½œä¸ºå¯ä»¥æ¨å¯¼å‡ºç”µç£å­¦çš„åŸç†ã€‚</p>
      </div>
      <div class="en">
        The same Hermann Weyl who wrote so dithyrambically about symmetry is the one who first introduced the concept of gauge invariance in physics in the early 20th century, emphasizing its role as a principle from which electromagnetism can be derived.
      </div>
    </div>

    <div class="callout callout-history">
      <h4>ğŸº "è§„èŒƒ"ä¸€è¯çš„è¶£å‘³èµ·æº</h4>
      <p>Weyl æœ€åˆï¼ˆ1919 å¹´ï¼‰é”™è¯¯åœ°çŒœæƒ³ç”µç£å­¦çš„å±€éƒ¨å¯¹ç§°æ€§æ˜¯å°ºåº¦ï¼ˆscaleï¼‰çš„ä¸å˜æ€§ã€‚"è§„èŒƒ"ï¼ˆgaugeï¼Œå¾·è¯­ <em>Eich</em>ï¼‰è¿™ä¸ªæœ¯è¯­æ˜¯ç±»æ¯”é“è·¯çš„å„ç§è½¨è·ï¼ˆtrack gaugesï¼‰è€Œé€‰æ‹©çš„ã€‚åœ¨é‡å­åŠ›å­¦å‘å±•ä¹‹åï¼ŒWeylï¼ˆ1929ï¼‰é€šè¿‡å°†å°ºåº¦å› å­æ›¿æ¢ä¸º<strong>æ³¢çš„ç›¸ä½å˜åŒ–</strong>æ¥ä¿®æ­£äº†è§„èŒƒé€‰æ‹©â€”â€”è¿™å°±æ˜¯æˆ‘ä»¬ä»Šå¤©ä½¿ç”¨çš„ U(1) è§„èŒƒç†è®ºã€‚</p>
    </div>

    <h4 id="standard-model">ä»è§„èŒƒä¸å˜åˆ°æ ‡å‡†æ¨¡å‹</h4>

    <div class="bilingual">
      <div class="zh">
        <p>ç»è¿‡å‡ åå¹´çš„å‘å±•ï¼ŒWeyl çš„è¿™ä¸ªåŸºæœ¬åŸç†â€”â€”ä»¥ <strong>Yang å’Œ Mills</strong>ï¼ˆ1954ï¼‰å‘å±•çš„æ¨å¹¿å½¢å¼â€”â€”æœ€ç»ˆæˆåŠŸåœ°æä¾›äº†æè¿°ç”µç£åŠ›ã€å¼±æ ¸åŠ›å’Œå¼ºæ ¸åŠ›çš„é‡å­åŠ›å­¦è¡Œä¸ºçš„ç»Ÿä¸€æ¡†æ¶ï¼Œæœ€ç»ˆå½¢æˆäº†æ•è·é™¤å¼•åŠ›å¤–æ‰€æœ‰åŸºæœ¬åŠ›çš„<span class="term">æ ‡å‡†æ¨¡å‹</span>ï¼ˆStandard Modelï¼‰ã€‚</p>
      </div>
      <div class="en">
        This fundamental principle proved successful in providing a unified framework to describe all fundamental forces but gravity, culminating in the Standard Model.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ æ ‡å‡†æ¨¡å‹çš„å¯¹ç§°ç¾¤</h4>
      <div class="math-block">
        $$G_{\text{SM}} = SU(3)_C \times SU(2)_L \times U(1)_Y$$
      </div>
      <table>
        <thead>
          <tr><th>åŠ›</th><th>è§„èŒƒç¾¤</th><th>ç»è‰²å­</th><th>GDL å¯¹åº”</th></tr>
        </thead>
        <tbody>
          <tr><td>ç”µç£åŠ›</td><td>$U(1)$</td><td>å…‰å­ $\gamma$</td><td>ç›¸ä½ç­‰å˜æ€§</td></tr>
          <tr><td>å¼±æ ¸åŠ›</td><td>$SU(2)$</td><td>$W^\pm, Z^0$</td><td>éé˜¿è´å°”è§„èŒƒ</td></tr>
          <tr><td>å¼ºæ ¸åŠ›</td><td>$SU(3)$</td><td>8 ä¸ªèƒ¶å­</td><td>çº¤ç»´ä¸›è¿ç»œ</td></tr>
        </tbody>
      </table>
      <div class="math-explain">
        <p>æ­£å¦‚ Nobel å¥–ç‰©ç†å­¦å®¶ Philip Andersonï¼ˆ1972ï¼‰æ‰€æ€»ç»“çš„ï¼š"è¯´ç‰©ç†å­¦å°±æ˜¯å¯¹ç§°æ€§çš„ç ”ç©¶ï¼Œè¿™åªæ˜¯ç¨å¾®å¤¸å¤§äº†äº‹å®ã€‚" (<em>"It is only slightly overstating the case to say that physics is the study of symmetry."</em>)</p>
        <p><strong>GDL ç±»æ¯”</strong>ï¼šæ ‡å‡†æ¨¡å‹ä¸­ä»å±€éƒ¨è§„èŒƒå¯¹ç§°æ¨å¯¼å‡ºåŠ›åœº â†” GDL ä¸­ä»åŸŸä¸Šçš„å¯¹ç§°ç¾¤æ¨å¯¼å‡ºç½‘ç»œæ¶æ„ã€‚Chapter 4.5 çš„è§„èŒƒç­‰å˜ CNN æ­£æ˜¯è¿™ä¸€ç‰©ç†æ€æƒ³çš„ç›´æ¥ä½“ç°ã€‚</p>
      </div>
    </div>

    <!-- ============================================================ -->
    <!-- 7.2 HARMONIC ANALYSIS -->
    <!-- ============================================================ -->
    <h2 id="sec7-2">7.2 è°ƒå’Œåˆ†æä¸ä¿¡å·å¤„ç†<br><span style="font-size:0.7em;color:var(--text-secondary)">Signal Processing and Harmonic Analysis</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>è‡ªä» CNN å–å¾—æ—©æœŸæˆåŠŸä»¥æ¥ï¼Œç ”ç©¶è€…ä»¬å°±å€ŸåŠ©<span class="term">è°ƒå’Œåˆ†æ</span>ï¼ˆharmonic analysisï¼‰ã€å›¾åƒå¤„ç†å’Œè®¡ç®—ç¥ç»ç§‘å­¦çš„å·¥å…·æ¥è¯•å›¾å»ºç«‹è§£é‡Š CNN é«˜æ•ˆæ€§çš„ç†è®ºæ¡†æ¶ã€‚</p>
      </div>
      <div class="en">
        Since the early successes of CNNs, researchers have resorted to tools from harmonic analysis, image processing, and computational neuroscience to provide a theoretical framework that explains their efficiency.
      </div>
    </div>

    <h3 id="fourier-history">Fourier çš„é—äº§</h3>

    <div class="bilingual">
      <div class="zh">
        <p>è°ƒå’Œåˆ†æçš„æ ¸å¿ƒæ€æƒ³â€”â€”å°†ä¿¡å·åˆ†è§£ä¸ºåŸºå‡½æ•°çš„çº¿æ€§ç»„åˆâ€”â€”å¯ä»¥è¿½æº¯åˆ° <strong>Joseph Fourier</strong>ï¼ˆ1807ï¼‰å¯¹çƒ­ä¼ å¯¼æ–¹ç¨‹çš„ç ”ç©¶ã€‚ä» Fourier çº§æ•°åˆ°ç°ä»£çš„ç¾¤ä¸Š Fourier åˆ†æï¼Œå…¶æ ¸å¿ƒæ€æƒ³ä¸€è„‰ç›¸æ‰¿ï¼š</p>
      </div>
      <div class="en">
        The core idea of harmonic analysis â€” decomposing signals into linear combinations of basis functions â€” traces back to Fourier's study of the heat equation.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ ä»ç»å…¸ Fourier åˆ°ç¾¤ Fourier å˜æ¢</h4>

      <p><strong>ç»å…¸ Fourier å˜æ¢</strong>ï¼ˆå¹³ç§»ç¾¤ $\mathbb{R}$ï¼‰ï¼š</p>
      <div class="math-block">
        $$\hat{f}(\omega) = \int_{-\infty}^{\infty} f(t) e^{-i\omega t} dt$$
        <div class="math-explain">åŸºå‡½æ•° $e^{i\omega t}$ æ˜¯å¹³ç§»ç¾¤çš„ä¸å¯çº¦è¡¨ç¤ºã€‚</div>
      </div>

      <p><strong>çƒè°å‡½æ•°</strong>ï¼ˆæ—‹è½¬ç¾¤ SO(3)ï¼‰ï¼š</p>
      <div class="math-block">
        $$f(\theta, \phi) = \sum_{\ell=0}^{\infty} \sum_{m=-\ell}^{\ell} \hat{f}_\ell^m Y_\ell^m(\theta, \phi)$$
        <div class="math-explain">$Y_\ell^m$ æ˜¯ SO(3) ä½œç”¨åœ¨ $S^2$ ä¸Šçš„ä¸å¯çº¦è¡¨ç¤ºã€‚è¿™æ˜¯ Chapter 4.3 çƒé¢ CNN çš„åŸºç¡€ã€‚</div>
      </div>

      <p><strong>å›¾ Fourier å˜æ¢</strong>ï¼ˆç½®æ¢ç¾¤ $\Sigma_n$ çš„è¿‘ä¼¼ï¼‰ï¼š</p>
      <div class="math-block">
        $$\hat{f}(\lambda_k) = \sum_{i=1}^{n} f(i) \, u_k(i), \quad k = 0, \ldots, n-1$$
        <div class="math-explain">$u_k$ æ˜¯å›¾ Laplacian $\mathbf{L}$ çš„ç‰¹å¾å‘é‡ï¼Œ$\lambda_k$ æ˜¯å¯¹åº”ç‰¹å¾å€¼ã€‚</div>
      </div>

      <p><strong>Peter-Weyl å®šç†</strong>ï¼ˆç´§è‡´ç¾¤ $G$ï¼‰ï¼š</p>
      <div class="math-block">
        $$f(g) = \sum_{\rho \in \hat{G}} d_\rho \, \text{tr}\left[\hat{f}(\rho) \, \rho(g)\right]$$
        <div class="math-explain">$\hat{G}$ æ˜¯ç¾¤ $G$ çš„æ‰€æœ‰ä¸å¯çº¦è¡¨ç¤ºçš„é›†åˆã€‚è¿™æ˜¯æœ€ä¸€èˆ¬çš„å½¢å¼ï¼Œä¸Šé¢æ‰€æœ‰ Fourier å˜æ¢éƒ½æ˜¯å…¶ç‰¹ä¾‹ã€‚</div>
      </div>
    </div>

    <h3 id="m-theory">M-theory ä¸è§†è§‰çš®å±‚æ¨¡å‹</h3>

    <div class="bilingual">
      <div class="zh">
        <p><span class="term">M-theory</span> æ˜¯ä¸€ä¸ªå—è§†è§‰çš®å±‚å¯å‘çš„æ¡†æ¶ï¼Œç”± <strong>Tomaso Poggio</strong> åŠå…¶åˆä½œè€…é¦–åˆ›ï¼ˆRiesenhuber and Poggio, 1999; Serre et al., 2007ï¼‰ï¼ŒåŸºäºå¯ä»¥åœ¨æŸäº›å¯¹ç§°ç¾¤ä¸‹æ“çºµçš„<strong>æ¨¡æ¿</strong>ï¼ˆtemplatesï¼‰æ¦‚å¿µã€‚å…¶å±‚æ¬¡åŒ–ç»“æ„â€”â€”ç®€å•ç»†èƒæ£€æµ‹ç‰¹å¾ï¼Œå¤æ‚ç»†èƒæ± åŒ–ä»¥è·å¾—ä¸å˜æ€§â€”â€”ç›´æ¥é¢„ç¤ºäº†ç°ä»£ CNN çš„è®¾è®¡ã€‚</p>
      </div>
      <div class="en">
        M-theory is a framework inspired by the visual cortex, based on the notion of templates that can be manipulated under certain symmetry groups.
      </div>
    </div>

    <h3 id="steerable">å¯æ§é‡‘å­—å¡” (Steerable Pyramids)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¦ä¸€ä¸ªæºäºè®¡ç®—ç¥ç»ç§‘å­¦çš„è‘—åæ¨¡å‹æ˜¯<span class="term">å¯æ§é‡‘å­—å¡”</span>ï¼ˆsteerable pyramidsï¼‰ï¼Œç”± <strong>Simoncelli å’Œ Freeman</strong>ï¼ˆ1995ï¼‰å¼€å‘ï¼Œè¿™æ˜¯ä¸€ç§å¤šå°ºåº¦å°æ³¢åˆ†è§£ï¼Œå¯¹æŸäº›è¾“å…¥å˜æ¢å…·æœ‰è‰¯å¥½çš„æ€§è´¨ã€‚å®ƒä»¬æ˜¯æ—©æœŸçº¹ç†ç”Ÿæˆæ¨¡å‹ï¼ˆPortilla and Simoncelli, 2000ï¼‰çš„æ ¸å¿ƒå…ƒç´ ï¼Œåæ¥è¿™äº›æ¨¡å‹é€šè¿‡ç”¨æ·±åº¦ CNN ç‰¹å¾æ›¿æ¢å¯æ§å°æ³¢ç‰¹å¾è€Œå¾—åˆ°æ”¹è¿›ï¼ˆGatys et al., 2015ï¼‰ã€‚</p>
        <p><strong>GDL è”ç³»</strong>ï¼šå¯æ§é‡‘å­—å¡” â†’ å¯æ§æ»¤æ³¢å™¨ï¼ˆsteerable filtersï¼‰â†’ å¯æ§ CNNï¼ˆCohen and Welling, 2016ï¼‰â†’ ç¾¤ç­‰å˜ CNNã€‚"å¯æ§æ€§"(steerability) æ„å‘³ç€æ»¤æ³¢å™¨åœ¨æ—‹è½¬ä¸‹å¯ä»¥ç”¨æœ‰é™åŸºæ¥è¡¨ç¤ºâ€”â€”è¿™æ­£æ˜¯ Chapter 5 ä¸­ç­‰å˜æ¶æ„çš„æ ¸å¿ƒæ€æƒ³ã€‚</p>
      </div>
      <div class="en">
        Steerable pyramids â€” multiscale wavelet decompositions with favorable properties against input transformations â€” were a central element in early generative models for textures.
      </div>
    </div>

    <h3 id="scattering">æ•£å°„å˜æ¢ (Scattering Transforms)</h3>

    <div class="bilingual">
      <div class="zh">
        <p><span class="term">æ•£å°„å˜æ¢</span>ï¼ˆScattering Transformsï¼‰ç”± <strong>StÃ©phane Mallat</strong>ï¼ˆ2012ï¼‰å¼•å…¥å¹¶ç”± <strong>Bruna å’Œ Mallat</strong>ï¼ˆ2013ï¼‰å‘å±•ï¼Œæä¾›äº†ä¸€ä¸ªç†è§£ CNN çš„æ¡†æ¶â€”â€”é€šè¿‡ç”¨å¤šå°ºåº¦å°æ³¢åˆ†è§£æ›¿æ¢å¯è®­ç»ƒæ»¤æ³¢å™¨ï¼ŒåŒæ—¶å±•ç¤ºäº†<strong>å½¢å˜ç¨³å®šæ€§</strong>ï¼ˆdeformation stabilityï¼‰å’Œæ¶æ„ä¸­<strong>æ·±åº¦</strong>çš„ä½œç”¨ã€‚</p>
      </div>
      <div class="en">
        Scattering transforms, introduced by Mallat (2012), provided a framework to understand CNNs by replacing trainable filters with multiscale wavelet decompositions, showcasing deformation stability and the role of depth.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ æ•£å°„å˜æ¢çš„æ•°å­¦æ¡†æ¶</h4>
      <p>æ•£å°„å˜æ¢å¯ä»¥çœ‹ä½œä¸€ä¸ª"å›ºå®šæƒé‡çš„ CNN"ï¼š</p>

      <div class="math-block">
        <p><strong>ç¬¬ä¸€å±‚</strong>ï¼ˆç±»æ¯” CNN ç¬¬ä¸€å±‚å·ç§¯ + ReLUï¼‰ï¼š</p>
        $$S_1[j, \theta] f = |f * \psi_{j,\theta}|$$
        <div class="math-explain">
          $\psi_{j,\theta}$ æ˜¯å°ºåº¦ $j$ã€æ–¹å‘ $\theta$ çš„å°æ³¢ï¼Œ$|\cdot|$ æ˜¯æ¨¡ï¼ˆéçº¿æ€§ï¼Œç±»æ¯” ReLUï¼‰ã€‚
        </div>
      </div>

      <div class="math-block">
        <p><strong>ç¬¬äºŒå±‚</strong>ï¼ˆæ¢å¤ç¬¬ä¸€å±‚éçº¿æ€§ä¸¢å¤±çš„ä¿¡æ¯ï¼‰ï¼š</p>
        $$S_2[j_1, \theta_1, j_2, \theta_2] f = ||f * \psi_{j_1,\theta_1}| * \psi_{j_2,\theta_2}|$$
      </div>

      <div class="math-block">
        <p><strong>æœ€ç»ˆè¾“å‡º</strong>ï¼ˆå¯¹æ¯å±‚åšä½é€šæ»¤æ³¢è·å¾—å¹³ç§»ä¸å˜ç‰¹å¾ï¼‰ï¼š</p>
        $$\overline{S}_m f = S_m f * \phi_J$$
        <div class="math-explain">
          $\phi_J$ æ˜¯å°ºåº¦ $J$ çš„ä½é€šæ»¤æ³¢å™¨ï¼ˆç±»æ¯” CNN çš„å…¨å±€æ± åŒ–ï¼‰ã€‚
        </div>
      </div>

      <p><strong>å…³é”®æ€§è´¨</strong>ï¼š</p>
      <ul>
        <li><strong>å¹³ç§»ä¸å˜æ€§</strong>ï¼š$\overline{S}_m(T_c f) = \overline{S}_m f + O(2^{-J})$</li>
        <li><strong>å½¢å˜ç¨³å®šæ€§ï¼ˆLipschitzï¼‰</strong>ï¼š$\|\overline{S} f - \overline{S} (f \circ \tau)\| \leq C \|\nabla \tau\|_\infty \|f\|$</li>
        <li><strong>èƒ½é‡å®ˆæ’</strong>ï¼š$\sum_{m=0}^{\infty} \|\overline{S}_m f\|^2 = \|f\|^2$</li>
      </ul>
    </div>

    <h4 id="code-scattering">ğŸ’» ä»£ç ï¼šæ•£å°„å˜æ¢ä¸ CNN çš„å¯¹æ¯”</h4>

    <div class="code-container">
      <div class="code-header">
        <span>Python â€” æ•£å°„å˜æ¢ vs CNN ç‰¹å¾æå–</span>
        <button class="copy-btn" onclick="copyCode(this)">å¤åˆ¶</button>
      </div>
<pre><code><span style="color:var(--code-comment)"># æ•£å°„å˜æ¢ vs CNNï¼šç†è§£å›ºå®šæ»¤æ³¢å™¨ä¸å¯å­¦ä¹ æ»¤æ³¢å™¨</span>
<span style="color:var(--code-keyword)">import</span> numpy <span style="color:var(--code-keyword)">as</span> np
<span style="color:var(--code-keyword)">import</span> torch
<span style="color:var(--code-keyword)">import</span> torch.nn <span style="color:var(--code-keyword)">as</span> nn

<span style="color:var(--code-comment)"># === 1. ç®€åŒ–çš„ 1D æ•£å°„å˜æ¢ ===</span>
<span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">morlet_wavelet</span>(t, scale, freq=<span style="color:var(--code-number)">5.0</span>):
    <span style="color:var(--code-string)">"""Morlet å°æ³¢ï¼šÏˆ(t) = exp(-tÂ²/2) * exp(iÏ‰t)"""</span>
    t_scaled = t / scale
    envelope = np.exp(-t_scaled**<span style="color:var(--code-number)">2</span> / <span style="color:var(--code-number)">2</span>)
    oscillation = np.exp(<span style="color:var(--code-number)">1j</span> * freq * t_scaled)
    <span style="color:var(--code-keyword)">return</span> envelope * oscillation / np.sqrt(scale)

<span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">scattering_layer</span>(signal, scales):
    <span style="color:var(--code-string)">"""å•å±‚æ•£å°„å˜æ¢ï¼š|signal * Ïˆ_j| for each scale j"""</span>
    t = np.linspace(-<span style="color:var(--code-number)">5</span>, <span style="color:var(--code-number)">5</span>, len(signal))
    outputs = []
    <span style="color:var(--code-keyword)">for</span> s <span style="color:var(--code-keyword)">in</span> scales:
        psi = morlet_wavelet(t, s)
        <span style="color:var(--code-comment)"># å·ç§¯ + å–æ¨¡ï¼ˆéçº¿æ€§ï¼‰</span>
        conv = np.abs(np.convolve(signal, np.real(psi), mode=<span style="color:var(--code-string)">'same'</span>))
        outputs.append(conv)
    <span style="color:var(--code-keyword)">return</span> np.stack(outputs)

<span style="color:var(--code-comment)"># ä¸¤å±‚æ•£å°„</span>
signal = np.random.randn(<span style="color:var(--code-number)">256</span>)
scales = [<span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">2</span>, <span style="color:var(--code-number)">4</span>, <span style="color:var(--code-number)">8</span>]
S1 = scattering_layer(signal, scales)       <span style="color:var(--code-comment)"># [4, 256]</span>
S2 = np.stack([scattering_layer(S1[j], scales) <span style="color:var(--code-keyword)">for</span> j <span style="color:var(--code-keyword)">in</span> range(len(scales))])  <span style="color:var(--code-comment)"># [4, 4, 256]</span>

<span style="color:var(--code-comment)"># ä½é€šæ»¤æ³¢è·å¾—å¹³ç§»ä¸å˜ç‰¹å¾</span>
<span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">lowpass_pool</span>(x, J=<span style="color:var(--code-number)">16</span>):
    <span style="color:var(--code-string)">"""å…¨å±€ä½é€šï¼šç±»æ¯” CNN çš„ global average pooling"""</span>
    <span style="color:var(--code-keyword)">return</span> np.mean(x.reshape(*x.shape[:-<span style="color:var(--code-number)">1</span>], -<span style="color:var(--code-number)">1</span>, J), axis=-<span style="color:var(--code-number)">1</span>)

S0_bar = lowpass_pool(signal[None, :])  <span style="color:var(--code-comment)"># é›¶é˜¶æ•£å°„ç³»æ•°</span>
S1_bar = lowpass_pool(S1)                <span style="color:var(--code-comment)"># ä¸€é˜¶æ•£å°„ç³»æ•°</span>
S2_bar = lowpass_pool(S2.reshape(-<span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">256</span>))  <span style="color:var(--code-comment)"># äºŒé˜¶æ•£å°„ç³»æ•°</span>

print(f<span style="color:var(--code-string)">"æ•£å°„ç‰¹å¾ç»´åº¦: S0={S0_bar.shape}, S1={S1_bar.shape}, S2={S2_bar.shape}"</span>)
print(f<span style="color:var(--code-string)">"å…³é”®åŒºåˆ«: æ•£å°„å˜æ¢çš„'æ»¤æ³¢å™¨'(å°æ³¢)æ˜¯å›ºå®šçš„, ä¸éœ€è¦è®­ç»ƒ!"</span>)

<span style="color:var(--code-comment)"># === 2. å¯¹æ¯”ï¼šç­‰ä»·çš„ CNN ç»“æ„ ===</span>
<span style="color:var(--code-keyword)">class</span> <span style="color:var(--code-function)">SimpleCNN1D</span>(nn.Module):
    <span style="color:var(--code-string)">"""å¯¹æ ‡æ•£å°„å˜æ¢çš„ä¸¤å±‚ CNN"""</span>
    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">__init__</span>(self, n_scales=<span style="color:var(--code-number)">4</span>):
        super().__init__()
        <span style="color:var(--code-comment)"># å¯¹åº”æ•£å°„çš„ç¬¬ä¸€å±‚ï¼šå¯å­¦ä¹ æ»¤æ³¢å™¨</span>
        self.conv1 = nn.Conv1d(<span style="color:var(--code-number)">1</span>, n_scales, kernel_size=<span style="color:var(--code-number)">11</span>, padding=<span style="color:var(--code-number)">5</span>)
        <span style="color:var(--code-comment)"># å¯¹åº”æ•£å°„çš„ç¬¬äºŒå±‚</span>
        self.conv2 = nn.Conv1d(n_scales, n_scales**<span style="color:var(--code-number)">2</span>, kernel_size=<span style="color:var(--code-number)">11</span>, padding=<span style="color:var(--code-number)">5</span>)
        <span style="color:var(--code-comment)"># éçº¿æ€§: ReLU ä»£æ›¿å–æ¨¡</span>
        self.relu = nn.ReLU()
        <span style="color:var(--code-comment)"># æ± åŒ–: ç±»æ¯”æ•£å°„çš„ä½é€šæ»¤æ³¢</span>
        self.pool = nn.AdaptiveAvgPool1d(<span style="color:var(--code-number)">16</span>)

    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">forward</span>(self, x):
        h1 = self.relu(self.conv1(x))   <span style="color:var(--code-comment)"># [B, 4, L]  â† ç¬¬ä¸€å±‚</span>
        h2 = self.relu(self.conv2(h1))  <span style="color:var(--code-comment)"># [B, 16, L] â† ç¬¬äºŒå±‚</span>
        <span style="color:var(--code-keyword)">return</span> self.pool(h2)             <span style="color:var(--code-comment)"># [B, 16, 16] â† æ± åŒ–</span>

model = SimpleCNN1D()
x = torch.randn(<span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">256</span>)
out = model(x)
print(f<span style="color:var(--code-string)">"CNN è¾“å‡º: {out.shape}"</span>)
print(f<span style="color:var(--code-string)">"CNN æœ‰ {sum(p.numel() for p in model.parameters())} ä¸ªå¯è®­ç»ƒå‚æ•°"</span>)
print(f<span style="color:var(--code-string)">"æ•£å°„å˜æ¢æœ‰ 0 ä¸ªå¯è®­ç»ƒå‚æ•°ï¼ˆå…¨éƒ¨å›ºå®šå°æ³¢ï¼‰"</span>)
</code></pre>
    </div>

    <h3 id="gsp-history">å›¾ä¿¡å·å¤„ç† (Graph Signal Processing)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¦ä¸€ç±»é‡è¦çš„å›¾ç¥ç»ç½‘ç»œâ€”â€”é€šå¸¸è¢«ç§°ä¸º<span class="term">è°±åŸŸ</span>ï¼ˆspectralï¼‰æ–¹æ³•â€”â€”æºäºæœ¬ä¹¦ä½œè€…ä¹‹ä¸€ï¼ˆBruna et al., 2013ï¼‰çš„å·¥ä½œï¼Œä½¿ç”¨äº†<span class="term">å›¾ Fourier å˜æ¢</span>ï¼ˆGraph Fourier Transformï¼‰çš„æ¦‚å¿µã€‚</p>
        <p>è¿™ä¸€æ„é€ çš„æ ¹æºåœ¨ä¿¡å·å¤„ç†å’Œè®¡ç®—è°ƒå’Œåˆ†æç¤¾åŒºï¼Œå…¶ä¸­å¤„ç†éæ¬§å‡ é‡Œå¾—ä¿¡å·åœ¨ 2000 å¹´ä»£åæœŸå’Œ 2010 å¹´ä»£åˆæœŸå˜å¾—çªå‡ºã€‚æ¥è‡ª <strong>Pierre Vandergheynst</strong>ï¼ˆShuman et al., 2013ï¼‰å’Œ <strong>JosÃ© Moura</strong>ï¼ˆSandryhaila and Moura, 2013ï¼‰å›¢é˜Ÿçš„æœ‰å½±å“åŠ›çš„è®ºæ–‡æ¨å¹¿äº†"å›¾ä¿¡å·å¤„ç†"ï¼ˆGSPï¼‰çš„æ¦‚å¿µä»¥åŠåŸºäºå›¾é‚»æ¥çŸ©é˜µå’Œ Laplacian çŸ©é˜µçš„ç‰¹å¾å‘é‡çš„å¹¿ä¹‰ Fourier å˜æ¢ã€‚</p>
      </div>
      <div class="en">
        The roots of spectral GNNs are in the signal processing community, where dealing with non-Euclidean signals became prominent in the late 2000s and early 2010s.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ ä»ç»å…¸ Fourier åˆ°å›¾ Fourier</h4>
      <div class="compare-grid">
        <div>
          <h4>ç»å…¸ä¿¡å·å¤„ç†</h4>
          <p>åŸŸï¼š$\mathbb{R}^d$ï¼ˆæ¬§å‡ é‡Œå¾—ç©ºé—´ï¼‰</p>
          <p>ç®—å­ï¼šLaplacian $\nabla^2$</p>
          <p>ç‰¹å¾å‡½æ•°ï¼š$e^{i\omega \cdot x}$</p>
          <p>å˜æ¢ï¼š$\hat{f}(\omega) = \int f(x) e^{-i\omega \cdot x} dx$</p>
          <p>å·ç§¯ï¼š$f * g = \mathcal{F}^{-1}[\hat{f} \cdot \hat{g}]$</p>
        </div>
        <div>
          <h4>å›¾ä¿¡å·å¤„ç†</h4>
          <p>åŸŸï¼šå›¾ $\mathcal{G} = (V, E)$</p>
          <p>ç®—å­ï¼šå›¾ Laplacian $\mathbf{L}$</p>
          <p>ç‰¹å¾å‘é‡ï¼š$\mathbf{L} \mathbf{u}_k = \lambda_k \mathbf{u}_k$</p>
          <p>å˜æ¢ï¼š$\hat{f}(\lambda_k) = \langle f, \mathbf{u}_k \rangle$</p>
          <p>å·ç§¯ï¼š$f *_{\mathcal{G}} g = \mathbf{U} \text{diag}(\hat{g}) \mathbf{U}^T f$</p>
        </div>
      </div>
    </div>

    <h3 id="computer-graphics">è®¡ç®—æœºå›¾å½¢å­¦ä¸å‡ ä½•å¤„ç†</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨è®¡ç®—æœºå›¾å½¢å­¦å’Œå‡ ä½•å¤„ç†é¢†åŸŸï¼Œ<strong>éæ¬§å‡ é‡Œå¾—è°ƒå’Œåˆ†ææ¯”å›¾ä¿¡å·å¤„ç†è‡³å°‘æ—©äº†åå¹´</strong>ã€‚æˆ‘ä»¬å¯ä»¥è¿½æº¯æµå½¢å’Œç½‘æ ¼ä¸Šçš„è°±æ»¤æ³¢å™¨åˆ° <strong>Taubin et al.</strong>ï¼ˆ1996ï¼‰çš„å·¥ä½œã€‚è¿™äº›æ–¹æ³•åœ¨ 2000 å¹´ä»£æˆä¸ºä¸»æµï¼Œéšåæ˜¯ <strong>Karni å’Œ Gotsman</strong>ï¼ˆ2000ï¼‰å…³äºè°±å‡ ä½•å‹ç¼©çš„æœ‰å½±å“åŠ›è®ºæ–‡ä»¥åŠ <strong>LÃ©vy</strong>ï¼ˆ2006ï¼‰å…³äºä½¿ç”¨ Laplacian ç‰¹å¾å‘é‡ä½œä¸ºéæ¬§å‡ é‡Œå¾— Fourier åŸºçš„è®ºæ–‡ã€‚</p>
        <p>è°±æ–¹æ³•å·²è¢«ç”¨äºä¸€ç³»åˆ—åº”ç”¨ï¼Œæœ€çªå‡ºçš„æ˜¯å½¢çŠ¶æè¿°å­ï¼ˆSun et al., 2009ï¼‰å’Œ<span class="term">å‡½æ•°æ˜ å°„</span>ï¼ˆFunctional Maps, Ovsjanikov et al., 2012ï¼‰ã€‚</p>
      </div>
      <div class="en">
        Non-Euclidean harmonic analysis in computer graphics predates Graph Signal Processing by at least a decade. Spectral methods on manifolds trace back to Taubin et al. (1996).
      </div>
    </div>

    <div class="callout callout-history">
      <h4>ğŸº "åŒèƒèƒå…„å¼Ÿ"è¶£äº‹</h4>
      <p>ä¹¦ä¸­æåˆ°ï¼šä¸è°±å›¾ CNN ç±»ä¼¼çš„å¯å­¦ä¹ å½¢çŠ¶æè¿°å­ç”± <strong>Roee Litman</strong> å’Œ <strong>Alex Bronstein</strong>ï¼ˆ2013ï¼‰æå‡ºï¼Œåè€…æ˜¯æœ¬ä¹¦ä½œè€…ï¼ˆMichael Bronsteinï¼‰çš„<strong>åŒèƒèƒå…„å¼Ÿ</strong>ã€‚GDL ç¡®å®æ˜¯ä¸€ä¸ª"å®¶æ—äº‹ä¸š"ï¼</p>
    </div>

    <h4>ç½‘æ ¼ä¸Šçš„æ·±åº¦å­¦ä¹ å…ˆé©±</h4>

    <div class="bilingual">
      <div class="zh">
        <p>åŸºäºå†…åœ¨åº¦é‡ä¸å˜é‡çš„å½¢çŠ¶åˆ†ææ¨¡å‹ç”±è®¡ç®—æœºå›¾å½¢å­¦é¢†åŸŸçš„å¤šä½ä½œè€…å¼•å…¥ï¼ˆElad and Kimmel, 2003; MÃ©moli and Sapiro, 2005; Bronstein et al., 2006ï¼‰ã€‚ç¬¬ä¸€ä¸ªç”¨äºç½‘æ ¼æ·±åº¦å­¦ä¹ çš„æ¶æ„â€”â€”<span class="term">Geodesic CNN</span>â€”â€”ç”±æœ¬ä¹¦ä½œè€…ä¹‹ä¸€çš„å›¢é˜Ÿå¼€å‘ï¼ˆMasci et al., 2015ï¼‰ï¼Œä½¿ç”¨åº”ç”¨äºæµ‹åœ°çº¿å¾„å‘ patch çš„å±€éƒ¨å…±äº«æƒé‡æ»¤æ³¢å™¨ã€‚</p>
        <p>å®ƒæ˜¯åæ¥ç”±å¦ä¸€ä½ä½œè€…ï¼ˆCohen et al., 2019ï¼‰å¼€å‘çš„<strong>è§„èŒƒç­‰å˜ CNN</strong> çš„ç‰¹ä¾‹ã€‚Geodesic CNN çš„ä¸€ä¸ªæ¨å¹¿â€”â€”<span class="term">MoNet</span>ï¼ˆMonti et al., 2017ï¼‰â€”â€”ä½¿ç”¨äº†æ³¨æ„åŠ›ç±»ä¼¼çš„æœºåˆ¶å¯¹ç½‘æ ¼çš„å±€éƒ¨ç»“æ„ç‰¹å¾è¿›è¡Œæ“ä½œï¼Œä¹Ÿå¯ä»¥åœ¨ä¸€èˆ¬å›¾ä¸Šå·¥ä½œã€‚</p>
      </div>
      <div class="en">
        Geodesic CNNs (Masci et al., 2015) were the first deep learning architecture on meshes. MoNet (Monti et al., 2017) generalized it with an attention-like mechanism.
      </div>
    </div>

    <!-- ============================================================ -->
    <!-- 7.3 EARLY ML SYMMETRY -->
    <!-- ============================================================ -->
    <h2 id="sec7-3">7.3 æ—©æœŸæœºå™¨å­¦ä¹ ä¸­çš„å¯¹ç§°æ€§<br><span style="font-size:0.7em;color:var(--text-secondary)">Early Use of Symmetry in Machine Learning</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>åœ¨æœºå™¨å­¦ä¹ åŠå…¶åœ¨æ¨¡å¼è¯†åˆ«å’Œè®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ä¸­ï¼Œå¯¹ç§°æ€§çš„é‡è¦æ€§æ—©å·²è¢«è®¤è¯†åˆ°ã€‚è®¾è®¡ç­‰å˜ç‰¹å¾æ£€æµ‹å™¨çš„æ—©æœŸå·¥ä½œç”± <strong>Amari</strong>ï¼ˆ1978ï¼‰ã€<strong>Kanatani</strong>ï¼ˆ2012ï¼‰å’Œ <strong>Lenz</strong>ï¼ˆ1990ï¼‰å®Œæˆã€‚</p>
      </div>
      <div class="en">
        Early work on designing equivariant feature detectors for pattern recognition was done by Amari (1978), Kanatani (2012), and Lenz (1990).
      </div>
    </div>

    <div class="callout callout-history">
      <h4>ğŸº Shun'ichi Amari ä¸ä¿¡æ¯å‡ ä½•</h4>
      <p><strong>Shun'ichi Amari</strong> è¢«è®¤ä¸ºæ˜¯<strong>ä¿¡æ¯å‡ ä½•</strong>ï¼ˆinformation geometryï¼‰é¢†åŸŸçš„åˆ›å§‹äººï¼Œè¯¥é¢†åŸŸå°†é»æ›¼å‡ ä½•æ¨¡å‹åº”ç”¨äºæ¦‚ç‡åˆ†å¸ƒã€‚å…¶ä¸»è¦ç ”ç©¶å¯¹è±¡æ˜¯<span class="term">ç»Ÿè®¡æµå½¢</span>ï¼ˆstatistical manifoldï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªç‚¹å¯¹åº”ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚ä¿¡æ¯å‡ ä½•è‡³ä»Šä»æ˜¯æœºå™¨å­¦ä¹ ç†è®ºçš„é‡è¦åˆ†æ”¯â€”â€”ä¾‹å¦‚è‡ªç„¶æ¢¯åº¦ä¸‹é™æ³•å°±æ¥è‡ªä¿¡æ¯å‡ ä½•ã€‚</p>
    </div>

    <h3 id="invariance-theorem">ç¾¤ä¸å˜æ€§å®šç† (Group Invariance Theorem)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>åœ¨ç¥ç»ç½‘ç»œæ–‡çŒ®ä¸­ï¼Œ<strong>Minsky å’Œ Papert</strong>ï¼ˆ2017, åŸç‰ˆ 1969ï¼‰çš„ã€ŠPerceptronsã€‹ä¸€ä¹¦ä¸­è‘—åçš„<span class="term">æ„ŸçŸ¥æœºçš„ç¾¤ä¸å˜æ€§å®šç†</span>ï¼ˆGroup Invariance Theorem for Perceptronsï¼‰ä¸ºï¼ˆå•å±‚ï¼‰æ„ŸçŸ¥æœºå­¦ä¹ ä¸å˜é‡çš„èƒ½åŠ›è®¾å®šäº†æ ¹æœ¬é™åˆ¶ã€‚</p>
        <p>è¿™æ˜¯ç ”ç©¶å¤šå±‚æ¶æ„çš„ä¸»è¦åŠ¨æœºä¹‹ä¸€ï¼ˆSejnowski et al., 1986; Shawe-Taylor, 1989, 1993ï¼‰ï¼Œæœ€ç»ˆå¯¼è‡´äº†æ·±åº¦å­¦ä¹ çš„å‘å±•ã€‚</p>
      </div>
      <div class="en">
        The Group Invariance Theorem puts fundamental limitations on the capabilities of single-layer perceptrons to learn invariants. This was a primary motivation for studying multi-layer architectures.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ ç¾¤ä¸å˜æ€§å®šç† (Minsky & Papert, 1969)</h4>
      <p><strong>å®šç†</strong>ï¼šè®¾ $G$ æ˜¯ä½œç”¨åœ¨è¾“å…¥ç©ºé—´ $\mathcal{X}$ ä¸Šçš„ç¾¤ã€‚å¦‚æœä¸€ä¸ªå•å±‚æ„ŸçŸ¥æœºï¼ˆçº¿æ€§åˆ†ç±»å™¨ï¼‰$f(x) = \text{sign}(\mathbf{w}^T x + b)$ å¯¹ $G$ ä¸å˜ï¼Œå³ $f(gx) = f(x), \; \forall g \in G$ï¼Œé‚£ä¹ˆ $\mathbf{w}$ å¿…é¡»æ»¡è¶³ï¼š</p>
      <div class="math-block">
        $$\rho(g)^T \mathbf{w} = \mathbf{w}, \quad \forall g \in G$$
        <div class="math-explain">
          å…¶ä¸­ $\rho(g)$ æ˜¯ $G$ åœ¨è¾“å…¥ç©ºé—´ä¸Šçš„è¡¨ç¤ºã€‚è¿™æ„å‘³ç€ $\mathbf{w}$ å¿…é¡»åœ¨ $G$ çš„ä¸å˜å­ç©ºé—´ä¸­ã€‚å¯¹äº"å¤§"çš„ç¾¤ï¼ˆå¦‚æ—‹è½¬ç¾¤ï¼‰ï¼Œä¸å˜å­ç©ºé—´å¯èƒ½éå¸¸å°ï¼ˆç”šè‡³åªæœ‰é›¶å‘é‡ï¼‰ï¼Œä½¿å¾—æ„ŸçŸ¥æœºå®Œå…¨æ— æ³•å­¦ä¹ æœ‰æ„ä¹‰çš„ä¸å˜ç‰¹å¾ã€‚
        </div>
      </div>
      <p><strong>æ¨è®º</strong>ï¼šè¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦<strong>å¤šå±‚</strong>ç½‘ç»œâ€”â€”ä¸­é—´å±‚å¯ä»¥è®¡ç®—ç­‰å˜ç‰¹å¾ï¼ˆè€Œéä¸å˜ï¼‰ï¼Œåªåœ¨æœ€åä¸€å±‚æ–½åŠ ä¸å˜æ€§ï¼ˆå¦‚å…¨å±€æ± åŒ–ï¼‰ã€‚è¿™æ­£æ˜¯ GDL è“å›¾ä¸­å…ˆç­‰å˜ã€æœ€åä¸å˜çš„è®¾è®¡åŸåˆ™ã€‚</p>
    </div>

    <h3 id="neocognitron">Neocognitron (1982)ï¼šç¬¬ä¸€ä¸ªå¹³ç§»ä¸å˜ç¥ç»ç½‘ç»œ</h3>

    <div class="person-card">
      <div class="person-emoji">ğŸ§ </div>
      <div class="person-info">
        <h4>Kunihiko Fukushima (ç¦å³¶é‚¦å½¦)</h4>
        <p>åœ¨ç¥ç»ç½‘ç»œç¤¾åŒºä¸­ï¼Œ<strong>Neocognitron</strong>ï¼ˆFukushima and Miyake, 1982ï¼‰è¢«è®¤ä¸ºæ˜¯ç¬¬ä¸€ä¸ªåœ¨ç¥ç»ç½‘ç»œä¸­å®ç°<strong>å¹³ç§»ä¸å˜æ€§</strong>çš„æ¶æ„â€”â€”"ä¸å—ä½ç½®åç§»å½±å“çš„æ¨¡å¼è¯†åˆ«"ã€‚ä»–çš„è§£å†³æ–¹æ¡ˆæ˜¯å…·æœ‰<strong>å±€éƒ¨è¿æ¥</strong>å’Œ<strong>å±‚çº§ç»“æ„</strong>çš„ç¥ç»ç½‘ç»œï¼Œçµæ„Ÿæ¥è‡ª <strong>Hubel å’Œ Wiesel</strong>ï¼ˆ1959ï¼‰åœ¨è§†è§‰çš®å±‚ä¸­å‘ç°çš„æ„Ÿå—é‡ã€‚</p>
      </div>
    </div>

    <div class="callout callout-history">
      <h4>ğŸº Nobel çº§çš„ç”Ÿç‰©å­¦çµæ„Ÿ</h4>
      <p>Hubel å’Œ Wiesel å‘ç°è§†è§‰çš®å±‚ä¸­çš„ç¥ç»å…ƒå…·æœ‰<strong>å±‚çº§åŒ–çš„æ„Ÿå—é‡</strong>ï¼šç®€å•ç»†èƒå“åº”ç‰¹å®šæ–¹å‘çš„è¾¹ç¼˜ï¼Œå¤æ‚ç»†èƒå¯¹è¾¹ç¼˜çš„ä½ç½®ä¸æ•æ„Ÿï¼ˆä½ç½®ä¸å˜æ€§ï¼‰ã€‚è¿™ä¸€ç»å…¸å·¥ä½œè·å¾—äº† 1981 å¹´çš„<strong>è¯ºè´å°”åŒ»å­¦å¥–</strong>ï¼ˆä¸ Roger Sperry å…±äº«ï¼‰ã€‚ä» Neocognitron åˆ° CNN åˆ° GDLï¼Œè¿™ä¸ªç”Ÿç‰©å­¦çµæ„Ÿä¸€ç›´æ˜¯æ ¸å¿ƒã€‚</p>
    </div>

    <h3 id="lecun-cnn">LeCun ä¸ CNN (1998)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>è¿™äº›æƒ³æ³•åœ¨ <strong>Yann LeCun</strong> åŠå…¶åˆä½œè€…çš„å¼€åˆ›æ€§å·¥ä½œï¼ˆLeCun et al., 1998ï¼‰ä¸­è¾¾åˆ°äº†é¡¶å³°â€”â€”<span class="term">å·ç§¯ç¥ç»ç½‘ç»œ</span>ï¼ˆConvolutional Neural Networksï¼‰ã€‚CNN æŠŠ Neocognitron çš„å±€éƒ¨è¿æ¥ + æƒé‡å…±äº«æ€æƒ³ä¸åå‘ä¼ æ’­è®­ç»ƒç»“åˆï¼Œåˆ›é€ äº†ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡å®ç”¨çš„æ·±åº¦å­¦ä¹ æ¶æ„ã€‚</p>
      </div>
      <div class="en">
        These ideas culminated in CNNs in the seminal work of LeCun et al. (1998), combining local connectivity, weight sharing, and backpropagation training.
      </div>
    </div>

    <h3 id="wood-shawe">è¡¨ç¤ºè®ºè§†è§’ (Wood & Shawe-Taylor, 1996)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>é¦–æ¬¡ä»<span class="term">è¡¨ç¤ºè®º</span>ï¼ˆrepresentation theoryï¼‰è§’åº¦ç ”ç©¶ä¸å˜å’Œç­‰å˜ç¥ç»ç½‘ç»œçš„å·¥ä½œç”± <strong>Wood å’Œ Shawe-Taylor</strong>ï¼ˆ1996ï¼‰å®Œæˆï¼Œä½†<strong>ä¸å¹¸å¾ˆå°‘è¢«å¼•ç”¨</strong>ã€‚è¿™äº›æ€æƒ³çš„æ›´è¿‘æœŸçš„ä½“ç°åŒ…æ‹¬ Makadia et al.ï¼ˆ2007ï¼‰ã€Esteves et al.ï¼ˆ2020ï¼‰å’Œæœ¬ä¹¦ä½œè€…ä¹‹ä¸€ï¼ˆCohen and Welling, 2016ï¼‰çš„å·¥ä½œã€‚</p>
      </div>
      <div class="en">
        The first representation-theoretical view on invariant and equivariant neural networks was performed by Wood and Shawe-Taylor (1996), unfortunately rarely cited.
      </div>
    </div>

    <h4 id="code-cnn-symmetry">ğŸ’» ä»£ç ï¼šCNN çš„å¹³ç§»ç­‰å˜æ€§éªŒè¯</h4>

    <div class="code-container">
      <div class="code-header">
        <span>Python â€” éªŒè¯ CNN çš„å¹³ç§»ç­‰å˜æ€§ä¸æ—‹è½¬éç­‰å˜æ€§</span>
        <button class="copy-btn" onclick="copyCode(this)">å¤åˆ¶</button>
      </div>
<pre><code><span style="color:var(--code-comment)"># CNN å¯¹ç§°æ€§éªŒè¯ï¼šå¹³ç§»ç­‰å˜ vs æ—‹è½¬ä¸ç­‰å˜</span>
<span style="color:var(--code-keyword)">import</span> torch
<span style="color:var(--code-keyword)">import</span> torch.nn <span style="color:var(--code-keyword)">as</span> nn
<span style="color:var(--code-keyword)">import</span> torch.nn.functional <span style="color:var(--code-keyword)">as</span> F
<span style="color:var(--code-keyword)">import</span> numpy <span style="color:var(--code-keyword)">as</span> np

<span style="color:var(--code-comment)"># === 1. å¹³ç§»ç­‰å˜æ€§ ===</span>
conv = nn.Conv2d(<span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">4</span>, kernel_size=<span style="color:var(--code-number)">3</span>, padding=<span style="color:var(--code-number)">1</span>, bias=<span style="color:var(--code-keyword)">False</span>)

<span style="color:var(--code-comment)"># åŸå§‹è¾“å…¥</span>
x = torch.zeros(<span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">1</span>, <span style="color:var(--code-number)">16</span>, <span style="color:var(--code-number)">16</span>)
x[<span style="color:var(--code-number)">0</span>, <span style="color:var(--code-number)">0</span>, <span style="color:var(--code-number)">4</span>:<span style="color:var(--code-number)">8</span>, <span style="color:var(--code-number)">4</span>:<span style="color:var(--code-number)">8</span>] = <span style="color:var(--code-number)">1.0</span>  <span style="color:var(--code-comment)"># ä¸€ä¸ªæ–¹å—</span>

<span style="color:var(--code-comment)"># å¹³ç§»åçš„è¾“å…¥ï¼ˆå‘å³ç§» 3 åƒç´ ï¼‰</span>
x_shifted = torch.zeros_like(x)
x_shifted[<span style="color:var(--code-number)">0</span>, <span style="color:var(--code-number)">0</span>, <span style="color:var(--code-number)">4</span>:<span style="color:var(--code-number)">8</span>, <span style="color:var(--code-number)">7</span>:<span style="color:var(--code-number)">11</span>] = <span style="color:var(--code-number)">1.0</span>

<span style="color:var(--code-keyword)">with</span> torch.no_grad():
    y = conv(x)               <span style="color:var(--code-comment)"># å…ˆå·ç§¯</span>
    y_shifted = conv(x_shifted) <span style="color:var(--code-comment)"># å¯¹å¹³ç§»è¾“å…¥å·ç§¯</span>

    <span style="color:var(--code-comment)"># å¯¹è¾“å‡ºåšåŒæ ·çš„å¹³ç§»</span>
    y_then_shift = torch.zeros_like(y)
    y_then_shift[:, :, :, <span style="color:var(--code-number)">3</span>:] = y[:, :, :, :-<span style="color:var(--code-number)">3</span>]

<span style="color:var(--code-comment)"># éªŒè¯ï¼šconv(shift(x)) â‰ˆ shift(conv(x))</span>
diff_translation = (y_shifted[:,:,:<span style="color:var(--code-number)">-3</span>,<span style="color:var(--code-number)">3</span>:] - y_then_shift[:,:,:<span style="color:var(--code-number)">-3</span>,<span style="color:var(--code-number)">3</span>:]).abs().max()
print(f<span style="color:var(--code-string)">"å¹³ç§»ç­‰å˜è¯¯å·®: {diff_translation:.2e}"</span>)
<span style="color:var(--code-comment)"># â†’ çº¦ 0 ï¼ˆè¾¹ç•Œæ•ˆåº”å¤–å®Œç¾ç­‰å˜ï¼‰</span>

<span style="color:var(--code-comment)"># === 2. æ—‹è½¬ä¸ç­‰å˜æ€§ ===</span>
<span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">rotate_90</span>(x):
    <span style="color:var(--code-string)">"""é€†æ—¶é’ˆæ—‹è½¬ 90Â°"""</span>
    <span style="color:var(--code-keyword)">return</span> x.flip(-<span style="color:var(--code-number)">1</span>).transpose(-<span style="color:var(--code-number)">2</span>, -<span style="color:var(--code-number)">1</span>)

<span style="color:var(--code-keyword)">with</span> torch.no_grad():
    x_rot = rotate_90(x)
    y_rot_input = conv(x_rot)     <span style="color:var(--code-comment)"># å…ˆæ—‹è½¬å†å·ç§¯</span>
    y_rot_output = rotate_90(y)   <span style="color:var(--code-comment)"># å…ˆå·ç§¯å†æ—‹è½¬</span>

diff_rotation = (y_rot_input - y_rot_output).abs().max()
print(f<span style="color:var(--code-string)">"æ—‹è½¬ç­‰å˜è¯¯å·®: {diff_rotation:.4f}"</span>)
<span style="color:var(--code-comment)"># â†’ éé›¶ï¼æ ‡å‡† CNN å¯¹æ—‹è½¬ä¸ç­‰å˜</span>
<span style="color:var(--code-comment)"># â†’ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦ Group Equivariant CNN (Cohen & Welling, 2016)</span>

<span style="color:var(--code-comment)"># === 3. å…¨å±€æ± åŒ–è·å¾—å¹³ç§»ä¸å˜æ€§ ===</span>
pool = nn.AdaptiveAvgPool2d(<span style="color:var(--code-number)">1</span>)
<span style="color:var(--code-keyword)">with</span> torch.no_grad():
    inv_orig = pool(conv(x))
    inv_shift = pool(conv(x_shifted))
diff_invariance = (inv_orig - inv_shift).abs().max()
print(f<span style="color:var(--code-string)">"æ± åŒ–åå¹³ç§»ä¸å˜æ€§è¯¯å·®: {diff_invariance:.2e}"</span>)
<span style="color:var(--code-comment)"># â†’ çº¦ 0 â€” ç­‰å˜ç‰¹å¾ + ä¸å˜æ± åŒ– = ä¸å˜è¾“å‡ºï¼ˆGDL è“å›¾ï¼ï¼‰</span>
</code></pre>
    </div>

    <!-- ============================================================ -->
    <!-- 7.4 GNN HISTORY -->
    <!-- ============================================================ -->
    <h2 id="sec7-4">7.4 å›¾ç¥ç»ç½‘ç»œçš„å‘å±•å²<br><span style="font-size:0.7em;color:var(--text-secondary)">History of Graph Neural Networks</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>å¾ˆéš¾ç²¾ç¡®æŒ‡å‡ºå›¾ç¥ç»ç½‘ç»œçš„æ¦‚å¿µä½•æ—¶å¼€å§‹å‡ºç°â€”â€”éƒ¨åˆ†åŸå› æ˜¯å¤§å¤šæ•°æ—©æœŸå·¥ä½œæ²¡æœ‰å°†å›¾ä½œä¸ºä¸€ç­‰å…¬æ°‘ï¼Œéƒ¨åˆ†æ˜¯å› ä¸º GNN ç›´åˆ° 2010 å¹´ä»£åæœŸæ‰å˜å¾—å®ç”¨ï¼Œè¿˜éƒ¨åˆ†æ˜¯å› ä¸ºè¿™ä¸ªé¢†åŸŸæ˜¯ä»å¤šä¸ªç ”ç©¶æ–¹å‘çš„æ±‡åˆä¸­æ¶Œç°çš„ã€‚</p>
      </div>
      <div class="en">
        It is difficult to pinpoint exactly when the concept of GNNs began to emerge â€” partly because most early work did not place graphs as a first-class citizen, and partly because this field emerged from the confluence of several research areas.
      </div>
    </div>

    <h3 id="gnn-prehistory">1990sï¼šå‰ GNN æ—¶ä»£ â€” "é€šè¿‡ç»“æ„åå‘ä¼ æ’­"</h3>

    <div class="bilingual">
      <div class="zh">
        <p>GNN çš„æ—©æœŸå½¢å¼è‡³å°‘å¯ä»¥è¿½æº¯åˆ° 1990 å¹´ä»£ï¼š</p>
        <ul>
          <li><strong>Sperduti</strong>ï¼ˆ1994ï¼‰â€” Labeling RAAMï¼šåœ¨ç»“æ„åŒ–æ•°æ®ä¸Šå­¦ä¹ è¡¨ç¤º</li>
          <li><strong>Goller å’Œ Kuchler</strong>ï¼ˆ1996ï¼‰â€” <span class="term">"é€šè¿‡ç»“æ„åå‘ä¼ æ’­"</span>ï¼ˆbackpropagation through structureï¼‰</li>
          <li><strong>Sperduti å’Œ Starita</strong>ï¼ˆ1997ï¼‰â€” è‡ªé€‚åº”æ•°æ®ç»“æ„å¤„ç†</li>
          <li><strong>Frasconi et al.</strong>ï¼ˆ1998ï¼‰â€” æ•°æ®ç»“æ„çš„é€šç”¨æ¡†æ¶</li>
        </ul>
        <p>è™½ç„¶è¿™äº›å·¥ä½œä¸»è¦å…³æ³¨"ç»“æ„"ï¼ˆé€šå¸¸æ˜¯æ ‘æˆ–æœ‰å‘æ— ç¯å›¾ï¼‰ï¼Œä½†å®ƒä»¬æ¶æ„ä¸­ä¿ç•™çš„è®¸å¤šä¸å˜æ€§ä¸ä»Šå¤©æ›´å¸¸ç”¨çš„ GNN æ˜¯ç›¸ä¼¼çš„ã€‚</p>
      </div>
      <div class="en">
        Early forms of GNNs can be traced back to the 1990s, primarily concerned with operating over "structures" (often trees or DAGs), many of the invariances preserved are reminiscent of modern GNNs.
      </div>
    </div>

    <h3 id="gnn-birth">2005ï¼šGNN çš„æ­£å¼è¯ç”Ÿ</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¯¹é€šç”¨å›¾ç»“æ„å¤„ç†çš„é¦–æ¬¡æ­£å¼å¤„ç†ï¼ˆä»¥åŠ"<span class="term">å›¾ç¥ç»ç½‘ç»œ</span>"ä¸€è¯çš„åˆ›é€ ï¼‰å‘ç”Ÿåœ¨ 21 ä¸–çºªåˆã€‚åœ¨æ„å¤§åˆ©é”¡è€¶çº³å¤§å­¦çš„äººå·¥æ™ºèƒ½å®éªŒå®¤å†…ï¼Œç”± <strong>Marco Gori</strong> å’Œ <strong>Franco Scarselli</strong> ä¸»å¯¼çš„è®ºæ–‡ï¼ˆGori et al., 2005; Scarselli et al., 2008ï¼‰æå‡ºäº†ç¬¬ä¸€ä¸ª"GNN"ã€‚</p>
        <p>å®ƒä»¬ä¾èµ–äº<strong>å¾ªç¯æœºåˆ¶</strong>ï¼ˆrecurrent mechanismsï¼‰ï¼Œè¦æ±‚ç¥ç»ç½‘ç»œå‚æ•°æŒ‡å®š<strong>æ”¶ç¼©æ˜ å°„</strong>ï¼ˆcontraction mappingsï¼‰ï¼Œå› æ­¤é€šè¿‡æœç´¢<strong>ä¸åŠ¨ç‚¹</strong>æ¥è®¡ç®—èŠ‚ç‚¹è¡¨ç¤ºâ€”â€”è¿™æœ¬èº«éœ€è¦ä¸€ç§ç‰¹æ®Šå½¢å¼çš„åå‘ä¼ æ’­ï¼ˆAlmeida, 1990; Pineda, 1988ï¼‰ï¼Œè€Œä¸”å®Œå…¨ä¸ä¾èµ–äºèŠ‚ç‚¹ç‰¹å¾ã€‚</p>
      </div>
      <div class="en">
        The first proper "GNN" (Gori et al., 2005; Scarselli et al., 2008) relied on recurrent mechanisms, required contraction mappings, and computed node representations by searching for a fixed point.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ åŸå§‹ GNN çš„ä¸åŠ¨ç‚¹å…¬å¼</h4>
      <div class="math-block">
        $$\mathbf{h}_u^{(t+1)} = f_\theta\!\left(\mathbf{x}_u, \left\{\mathbf{h}_v^{(t)}, \mathbf{x}_v, \mathbf{e}_{uv}\right\}_{v \in \mathcal{N}(u)}\right)$$
        <div class="math-explain">
          <p>åœ¨ $t \to \infty$ æ—¶æ”¶æ•›åˆ°ä¸åŠ¨ç‚¹ $\mathbf{h}^* = f_\theta(\mathbf{h}^*)$ã€‚<strong>è¦æ±‚</strong>ï¼š$f_\theta$ å¿…é¡»æ˜¯æ”¶ç¼©æ˜ å°„ï¼ˆ$\|f_\theta(a) - f_\theta(b)\| \leq c\|a - b\|, c < 1$ï¼‰ï¼Œç”± Banach ä¸åŠ¨ç‚¹å®šç†ä¿è¯æ”¶æ•›ã€‚</p>
          <p><strong>ç¼ºé™·</strong>ï¼šæ”¶ç¼©æ˜ å°„çš„çº¦æŸä¸¥é‡é™åˆ¶äº†è¡¨è¾¾åŠ›ï¼›ä¸åŠ¨ç‚¹åå‘ä¼ æ’­è®¡ç®—é‡å¤§ï¼›ä¸ä½¿ç”¨èŠ‚ç‚¹ç‰¹å¾ã€‚</p>
        </div>
      </div>
    </div>

    <div class="bilingual">
      <div class="zh">
        <p>æ‰€æœ‰ä¸Šè¿°é—®é¢˜éƒ½è¢« <strong>Li et al.</strong>ï¼ˆ2015ï¼‰çš„ <span class="term">Gated GNN</span>ï¼ˆGGNNï¼‰æ¨¡å‹è§£å†³äº†ã€‚GGNN å°†ç°ä»£ RNN çš„è®¸å¤šä¼˜ç‚¹ï¼ˆå¦‚é—¨æ§æœºåˆ¶å’Œæ—¶é—´åå‘ä¼ æ’­ï¼‰å¼•å…¥äº† GNN æ¨¡å‹ï¼Œè‡³ä»Šä»ç„¶æµè¡Œã€‚</p>
        <p>åŒæ—¶ï¼Œ<strong>Alessio Micheli</strong> æå‡ºäº†å›¾çš„ç¥ç»ç½‘ç»œï¼ˆNN4Gï¼‰æ¨¡å‹ï¼Œä¸“æ³¨äº<strong>å‰é¦ˆ</strong>è€Œéå¾ªç¯èŒƒå¼ï¼ˆMicheli, 2009ï¼‰ã€‚</p>
      </div>
      <div class="en">
        All issues were rectified by the Gated GNN (GGNN) of Li et al. (2015), which brought gating mechanisms and backpropagation through time to the GNN model.
      </div>
    </div>

    <h3 id="gnn-chemistry">è®¡ç®—åŒ–å­¦ï¼šGNN çš„ç‹¬ç«‹èµ·æº</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¦ä¸€æ¡ç‹¬ç«‹ä¸”å¹¶è¡Œçš„ GNN å‘å±•çº¿æ˜¯å®Œå…¨ç”±<span class="term">è®¡ç®—åŒ–å­¦</span>çš„éœ€æ±‚é©±åŠ¨çš„ï¼Œåœ¨é‚£é‡Œåˆ†å­æœ€è‡ªç„¶åœ°è¡¨ç¤ºä¸ºåŸå­ï¼ˆèŠ‚ç‚¹ï¼‰é€šè¿‡åŒ–å­¦é”®ï¼ˆè¾¹ï¼‰è¿æ¥çš„å›¾ã€‚</p>
        <ul>
          <li><strong>Kireev</strong>ï¼ˆ1995ï¼‰â€” ChemNetï¼šæœ€æ—©çš„åˆ†å­å›¾ç¥ç»ç½‘ç»œ</li>
          <li><strong>Baskin et al.</strong>ï¼ˆ1997ï¼‰â€” ç»“æ„-æ€§è´¨ç›´æ¥å…³è”</li>
          <li><strong>Merkwirth å’Œ Lengauer</strong>ï¼ˆ2005ï¼‰â€” æ˜¾å¼æå‡ºäº†<strong>è¾¹ç±»å‹æ¡ä»¶æƒé‡</strong>å’Œ<strong>å…¨å±€æ± åŒ–</strong>â€”â€”è¿™äº›æ˜¯å½“ä»£ GNN ä¸­å¸¸è§çš„å…ƒç´ </li>
          <li><strong>Duvenaud et al.</strong>ï¼ˆ2015ï¼‰â€” æ”¹è¿›<strong>åˆ†å­æŒ‡çº¹</strong>ï¼ˆmolecular fingerprintingï¼‰</li>
          <li><strong>Gilmer et al.</strong>ï¼ˆ2017ï¼‰â€” <span class="term">MPNN</span> æ¡†æ¶ï¼šé¢„æµ‹é‡å­åŒ–å­¦æ€§è´¨ï¼Œç»Ÿä¸€äº†å¤šç§ GNN å˜ä½“</li>
        </ul>
        <p>åœ¨æ’°å†™æœ¬ä¹¦æ—¶ï¼Œåˆ†å­æ€§è´¨é¢„æµ‹æ˜¯ GNN æœ€æˆåŠŸçš„åº”ç”¨ä¹‹ä¸€ï¼Œå…·æœ‰å‘ç°æ–°å‹æŠ—ç”Ÿç´ è¯ç‰©ï¼ˆStokes et al., 2020ï¼‰ç­‰æœ‰å½±å“åŠ›çš„æˆæœã€‚</p>
      </div>
      <div class="en">
        An independent line of GNN development was entirely driven by computational chemistry. Molecular property prediction remains one of the most successful GNN applications.
      </div>
    </div>

    <div class="callout callout-robot">
      <h4>ğŸ¤– PhysRobotï¼šåŒ–å­¦ GNN â†’ ç‰©ç†ä»¿çœŸ GNN</h4>
      <p>è®¡ç®—åŒ–å­¦å’Œç‰©ç†ä»¿çœŸçš„ GNN å…±äº«ç›¸åŒçš„æ ¸å¿ƒæ€æƒ³ï¼š</p>
      <table>
        <thead>
          <tr><th></th><th>è®¡ç®—åŒ–å­¦</th><th>ç‰©ç†ä»¿çœŸ (PhysRobot)</th></tr>
        </thead>
        <tbody>
          <tr><td>èŠ‚ç‚¹</td><td>åŸå­</td><td>ç²’å­/ç½‘æ ¼ç‚¹</td></tr>
          <tr><td>è¾¹</td><td>åŒ–å­¦é”®</td><td>ç©ºé—´é‚»è¿‘å…³ç³»</td></tr>
          <tr><td>èŠ‚ç‚¹ç‰¹å¾</td><td>åŸå­åºæ•°ã€ç”µè·</td><td>ä½ç½®ã€é€Ÿåº¦ã€è´¨é‡</td></tr>
          <tr><td>è¾¹ç‰¹å¾</td><td>é”®ç±»å‹ã€é”®é•¿</td><td>ç›¸å¯¹ä½ç§»ã€è·ç¦»</td></tr>
          <tr><td>ç­‰å˜æ€§</td><td>E(3) (æ—‹è½¬+å¹³ç§»)</td><td>SE(3) (æ—‹è½¬+å¹³ç§»)</td></tr>
          <tr><td>ä»»åŠ¡</td><td>é¢„æµ‹åˆ†å­æ€§è´¨</td><td>é¢„æµ‹ä¸‹ä¸€æ­¥çŠ¶æ€</td></tr>
        </tbody>
      </table>
      <p>Gilmer et al. (2017) çš„ MPNN æ¡†æ¶â€”â€”Chapter 5 çš„æ ¸å¿ƒâ€”â€”ç›´æ¥ç»Ÿä¸€äº†è¿™ä¸¤ä¸ªé¢†åŸŸã€‚</p>
    </div>

    <h3 id="node-embed">èŠ‚ç‚¹åµŒå…¥ï¼šä» DeepWalk åˆ°å¯¹æ¯”å­¦ä¹ </h3>

    <div class="bilingual">
      <div class="zh">
        <p>å›¾ä¸Šæ·±åº¦å­¦ä¹ çš„ä¸€äº›æœ€æ—©æˆåŠŸæ•…äº‹æ¶‰åŠä»¥æ— ç›‘ç£æ–¹å¼å­¦ä¹ èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚å…³é”®çš„æ—©æœŸæ–¹æ³•ä¾èµ–äº<span class="term">éšæœºæ¸¸èµ°åµŒå…¥</span>ï¼ˆrandom walk-based embeddingsï¼‰ï¼šå­¦ä¹ èŠ‚ç‚¹è¡¨ç¤ºï¼Œä½¿å¾—åœ¨çŸ­éšæœºæ¸¸èµ°ä¸­å…±åŒå‡ºç°çš„èŠ‚ç‚¹è¡¨ç¤ºæ›´æ¥è¿‘ã€‚</p>
        <ul>
          <li><strong>DeepWalk</strong>ï¼ˆPerozzi et al., 2014ï¼‰â€” å›¾ä¸Šçš„ word2vec</li>
          <li><strong>node2vec</strong>ï¼ˆGrover and Leskovec, 2016ï¼‰â€” å¸¦åå‘éšæœºæ¸¸èµ°</li>
          <li><strong>LINE</strong>ï¼ˆTang et al., 2015ï¼‰â€” å¤§è§„æ¨¡ä¿¡æ¯ç½‘ç»œåµŒå…¥</li>
          <li><strong>Planetoid</strong>ï¼ˆYang et al., 2016ï¼‰â€” é¦–ä¸ªç»“åˆç›‘ç£æ ‡ç­¾ä¿¡æ¯çš„æ–¹æ³•</li>
        </ul>
      </div>
      <div class="en">
        Key early approaches relied on random walk-based embeddings: learning node representations that bring them closer together if nodes co-occur in a short random walk.
      </div>
    </div>

    <div class="bilingual">
      <div class="zh">
        <p>æœ‰è¶£çš„æ˜¯ï¼Œåæ¥å‘ç°å°†é‚»è¿‘èŠ‚ç‚¹è¡¨ç¤ºæ¨åˆ°ä¸€èµ·å·²ç»æ˜¯ GNN å½’çº³åç½®çš„å…³é”®éƒ¨åˆ†ã€‚å®é™…ä¸Šï¼Œ<strong>æœªç»è®­ç»ƒçš„ GNN</strong> å·²ç»å±•ç¤ºå‡ºä¸ DeepWalk æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ˆVeliÄkoviÄ‡ et al., 2019; Wu et al., 2019ï¼‰ã€‚è¿™å¼•å‘äº†ä»éšæœºæ¸¸èµ°è½¬å‘<span class="term">å¯¹æ¯”å­¦ä¹ </span>æ–¹æ³•çš„è¶‹åŠ¿ï¼ŒåŒ…æ‹¬ <strong>DGI</strong>ï¼ˆDeep Graph Infomaxï¼‰ã€<strong>GRACE</strong>ã€BERT-like ç›®æ ‡å’Œ <strong>BGRL</strong>ã€‚</p>
      </div>
      <div class="en">
        An untrained GNN was already competitive with DeepWalk, launching a direction towards contrastive approaches like DGI, GRACE, and BGRL.
      </div>
    </div>

    <h3 id="pgm-gnn">æ¦‚ç‡å›¾æ¨¡å‹ä¸ GNN</h3>

    <div class="bilingual">
      <div class="zh">
        <p>GNN åŒæ—¶ä¹Ÿé€šè¿‡åµŒå…¥<span class="term">æ¦‚ç‡å›¾æ¨¡å‹</span>ï¼ˆPGMs, Wainwright and Jordan, 2008ï¼‰çš„è®¡ç®—è€Œå¤å…´ã€‚PGM æ˜¯å¤„ç†å›¾æ•°æ®çš„å¼ºå¤§å·¥å…·ï¼šèŠ‚ç‚¹è¢«è§†ä¸ºéšæœºå˜é‡ï¼Œå›¾ç»“æ„ç¼–ç æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾ã€‚PGM ä¸Šçš„å­¦ä¹ å’Œæ¨ç†ç®—æ³•ä¾èµ–äºé€šè¿‡è¾¹ä¼ é€’æ¶ˆæ¯çš„å½¢å¼ï¼ˆPearl, 2014ï¼‰ï¼ŒåŒ…æ‹¬å˜åˆ†å¹³å‡åœºæ¨ç†å’Œå¾ªç¯ä¿¡å¿µä¼ æ’­ã€‚</p>
      </div>
      <div class="en">
        GNNs also resurged through embedding PGM computations. Algorithms for learning and inference on PGMs rely on forms of passing messages over edges.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ ä» PGM åˆ° GNNï¼šstructure2vec çš„æ•°å­¦æ¡¥æ¢</h4>
      <p><strong>Dai et al.</strong>ï¼ˆ2016ï¼‰çš„ <span class="term">structure2vec</span> å»ºç«‹äº† PGM å’Œ GNN ä¹‹é—´çš„ç†è®ºè”ç³»ã€‚å…³é”®"æŠ€å·§"æ˜¯ä½¿ç”¨<strong>åˆ†å¸ƒçš„ Hilbert ç©ºé—´åµŒå…¥</strong>ï¼ˆSmola et al., 2007ï¼‰ï¼š</p>
      <div class="math-block">
        <p>ç»™å®šé€‚å½“é€‰æ‹©çš„åµŒå…¥å‡½æ•° $\phi$ï¼Œæ¦‚ç‡åˆ†å¸ƒ $p(x)$ å¯ä»¥åµŒå…¥ä¸ºï¼š</p>
        $$\mu_p = \mathbb{E}_{x \sim p(x)}[\phi(x)]$$
        <div class="math-explain">
          è¿™ç§å¯¹åº”å…è®¸æˆ‘ä»¬è¿›è¡Œ GNN å¼è®¡ç®—ï¼ŒåŒæ—¶çŸ¥é“ GNN è®¡ç®—çš„è¡¨ç¤ºæ€»æ˜¯å¯¹åº”äºèŠ‚ç‚¹ç‰¹å¾ä¸ŠæŸä¸ªæ¦‚ç‡åˆ†å¸ƒçš„åµŒå…¥ã€‚structure2vec æœ¬èº«æœ€ç»ˆæ˜¯ä¸€ä¸ªå¾ˆå®¹æ˜“çº³å…¥ GDL æ¡†æ¶çš„ GNN æ¶æ„ã€‚
        </div>
      </div>
      <p>è¿™å¯å‘äº†ä¸€ç³»åˆ—æ›´ç›´æ¥ç»“åˆ PGM è®¡ç®—çš„ GNN æ¶æ„ï¼ŒåŒ…æ‹¬ä¸æ¡ä»¶éšæœºåœºï¼ˆCRFï¼‰ã€å…³ç³» Markov ç½‘ç»œå’Œ Markov é€»è¾‘ç½‘ç»œçš„ç»“åˆã€‚</p>
    </div>

    <h3 id="spectral-gnn">è°±åŸŸ GNN çš„æ¼”åŒ–</h3>

    <div class="bilingual">
      <div class="zh">
        <p>åŸºäºè°±æ»¤æ³¢å™¨çš„å›¾å·ç§¯ç¥ç»ç½‘ç»œ <strong>Defferrard et al.</strong>ï¼ˆ2016ï¼‰å’Œ <strong>Kipf and Welling</strong>ï¼ˆ2016aï¼‰æ˜¯è¯¥é¢†åŸŸè¢«å¼•ç”¨æœ€å¤šçš„è®ºæ–‡ä¹‹ä¸€ï¼Œå¯ä»¥è¢«è®¤ä¸ºæ˜¯é‡æ–°ç‚¹ç‡ƒäº†è¿‘å¹´æ¥å¯¹å›¾ä¸Šæœºå™¨å­¦ä¹ å…´è¶£çš„å…³é”®å·¥ä½œã€‚</p>
      </div>
      <div class="en">
        The graph convolutional neural networks relying on spectral filters by Defferrard et al. (2016) and Kipf and Welling (2016a) can likely be credited as reigniting interest in machine learning on graphs.
      </div>
    </div>

    <div class="timeline">
      <div class="timeline-item">
        <div class="timeline-year">2013 â€” Bruna et al.</div>
        <div class="timeline-title">ç¬¬ä¸€ä¸ªè°±åŸŸå›¾ CNN</div>
        <div class="timeline-desc">ç›´æ¥åœ¨å›¾ Fourier åŸŸå®šä¹‰å·ç§¯ï¼š$y = \mathbf{U} \text{diag}(\hat{g}) \mathbf{U}^T x$ã€‚é—®é¢˜ï¼šéœ€è¦ $O(n^2)$ çš„ç‰¹å¾åˆ†è§£ï¼Œæ»¤æ³¢å™¨éå±€éƒ¨åŒ–ã€‚</div>
      </div>
      <div class="timeline-item">
        <div class="timeline-year">2016 â€” Defferrard et al. (ChebNet)</div>
        <div class="timeline-title">åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼åŠ é€Ÿ</div>
        <div class="timeline-desc">ç”¨ Chebyshev å¤šé¡¹å¼è¿‘ä¼¼è°±æ»¤æ³¢å™¨ï¼š$g_\theta(\mathbf{L}) = \sum_{k=0}^{K} \theta_k T_k(\tilde{\mathbf{L}})$ã€‚å°† $O(n^2)$ é™è‡³ $O(K|E|)$â€”â€”K é˜¶å±€éƒ¨åŒ–ï¼</div>
      </div>
      <div class="timeline-item">
        <div class="timeline-year">2016 â€” Kipf & Welling (GCN)</div>
        <div class="timeline-title">ä¸€é˜¶è¿‘ä¼¼ = æ¶ˆæ¯ä¼ é€’</div>
        <div class="timeline-desc">å°† ChebNet ç®€åŒ–åˆ° $K=1$ï¼š$\mathbf{H}^{(l+1)} = \sigma(\tilde{\mathbf{D}}^{-1/2}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-1/2}\mathbf{H}^{(l)}\mathbf{W}^{(l)})$ã€‚ç®€å•ã€é«˜æ•ˆã€å¼ºå¤§â€”â€”ç‚¹ç‡ƒäº† GNN çš„çƒ­æ½®ã€‚</div>
      </div>
      <div class="timeline-item">
        <div class="timeline-year">2017 â€” Gilmer et al. (MPNN)</div>
        <div class="timeline-title">æ¶ˆæ¯ä¼ é€’ç»Ÿä¸€æ¡†æ¶</div>
        <div class="timeline-desc">å°†æ‰€æœ‰ GNN ç»Ÿä¸€ä¸ºï¼šæ¶ˆæ¯ $\mathbf{m}_{u \to v}$ã€èšåˆ $\bigoplus$ã€æ›´æ–° $\phi$ã€‚æ­ç¤ºäº†è°±åŸŸå’Œç©ºé—´åŸŸæ–¹æ³•çš„ç­‰ä»·æ€§ã€‚</div>
      </div>
    </div>

    <h3 id="spatial-gnn">ç©ºé—´åŸŸ GNN ä¸æ³¨æ„åŠ›æœºåˆ¶</h3>

    <div class="bilingual">
      <div class="zh">
        <p>åœ¨è®¡ç®—æœºå›¾å½¢å­¦çš„èƒŒæ™¯ä¸‹ï¼Œ<span class="term">å›¾æ³¨æ„åŠ›ç½‘ç»œ</span>ï¼ˆGATï¼‰ï¼Œä»æŠ€æœ¯ä¸Šæ¥è¯´å¯ä»¥è¢«è®¤ä¸ºæ˜¯ MoNet çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œç”±æœ¬ä¹¦ä½œè€…ä¹‹ä¸€å¼•å…¥ï¼ˆVeliÄkoviÄ‡ et al., 2018ï¼‰ã€‚GAT å°† MoNet çš„æ³¨æ„åŠ›æœºåˆ¶æ¨å¹¿ä¸ºä¹Ÿç»“åˆ<strong>èŠ‚ç‚¹ç‰¹å¾ä¿¡æ¯</strong>ï¼Œä¸å†ä»…ä»…ä¾èµ–çº¯ç»“æ„å¯¼å‡ºçš„ç›¸å…³æ€§ã€‚å®ƒæ˜¯ç›®å‰ä½¿ç”¨æœ€å¹¿æ³›çš„ GNN æ¶æ„ä¹‹ä¸€ã€‚</p>
      </div>
      <div class="en">
        GAT (VeliÄkoviÄ‡ et al., 2018) generalizes MoNet's attention mechanism to also incorporate node feature information. It is one of the most popular GNN architectures currently in use.
      </div>
    </div>

    <div class="callout callout-math">
      <h4>ğŸ“ GAT æ³¨æ„åŠ›æœºåˆ¶æ¨å¯¼</h4>
      <div class="math-block">
        <p><strong>æ³¨æ„åŠ›ç³»æ•°</strong>ï¼ˆèŠ‚ç‚¹ $i$ å¯¹é‚»å±… $j$ çš„æ³¨æ„åŠ›ï¼‰ï¼š</p>
        $$e_{ij} = \text{LeakyReLU}\!\left(\mathbf{a}^T [\mathbf{W}\mathbf{h}_i \| \mathbf{W}\mathbf{h}_j]\right)$$
        $$\alpha_{ij} = \text{softmax}_j(e_{ij}) = \frac{\exp(e_{ij})}{\sum_{k \in \mathcal{N}(i)} \exp(e_{ik})}$$
      </div>
      <div class="math-block">
        <p><strong>å¤šå¤´æ³¨æ„åŠ›è¾“å‡º</strong>ï¼š</p>
        $$\mathbf{h}_i' = \Big\|_{k=1}^{K} \sigma\!\left(\sum_{j \in \mathcal{N}(i)} \alpha_{ij}^{(k)} \mathbf{W}^{(k)} \mathbf{h}_j\right)$$
        <div class="math-explain">
          <p>$\|$ è¡¨ç¤ºæ‹¼æ¥ï¼Œ$K$ æ˜¯æ³¨æ„åŠ›å¤´æ•°ã€‚å…³é”®åˆ›æ–°ï¼šæ³¨æ„åŠ›æƒé‡ $\alpha_{ij}$ åŒæ—¶ä¾èµ–æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹çš„ç‰¹å¾ï¼ˆè€Œéä»…ä¾èµ–ç»“æ„ï¼‰ã€‚</p>
          <p><strong>GAT vs MoNet</strong>ï¼šMoNet çš„æ³¨æ„åŠ›åŸºäºèŠ‚ç‚¹çš„å‡ ä½•åæ ‡ï¼›GAT çš„æ³¨æ„åŠ›åŸºäºå­¦ä¹ åˆ°çš„ç‰¹å¾ã€‚åœ¨æœ‰ä¸°å¯Œç‰¹å¾çš„åœºæ™¯ï¼ˆå¦‚åˆ†å­ã€ç¤¾äº¤ç½‘ç»œï¼‰ä¸­ï¼ŒGAT é€šå¸¸æ›´ä¼˜ã€‚</p>
        </div>
      </div>
    </div>

    <div class="bilingual">
      <div class="zh">
        <p>åŒæ ·å€¼å¾—æåŠçš„æ˜¯ï¼Œ<strong>PointNet</strong>ï¼ˆQi et al., 2017ï¼‰â€”â€”å­¦ä¹ é›†åˆä¸Šçš„å‡½æ•°ï¼ˆZaheer et al., 2017ï¼‰â€”â€”åœ¨ Leo Guibas çš„æ–¯å¦ç¦å›¢é˜Ÿä¸­ä¸º 3D ç‚¹äº‘åˆ†æè€Œå¹¶è¡Œå¼€å‘ã€‚åç»­å·¥ä½œåŒ…æ‹¬ <span class="term">Dynamic Graph CNN</span>ï¼ˆDGCNN, Wang et al., 2019bï¼‰ï¼Œå®ƒä½¿ç”¨æœ€è¿‘é‚»å›¾æ•è·ç‚¹äº‘çš„å±€éƒ¨ç»“æ„ï¼Œå…³é”®ç‰¹å¾æ˜¯å›¾åœ¨å±‚ä¹‹é—´<strong>åŠ¨æ€æ›´æ–°</strong>ã€‚è¿™ä½¿ DGCNN æˆä¸º"<span class="term">æ½œå›¾å­¦ä¹ </span>"ï¼ˆlatent graph learningï¼‰çš„é¦–æ‰¹ä½“ç°ä¹‹ä¸€ã€‚</p>
      </div>
      <div class="en">
        PointNet (Qi et al., 2017) and DGCNN (Wang et al., 2019b) â€” where the graph is constructed on-the-fly and updated between layers â€” were among the first incarnations of 'latent graph learning'.
      </div>
    </div>

    <h4 id="code-gnn-evolution">ğŸ’» ä»£ç ï¼šä» GCN åˆ° GAT çš„æ¼”åŒ–</h4>

    <div class="code-container">
      <div class="code-header">
        <span>Python â€” GNN æ¶æ„æ¼”åŒ–ï¼šGCN â†’ GAT çš„å…³é”®å·®å¼‚</span>
        <button class="copy-btn" onclick="copyCode(this)">å¤åˆ¶</button>
      </div>
<pre><code><span style="color:var(--code-comment)"># GNN æ¼”åŒ–ï¼šä»å›ºå®šèšåˆåˆ°æ³¨æ„åŠ›èšåˆ</span>
<span style="color:var(--code-keyword)">import</span> torch
<span style="color:var(--code-keyword)">import</span> torch.nn <span style="color:var(--code-keyword)">as</span> nn
<span style="color:var(--code-keyword)">import</span> torch.nn.functional <span style="color:var(--code-keyword)">as</span> F

<span style="color:var(--code-comment)"># === 1. GCN Layer (Kipf & Welling, 2016) ===</span>
<span style="color:var(--code-keyword)">class</span> <span style="color:var(--code-function)">GCNLayer</span>(nn.Module):
    <span style="color:var(--code-string)">"""å›ºå®šæƒé‡èšåˆï¼šæ¯ä¸ªé‚»å±…æƒé‡ = 1/sqrt(d_i * d_j)"""</span>
    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">__init__</span>(self, in_dim, out_dim):
        super().__init__()
        self.W = nn.Linear(in_dim, out_dim, bias=<span style="color:var(--code-keyword)">False</span>)

    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">forward</span>(self, h, adj):
        <span style="color:var(--code-comment)"># å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ: D^{-1/2} A D^{-1/2}</span>
        deg = adj.sum(dim=-<span style="color:var(--code-number)">1</span>, keepdim=<span style="color:var(--code-keyword)">True</span>).clamp(min=<span style="color:var(--code-number)">1</span>)
        norm = (deg ** -<span style="color:var(--code-number)">0.5</span>)
        adj_norm = norm * adj * norm.transpose(-<span style="color:var(--code-number)">1</span>, -<span style="color:var(--code-number)">2</span>)
        <span style="color:var(--code-comment)"># æ¶ˆæ¯ä¼ é€’ = çŸ©é˜µä¹˜æ³•</span>
        <span style="color:var(--code-keyword)">return</span> F.relu(self.W(adj_norm @ h))

<span style="color:var(--code-comment)"># === 2. GAT Layer (VeliÄkoviÄ‡ et al., 2018) ===</span>
<span style="color:var(--code-keyword)">class</span> <span style="color:var(--code-function)">GATLayer</span>(nn.Module):
    <span style="color:var(--code-string)">"""å¯å­¦ä¹ æ³¨æ„åŠ›ï¼šæ¯ä¸ªé‚»å±…æƒé‡æ ¹æ®ç‰¹å¾åŠ¨æ€è®¡ç®—"""</span>
    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">__init__</span>(self, in_dim, out_dim, n_heads=<span style="color:var(--code-number)">4</span>):
        super().__init__()
        self.n_heads = n_heads
        self.head_dim = out_dim // n_heads
        self.W = nn.Linear(in_dim, out_dim, bias=<span style="color:var(--code-keyword)">False</span>)
        <span style="color:var(--code-comment)"># æ³¨æ„åŠ›å‚æ•°: a^T [Wh_i || Wh_j]</span>
        self.attn = nn.Parameter(torch.randn(n_heads, <span style="color:var(--code-number)">2</span> * self.head_dim))

    <span style="color:var(--code-keyword)">def</span> <span style="color:var(--code-function)">forward</span>(self, h, adj):
        N = h.size(<span style="color:var(--code-number)">0</span>)
        <span style="color:var(--code-comment)"># çº¿æ€§æŠ•å½±: [N, in] -> [N, heads, head_dim]</span>
        Wh = self.W(h).view(N, self.n_heads, self.head_dim)

        <span style="color:var(--code-comment)"># è®¡