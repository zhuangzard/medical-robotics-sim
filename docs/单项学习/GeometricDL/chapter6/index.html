<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chapter 6: Problems and Applications | GDL å­¦ä¹ æŒ‡å—</title>
  <link rel="stylesheet" href="../assets/style.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=Noto+Serif+SC:wght@400;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}]})"></script>
</head>
<body>
  <div class="progress-bar"></div>

  <header class="header">
    <div class="header-title"><a href="../index.html">ğŸ“ GDL å­¦ä¹ æŒ‡å—</a></div>
    <div class="header-nav">
      <a href="../chapter5/index.html">â† ä¸Šä¸€ç« </a>
      <a href="../index.html">ç›®å½•</a>
      <a href="../chapter7/index.html">ä¸‹ä¸€ç«  â†’</a>
      <button class="theme-toggle" onclick="toggleTheme()">ğŸŒ™</button>
    </div>
  </header>

  <button class="sidebar-toggle" onclick="toggleSidebar()">â˜°</button>

  <nav class="sidebar">
    <h3>Chapter 6</h3>
    <a href="#overview">æ¦‚è¿°</a>
    <a href="#chemistry">6.1 åŒ–å­¦ä¸è¯ç‰©å‘ç°</a>
    <a href="#mol-graphs" class="sub">åˆ†å­å›¾</a>
    <a href="#halicin" class="sub">Halicin çš„å‘ç°</a>
    <a href="#drug-repo" class="sub">è¯ç‰©é‡å®šä½</a>
    <a href="#equivariant-mol" class="sub">ç­‰å˜åˆ†å­ç½‘ç»œ</a>
    <a href="#proteins">6.2 è›‹ç™½è´¨ç”Ÿç‰©å­¦</a>
    <a href="#protein-folding" class="sub">è›‹ç™½è´¨æŠ˜å </a>
    <a href="#alphafold" class="sub">AlphaFold</a>
    <a href="#masif" class="sub">MaSIF è¡¨é¢æ–¹æ³•</a>
    <a href="#recommender">6.3 æ¨èç³»ç»Ÿä¸ç¤¾äº¤ç½‘ç»œ</a>
    <a href="#pinsage" class="sub">PinSage</a>
    <a href="#misinformation" class="sub">è™šå‡ä¿¡æ¯æ£€æµ‹</a>
    <a href="#traffic">6.4 äº¤é€šé¢„æµ‹</a>
    <a href="#google-maps" class="sub">Google Maps</a>
    <a href="#vision">6.5 è®¡ç®—æœºè§†è§‰</a>
    <a href="#imagenet" class="sub">ImageNet é©å‘½</a>
    <a href="#detection" class="sub">ç›®æ ‡æ£€æµ‹</a>
    <a href="#gaming">6.6 æ¸¸æˆ AI</a>
    <a href="#alphago" class="sub">AlphaGo</a>
    <a href="#atari" class="sub">Atari</a>
    <a href="#text-speech">6.7 æ–‡æœ¬ä¸è¯­éŸ³</a>
    <a href="#wavenet" class="sub">WaveNet</a>
    <a href="#gpt" class="sub">GPT ç³»åˆ—</a>
    <a href="#healthcare">6.8 åŒ»ç–—å¥åº·</a>
    <a href="#brain" class="sub">è„‘ç½‘ç»œ</a>
    <a href="#ehr" class="sub">ç”µå­å¥åº·è®°å½•</a>
    <a href="#physics">6.9 ç²’å­ç‰©ç†ä¸å¤©ä½“ç‰©ç†</a>
    <a href="#jets" class="sub">ç²’å­ jet åˆ†ç±»</a>
    <a href="#neutrino" class="sub">ä¸­å¾®å­å¤©æ–‡å­¦</a>
    <a href="#vr">6.10 è™šæ‹Ÿ/å¢å¼ºç°å®</a>
    <a href="#medical-robotics">6.11 åŒ»ç–—æœºå™¨äºº</a>
    <a href="#surgery-sim" class="sub">æ‰‹æœ¯ä»¿çœŸ</a>
    <a href="#tissue-modeling" class="sub">è½¯ç»„ç»‡å»ºæ¨¡</a>
    <a href="#instrument" class="sub">å™¨æ¢°æ§åˆ¶</a>
    <a href="#summary">æ€»ç»“</a>
    <a href="#exercises">ç»ƒä¹ é¢˜</a>
    <h3>å¯¼èˆª</h3>
    <a href="../index.html">ğŸ“š æ€»ç›®å½•</a>
    <a href="../chapter5/index.html">â† Ch.5 GDL æ¨¡å‹</a>
    <a href="../chapter7/index.html">â†’ Ch.7 å†å²è§†è§’</a>
  </nav>

  <main class="main">
    <h1>Chapter 6: Problems and Applications<br><span style="font-size:0.6em;color:var(--text-secondary)">é—®é¢˜ä¸åº”ç”¨ â€” GDL å¦‚ä½•æ”¹å˜ä¸–ç•Œ</span></h1>

    <div class="callout callout-info" id="overview">
      <h4>æœ¬ç« æ¦‚è¿°</h4>
      <p>ä¸å˜æ€§å’Œå¯¹ç§°æ€§åœ¨ç°å®ä¸–ç•Œæ•°æ®ä¸­<strong>æ— å¤„ä¸åœ¨</strong>ã€‚å› æ­¤ï¼Œ21 ä¸–çºªæœºå™¨å­¦ä¹ æœ€å—æ¬¢è¿çš„åº”ç”¨æœ‰è®¸å¤šç›´æ¥æ¥è‡ª Geometric Deep Learningï¼Œæœ‰æ—¶ç”šè‡³å¹¶æœªå®Œå…¨æ„è¯†åˆ°è¿™ä¸€äº‹å®ã€‚æœ¬ç« æä¾› GDL åº”ç”¨çš„å…¨æ™¯æ‰«æï¼š</p>
      <ul>
        <li><strong>åŒ–å­¦ä¸è¯ç‰©</strong> â€” åˆ†å­å›¾ä¸Šçš„ GNN é©å‘½</li>
        <li><strong>è›‹ç™½è´¨ç”Ÿç‰©å­¦</strong> â€” AlphaFold å’Œ MaSIF</li>
        <li><strong>æ¨èç³»ç»Ÿ</strong> â€” å½±å“æ•°åäº¿ç”¨æˆ·</li>
        <li><strong>äº¤é€šé¢„æµ‹</strong> â€” Google Maps çš„ GNN å¼•æ“</li>
        <li><strong>è®¡ç®—æœºè§†è§‰</strong> â€” ImageNet åˆ°ç›®æ ‡æ£€æµ‹</li>
        <li><strong>ç²’å­ç‰©ç†</strong> â€” ä» LHC åˆ°ä¸­å¾®å­å¤©æ–‡å­¦</li>
        <li><strong>åŒ»ç–—æœºå™¨äºº</strong> â€” ä¸ PhysRobot çš„ç›´æ¥å…³è” ğŸ¤–</li>
      </ul>
      <p><strong>é¢„è®¡é˜…è¯»æ—¶é—´</strong>ï¼š3 å°æ—¶ &nbsp;|&nbsp; <strong>æ¯ä¸ªåº”ç”¨</strong>ï¼šé—®é¢˜å®šä¹‰ + å›¾ç»“æ„ + æ¨¡å‹ + ä»£ç  + ç»“æœ</p>
    </div>

    <!-- ========= 6.1 åŒ–å­¦ä¸è¯ç‰©å‘ç° ========= -->
    <h2 id="chemistry">6.1 åŒ–å­¦ä¸è¯ç‰©å‘ç°<br><span style="font-size:0.7em;color:var(--text-secondary)">Chemistry and Drug Design</span></h2>

    <h3 id="mol-graphs">åˆ†å­å³å›¾</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å›¾ä¸Šè¡¨å¾å­¦ä¹ æœ€æœ‰å‰æ™¯çš„åº”ç”¨ä¹‹ä¸€æ˜¯<strong>è®¡ç®—åŒ–å­¦</strong>å’Œ<strong>è¯ç‰©å¼€å‘</strong>ã€‚ä¼ ç»Ÿè¯ç‰©æ˜¯å°åˆ†å­ï¼Œè¢«è®¾è®¡ä¸ºä¸ç›®æ ‡åˆ†å­ï¼ˆé€šå¸¸æ˜¯è›‹ç™½è´¨ï¼‰åŒ–å­¦ç»“åˆï¼ˆ'ç»“åˆ'ï¼‰ï¼Œä»¥æ¿€æ´»æˆ–ç ´åæŸäº›ä¸ç–¾ç—…ç›¸å…³çš„åŒ–å­¦è¿‡ç¨‹ã€‚</p>
        <p>è¯ç‰©å¼€å‘æ˜¯ä¸€ä¸ªæå…¶æ¼«é•¿ä¸”æ˜‚è´µçš„è¿‡ç¨‹ï¼šå°†ä¸€ç§æ–°è¯æ¨å‘å¸‚åœºé€šå¸¸éœ€è¦<strong>è¶…è¿‡åå¹´</strong>ï¼ŒèŠ±è´¹<strong>è¶…è¿‡åäº¿ç¾å…ƒ</strong>ã€‚ä¸åˆ° 5% çš„å€™é€‰è¯ç‰©èƒ½è¿›å…¥æœ€åé˜¶æ®µã€‚</p>
      </div>
      <div class="en">
        One of the most promising applications of representation learning on graphs is in computational chemistry and drug development. Drug development typically takes more than a decade and costs more than a billion dollars, with less than 5% of candidates making it to the last stage.
      </div>
    </div>

    <div class="math-block">
      $$\text{åˆ†å­å›¾: } G = (\mathcal{V}, \mathcal{E}) \quad \text{where } \mathcal{V} = \text{atoms}, \; \mathcal{E} = \text{bonds}$$
      $$\text{èŠ‚ç‚¹ç‰¹å¾: } x_v = (\text{åŸå­ç±»å‹}, \text{ç”µè·}, \text{ä»·æ€}, \text{æ‰‹æ€§}, \ldots)$$
      $$\text{è¾¹ç‰¹å¾: } e_{uv} = (\text{é”®ç±»å‹: å•/åŒ/ä¸‰/èŠ³é¦™}, \text{æ˜¯å¦åœ¨ç¯ä¸­}, \ldots)$$
      <div class="math-explain">
        åˆ†å­å¤©ç„¶åœ°è¡¨ç¤ºä¸ºå›¾ï¼š<strong>åŸå­</strong>æ˜¯èŠ‚ç‚¹ï¼Œ<strong>åŒ–å­¦é”®</strong>æ˜¯è¾¹ã€‚èŠ‚ç‚¹å’Œè¾¹éƒ½æœ‰ä¸°å¯Œçš„ç‰¹å¾ã€‚åŒ–å­¦åˆæˆç©ºé—´ä¼°è®¡çº¦æœ‰ $10^{60}$ ç§åˆ†å­â€”â€”è¿™ä½¿å¾—å®éªŒç­›é€‰ä¸å¯èƒ½ï¼Œå¿…é¡»ä¾èµ–<strong>è™šæ‹Ÿç­›é€‰</strong>ï¼ˆin silico screeningï¼‰ã€‚
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p107_img0.png" alt="Halicin molecular graph">
      <figcaption>Halicin çš„åˆ†å­å›¾ã€‚GNN é¢„æµ‹å®ƒæ˜¯ä¸€ç§é«˜æ•ˆçš„å¹¿è°±æŠ—ç”Ÿç´ ï¼Œç”šè‡³å¯¹å·²çŸ¥å…·æœ‰æŠ—è¯æ€§çš„ç»†èŒæ ªä¹Ÿæœ‰æ•ˆã€‚</figcaption>
    </div>

    <h3 id="halicin">é‡Œç¨‹ç¢‘ï¼šHalicin çš„å‘ç°</h3>

    <div class="bilingual">
      <div class="zh">
        <p>Stokes et al. (2020) ä½¿ç”¨ GNN è®­ç»ƒé¢„æµ‹å€™é€‰åˆ†å­æ˜¯å¦æŠ‘åˆ¶å¤§è‚ æ†èŒç”Ÿé•¿ï¼ŒæˆåŠŸå‘ç° <strong>Halicin</strong>â€”â€”ä¸€ç§åŸæœ¬ç”¨äºæ²»ç–—ç³–å°¿ç—…çš„åˆ†å­â€”â€”å®é™…ä¸Šæ˜¯ä¸€ç§é«˜æ•ˆçš„<strong>å¹¿è°±æŠ—ç”Ÿç´ </strong>ï¼Œç”šè‡³å¯¹å·²çŸ¥å…·æœ‰æŠ—ç”Ÿç´ æŠ—æ€§çš„ç»†èŒæ ªä¹Ÿæœ‰æ•ˆã€‚è¿™ä¸€å‘ç°è¢«ç§‘å­¦ç•Œå’Œå¤§ä¼—åª’ä½“å¹¿æ³›æŠ¥é“ã€‚</p>
      </div>
      <div class="en">
        Stokes et al. (2020) used a GNN to effectively discover that Halicin, originally indicated for treating diabetes, is a highly potent antibiotic, even against bacteria strains with known antibiotic resistance.
      </div>
    </div>

    <pre><code># åˆ†å­å±æ€§é¢„æµ‹çš„ GNN (ç®€åŒ–ç‰ˆ)
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data

class MolecularGNN(nn.Module):
    """
    åˆ†å­å±æ€§é¢„æµ‹çš„å›¾ç¥ç»ç½‘ç»œ
    
    GDL è§†è§’:
    - åŸŸ: åˆ†å­å›¾ (åŸå­=èŠ‚ç‚¹, é”®=è¾¹)
    - å¯¹ç§°ç¾¤: Î£_n (åŸå­æ’åˆ—å¯¹ç§°)
    - ç­‰å˜å±‚: GCN æ¶ˆæ¯ä¼ é€’
    - ä¸å˜è¾“å‡º: å…¨å±€æ± åŒ– â†’ åˆ†å­çº§å±æ€§
    """
    def __init__(self, num_atom_features=9, hidden=64, num_classes=2):
        super().__init__()
        self.conv1 = GCNConv(num_atom_features, hidden)
        self.conv2 = GCNConv(hidden, hidden)
        self.conv3 = GCNConv(hidden, hidden)
        self.classifier = nn.Sequential(
            nn.Linear(hidden, 32),
            nn.ReLU(),
            nn.Linear(32, num_classes)
        )
        self.relu = nn.ReLU()
    
    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        
        # ç­‰å˜å±‚: æ¶ˆæ¯ä¼ é€’ (ç½®æ¢ç­‰å˜)
        x = self.relu(self.conv1(x, edge_index))
        x = self.relu(self.conv2(x, edge_index))
        x = self.relu(self.conv3(x, edge_index))
        
        # ä¸å˜æ± åŒ–: å…¨å±€å¹³å‡ (ç½®æ¢ä¸å˜)
        x = global_mean_pool(x, batch)
        
        # åˆ†ç±»: åˆ†å­çº§é¢„æµ‹
        return self.classifier(x)

# åˆ›å»ºä¸€ä¸ªç®€å•çš„åˆ†å­å›¾ (æ°´åˆ†å­ H2O)
# 3 ä¸ªåŸå­: O, H, H
x = torch.tensor([
    [8, 0, 0, 0, 0, 0, 0, 0, 2],  # æ°§ (åŸå­åºæ•°=8, ä»·=2)
    [1, 0, 0, 0, 0, 0, 0, 0, 1],  # æ°¢
    [1, 0, 0, 0, 0, 0, 0, 0, 1],  # æ°¢
], dtype=torch.float)

edge_index = torch.tensor([[0,0,1,2],[1,2,0,0]], dtype=torch.long)
data = Data(x=x, edge_index=edge_index, batch=torch.zeros(3, dtype=torch.long))

model = MolecularGNN()
pred = model(data)
print(f"åˆ†å­å›¾: {data.num_nodes} åŸå­, {data.num_edges} é”®")
print(f"é¢„æµ‹è¾“å‡º: {pred.shape} (æŠ‘èŒæ´»æ€§æ¦‚ç‡)")</code></pre>

    <h3 id="drug-repo">è¯ç‰©é‡å®šä½ (Drug Repositioning)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>æ¯”ç”Ÿæˆå…¨æ–°è¯ç‰©æ›´å¿«ã€æ›´ä¾¿å®œçš„é€”å¾„æ˜¯<span class="term">è¯ç‰©é‡å®šä½</span>â€”â€”è¯„ä¼°å·²æ‰¹å‡†çš„è¯ç‰©ç”¨äºæ–°ç”¨é€”ã€‚åœ¨æŸä¸ªæŠ½è±¡å±‚é¢ä¸Šï¼Œè¯ç‰©å¯¹äººä½“ç”ŸåŒ–çš„ä½œç”¨åŠå…¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨å¯ä»¥å»ºæ¨¡ä¸º<strong>å›¾</strong>ï¼Œå‚¬ç”Ÿäº† Albert-LÃ¡szlÃ³ BarabÃ¡si æå‡ºçš„"<strong>ç½‘ç»œåŒ»å­¦</strong>"æ¦‚å¿µã€‚</p>
        <p>Zitnik et al. (2018) ç”¨ GNN é¢„æµ‹è”åˆç”¨è¯çš„å‰¯ä½œç”¨ï¼ˆå¤šè¯ç†å­¦ï¼‰ï¼Œå°†é—®é¢˜å½¢å¼åŒ–ä¸ºè¯ç‰©-è¯ç‰©äº¤äº’å›¾ä¸Šçš„<strong>è¾¹é¢„æµ‹</strong>ä»»åŠ¡ã€‚</p>
      </div>
      <div class="en">
        Drug repositioning seeks to evaluate already-approved drugs for a novel purpose. The drug-drug interaction network is modeled as a graph, and GNNs predict side effects as an edge prediction task.
      </div>
    </div>

    <h3 id="equivariant-mol">ç­‰å˜åˆ†å­ç½‘ç»œ</h3>

    <div class="bilingual">
      <div class="zh">
        <p>æ›´å…ˆè¿›çš„åˆ†å­ GNN ä¸ä»…è€ƒè™‘å›¾æ‹“æ‰‘ï¼Œè¿˜è€ƒè™‘åˆ†å­çš„<strong>3D å‡ ä½•ç»“æ„</strong>ï¼Œå¹¶èå…¥å¯¹æ—‹è½¬å’Œå¹³ç§»çš„<strong>ç­‰å˜æ€§</strong>ï¼š</p>
        <ul>
          <li><strong>SchNet</strong> (SchÃ¼tt et al., 2018): ä½¿ç”¨è¿ç»­æ»¤æ³¢å™¨å’ŒåŸå­é—´è·ç¦»</li>
          <li><strong>DimeNet</strong> (Gasteiger et al., 2020): åŠ å…¥é”®è§’ä¿¡æ¯</li>
          <li><strong>EGNN</strong> (Satorras et al., 2021): E(n)-ç­‰å˜ï¼Œç›´æ¥æ›´æ–°åæ ‡</li>
          <li><strong>PaiNN</strong> (SchÃ¼tt et al., 2021): ç­‰å˜æ¶ˆæ¯ä¼ é€’ï¼Œå‘é‡ç‰¹å¾</li>
          <li><strong>TFN</strong> (Thomas et al., 2018): ä½¿ç”¨çƒè°å‡½æ•°çš„å¼ é‡åœºç½‘ç»œ</li>
        </ul>
      </div>
      <div class="en">
        More advanced molecular GNNs incorporate 3D geometry with equivariance to rotations and translations: SchNet, DimeNet, EGNN, PaiNN, TFN.
      </div>
    </div>

    <div class="math-block">
      $$\text{EGNN æ›´æ–°è§„åˆ™:} \quad h_i^{(l+1)} = \phi_h\left(h_i^{(l)}, \sum_{j \neq i} \phi_e(h_i^{(l)}, h_j^{(l)}, \|r_i - r_j\|^2, a_{ij})\right)$$
      $$r_i^{(l+1)} = r_i^{(l)} + \sum_{j \neq i} (r_i^{(l)} - r_j^{(l)}) \cdot \phi_r(m_{ij})$$
      <div class="math-explain">
        <strong>EGNN çš„å…³é”®è®¾è®¡</strong>ï¼š
        <br>â€¢ æ ‡é‡ç‰¹å¾ $h_i$ çš„æ›´æ–°ä½¿ç”¨ä¸å˜é‡ $\|r_i - r_j\|^2$ï¼ˆæ—‹è½¬ä¸å˜ï¼‰
        <br>â€¢ åæ ‡ $r_i$ çš„æ›´æ–°æ–¹å‘æ²¿ç€ $(r_i - r_j)$ï¼ˆæ—‹è½¬ç­‰å˜ï¼‰
        <br>â€¢ æ•´ä¸ªç½‘ç»œè‡ªåŠ¨æ»¡è¶³ E(n)-ç­‰å˜æ€§ï¼Œæ— éœ€æ•°æ®å¢å¼ºï¼
      </div>
    </div>

    <pre><code># E(n) ç­‰å˜å›¾ç¥ç»ç½‘ç»œ (EGNN) ç®€åŒ–å®ç°
import torch
import torch.nn as nn

class EGNNLayer(nn.Module):
    """
    E(n)-Equivariant Graph Neural Network Layer
    
    æ€§è´¨:
    - æ ‡é‡ç‰¹å¾ h å¯¹æ—‹è½¬/å¹³ç§»/åå°„ ä¸å˜
    - åæ ‡ r å¯¹æ—‹è½¬/å¹³ç§»/åå°„ ç­‰å˜
    """
    def __init__(self, hidden_dim=64):
        super().__init__()
        # æ¶ˆæ¯å‡½æ•°: ä½¿ç”¨ä¸å˜é‡ (è·ç¦»)
        self.edge_mlp = nn.Sequential(
            nn.Linear(2 * hidden_dim + 1, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        # èŠ‚ç‚¹æ›´æ–°
        self.node_mlp = nn.Sequential(
            nn.Linear(2 * hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        # åæ ‡æ›´æ–°æƒé‡
        self.coord_mlp = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, 1)
        )
    
    def forward(self, h, r, edge_index):
        src, dst = edge_index
        
        # 1. è®¡ç®—ä¸å˜é‡: è·ç¦»çš„å¹³æ–¹
        r_diff = r[src] - r[dst]
        dist_sq = (r_diff ** 2).sum(dim=-1, keepdim=True)  # æ—‹è½¬ä¸å˜!
        
        # 2. è¾¹æ¶ˆæ¯ (ä½¿ç”¨ä¸å˜é‡)
        edge_feat = torch.cat([h[src], h[dst], dist_sq], dim=-1)
        m_ij = self.edge_mlp(edge_feat)
        
        # 3. èšåˆæ¶ˆæ¯
        agg = torch.zeros_like(h)
        agg.index_add_(0, dst, m_ij)
        
        # 4. æ›´æ–°èŠ‚ç‚¹ç‰¹å¾ (ä¸å˜)
        h_new = self.node_mlp(torch.cat([h, agg], dim=-1))
        
        # 5. æ›´æ–°åæ ‡ (ç­‰å˜!)
        # r_new = r + Î£_j (r_i - r_j) * Ï†(m_ij)
        coord_weights = self.coord_mlp(m_ij)
        coord_agg = torch.zeros_like(r)
        coord_agg.index_add_(0, dst, r_diff * coord_weights)
        r_new = r + coord_agg
        
        return h_new, r_new

# æ¼”ç¤º
layer = EGNNLayer(hidden_dim=32)
h = torch.randn(5, 32)  # 5ä¸ªåŸå­çš„æ ‡é‡ç‰¹å¾
r = torch.randn(5, 3)    # 5ä¸ªåŸå­çš„3Dåæ ‡
edges = torch.tensor([[0,1,2,3],[1,2,3,4]], dtype=torch.long)

h_new, r_new = layer(h, r, edges)

# éªŒè¯ç­‰å˜æ€§: æ—‹è½¬è¾“å…¥åæ ‡
theta = torch.tensor(0.5)
R = torch.tensor([  # ç»•zè½´æ—‹è½¬
    [torch.cos(theta), -torch.sin(theta), 0],
    [torch.sin(theta),  torch.cos(theta), 0],
    [0, 0, 1]
], dtype=torch.float)

r_rotated = r @ R.T
h_rot, r_rot = layer(h, r_rotated, edges)

# r_rot åº”è¯¥ç­‰äº r_new @ R.T (ç­‰å˜!)
print(f"ç­‰å˜æ€§è¯¯å·®: {(r_rot - r_new @ R.T).abs().max():.6f}")
# â†’ åº”è¯¥æ¥è¿‘ 0 (æ•°å€¼ç²¾åº¦)</code></pre>

    <!-- ========= 6.2 è›‹ç™½è´¨ç”Ÿç‰©å­¦ ========= -->
    <h2 id="proteins">6.2 è›‹ç™½è´¨ç”Ÿç‰©å­¦<br><span style="font-size:0.7em;color:var(--text-secondary)">Protein Biology</span></h2>

    <h3 id="protein-folding">è›‹ç™½è´¨æŠ˜å é—®é¢˜</h3>

    <div class="bilingual">
      <div class="zh">
        <p>è›‹ç™½è´¨æ˜¯<strong>ç”Ÿç‰©é«˜åˆ†å­</strong>ï¼Œç”±æ°¨åŸºé…¸é“¾åœ¨é™ç”µåŠ›çš„å½±å“ä¸‹æŠ˜å æˆå¤æ‚çš„ 3D ç»“æ„ã€‚æ­£æ˜¯è¿™ç§ç»“æ„èµ‹äºˆè›‹ç™½è´¨å…¶åŠŸèƒ½ï¼š</p>
        <ul>
          <li><strong>æŠ—ä½“</strong>ï¼šä¿æŠ¤èº«ä½“æŠµå¾¡ç—…åŸä½“</li>
          <li><strong>èƒ¶åŸè›‹ç™½</strong>ï¼šèµ‹äºˆçš®è‚¤ç»“æ„</li>
          <li><strong>è¡€çº¢è›‹ç™½</strong>ï¼šå°†æ°§æ°”è¾“é€åˆ°ç»†èƒ</li>
          <li><strong>é…¶</strong>ï¼šå‚¬åŒ–åŒ–å­¦ååº”</li>
        </ul>
        <p>è›‹ç™½è´¨ç”Ÿç‰©ä¿¡æ¯å­¦çš„å…¸å‹å±‚çº§é—®é¢˜ï¼š<strong>åºåˆ—</strong>ï¼ˆ1D å­—ç¬¦ä¸²ï¼‰â†’ <strong>3D ç»“æ„</strong>ï¼ˆè›‹ç™½è´¨æŠ˜å ï¼‰â†’ <strong>åŠŸèƒ½</strong>ï¼ˆåŠŸèƒ½é¢„æµ‹ï¼‰ã€‚</p>
      </div>
      <div class="en">
        Proteins are biopolymers that fold into complex 3D structures under electrostatic forces. The typical hierarchy: sequence â†’ structure (folding) â†’ function.
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p108_img0.png" alt="Protein structure">
      <figcaption>è›‹ç™½è´¨ä»æ°¨åŸºé…¸åºåˆ—åˆ°3Dç»“æ„çš„æŠ˜å è¿‡ç¨‹ã€‚Fischer çš„"é’¥åŒ™-é”åŸç†"(1894)ï¼šä¸¤ä¸ªè›‹ç™½è´¨é€šå¸¸åªæœ‰åœ¨å…·æœ‰å‡ ä½•å’ŒåŒ–å­¦äº’è¡¥ç»“æ„æ—¶æ‰ä¼šç›¸äº’ä½œç”¨ã€‚</figcaption>
    </div>

    <h3 id="alphafold">AlphaFold: ç»“æ„é¢„æµ‹çš„é©å‘½</h3>

    <div class="bilingual">
      <div class="zh">
        <p>DeepMind çš„ <strong>AlphaFold</strong> (Senior et al., 2020) ä½¿ç”¨<strong>æ¥è§¦å›¾</strong>ï¼ˆcontact graphsï¼‰è¡¨ç¤ºè›‹ç™½è´¨ç»“æ„ï¼Œåœ¨ CASP14 ç«èµ›ä¸­ä»¥å‹å€’æ€§ä¼˜åŠ¿è·èƒœï¼Œè¢«è®¤ä¸º<strong>"è§£å†³"äº†è›‹ç™½è´¨ç»“æ„é¢„æµ‹é—®é¢˜</strong>â€”â€”è¿™æ˜¯ç”Ÿç‰©å­¦ä¸­ 50 å¹´æ¥çš„å¤§æŒ‘æˆ˜ã€‚</p>
        <p>AlphaFold 2 çš„å…³é”®åˆ›æ–°åŒ…æ‹¬ï¼š</p>
        <ul>
          <li><strong>Evoformer</strong>: åœ¨åºåˆ—å’Œç©ºé—´ä¸¤ä¸ªç»´åº¦ä¸Šäº¤æ›¿æ³¨æ„åŠ›</li>
          <li><strong>SE(3)-ç­‰å˜ç»“æ„æ¨¡å—</strong>: å°† 2D æ³¨æ„åŠ›è¾“å‡ºè½¬åŒ–ä¸º 3D åæ ‡</li>
          <li><strong>å¤šåºåˆ—æ¯”å¯¹</strong> (MSA): åˆ©ç”¨è¿›åŒ–ä¿¡æ¯</li>
          <li><strong>å›æ”¶æœºåˆ¶</strong>: è¿­ä»£ç²¾åŒ–ç»“æ„é¢„æµ‹</li>
        </ul>
      </div>
      <div class="en">
        DeepMind's AlphaFold used contact graphs to represent protein structure, winning CASP14 by a large margin and effectively "solving" the protein structure prediction problem.
      </div>
    </div>

    <div class="math-block">
      $$\text{AlphaFold çš„ GDL è§†è§’:}$$
      $$\text{åŸŸ: } \Omega = \text{æ°¨åŸºé…¸æ®‹åŸºçš„å®Œå…¨å›¾} \quad \text{å¯¹ç§°ç¾¤: } G = SE(3)$$
      $$\text{è¾“å…¥: } \text{åºåˆ— + MSA + æ¨¡æ¿} \xrightarrow{\text{Evoformer}} \text{è·ç¦»çŸ©é˜µ} \xrightarrow{\text{SE(3)-ç­‰å˜}} \text{3D åæ ‡}$$
      <div class="math-explain">
        AlphaFold æ˜¯ GDL åŸåˆ™çš„è¾‰ç…Œå®è·µï¼šå®ƒåˆ©ç”¨äº†è›‹ç™½è´¨ç»“æ„å¯¹ SE(3)ï¼ˆæ—‹è½¬+å¹³ç§»ï¼‰çš„<strong>ç­‰å˜æ€§</strong>ï¼ˆç»“æ„ä¸ä¾èµ–äºåæ ‡ç³»é€‰æ‹©ï¼‰ï¼Œä»¥åŠæ°¨åŸºé…¸æ®‹åŸºä¹‹é—´çš„å›¾ç»“æ„ä¸Šçš„<strong>ç½®æ¢ç­‰å˜æ€§</strong>ã€‚
      </div>
    </div>

    <h3 id="masif">MaSIF: è›‹ç™½è´¨è¡¨é¢æ–¹æ³•</h3>

    <div class="bilingual">
      <div class="zh">
        <p>Gainza et al. (2020) å¼€å‘äº† <strong>MaSIF</strong>ï¼ˆMolecular Surface Interaction Fingerprintingï¼‰ï¼Œä»è›‹ç™½è´¨çš„ 3D ç»“æ„é¢„æµ‹è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ã€‚MaSIF å°†è›‹ç™½è´¨å»ºæ¨¡ä¸º<strong>åˆ†å­è¡¨é¢</strong>ï¼ˆç¦»æ•£åŒ–ä¸ºç½‘æ ¼ï¼‰ï¼Œåœ¨å±€éƒ¨æµ‹åœ°è¡¥ä¸ä¸Šä½¿ç”¨<strong>ç½‘æ ¼å·ç§¯ç¥ç»ç½‘ç»œ</strong>ã€‚</p>
        <p>MaSIF æˆåŠŸå®ç°äº†<strong>ä»å¤´è®¾è®¡</strong>ï¼ˆde novoï¼‰è›‹ç™½è´¨â€”â€”å¯ä»¥æŠ‘åˆ¶ PD-1/PD-L1 å¤åˆç‰©çš„è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨ï¼Œè¿™åœ¨<strong>ç™Œç—‡å…ç–«æ²»ç–—</strong>ä¸­è‡³å…³é‡è¦ã€‚</p>
      </div>
      <div class="en">
        MaSIF models proteins as molecular surfaces (meshes) and uses mesh CNNs on local geodesic patches. It enabled de novo protein design for cancer immunotherapy (PD-1/PD-L1 inhibition).
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p109_img0.png" alt="MaSIF protein surface">
      <figcaption>PD-L1 è›‹ç™½è´¨è¡¨é¢ï¼ˆçƒ­åŠ›å›¾æ˜¾ç¤ºé¢„æµ‹çš„ç»“åˆä½ç‚¹ï¼‰å’Œè®¾è®¡çš„ç»“åˆè›‹ç™½ï¼ˆæ˜¾ç¤ºä¸ºå¸¦çŠ¶å›¾ï¼‰ã€‚è¿™ç§ä»å‡ ä½•è§’åº¦è®¾è®¡çš„è›‹ç™½è´¨æœ‰æ½œåŠ›ä½œä¸ºç™Œç—‡å…ç–«æ²»ç–—è¯ç‰©ã€‚</figcaption>
    </div>

    <!-- ========= 6.3 æ¨èç³»ç»Ÿ ========= -->
    <h2 id="recommender">6.3 æ¨èç³»ç»Ÿä¸ç¤¾äº¤ç½‘ç»œ<br><span style="font-size:0.7em;color:var(--text-secondary)">Recommender Systems and Social Networks</span></h2>

    <h3 id="pinsage">PinSage: å·¥ä¸šçº§ GNN æ¨è</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å›¾è¡¨å¾å­¦ä¹ çš„ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡å·¥ä¸šåº”ç”¨å‘ç”Ÿåœ¨<strong>ç¤¾äº¤ç½‘ç»œ</strong>ä¸­ï¼Œä¸»è¦æ˜¯æ¨èç³»ç»Ÿã€‚æ¨èç³»ç»Ÿè´Ÿè´£å†³å®šå‘ç”¨æˆ·æä¾›å“ªäº›å†…å®¹ï¼Œé€šå¸¸é€šè¿‡<strong>é“¾æ¥é¢„æµ‹</strong>ç›®æ ‡å®ç°ã€‚</p>
        <p>Pinterest çš„ <strong>PinSage</strong> (Ying et al., 2018) æ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸéƒ¨ç½²åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„ GNNï¼Œå°†å›¾è¡¨å¾å­¦ä¹ <strong>æ‰©å±•åˆ°æ•°ç™¾ä¸‡èŠ‚ç‚¹å’Œæ•°åäº¿è¾¹</strong>çš„å›¾ã€‚</p>
        <p>åç»­åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²çš„ GNN æ¨èç³»ç»ŸåŒ…æ‹¬ï¼š</p>
        <ul>
          <li>é˜¿é‡Œå·´å·´çš„ <strong>Aligraph</strong> (Zhu et al., 2019)</li>
          <li>äºšé©¬é€Šçš„ <strong>P-Companion</strong> (Hao et al., 2020)</li>
        </ul>
        <p>é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå›¾æ·±åº¦å­¦ä¹ æ¯å¤©å½±å“ç€<strong>æ•°ç™¾ä¸‡</strong>äººçš„æ—¥å¸¸ç”Ÿæ´»ã€‚</p>
      </div>
      <div class="en">
        PinSage (Pinterest) was the first successful production deployment of GNNs, scaling to graphs with millions of nodes and billions of edges. GNN-backed recommenders from Alibaba and Amazon followed.
      </div>
    </div>

    <pre><code># æ¨èç³»ç»Ÿä¸­çš„ GNN: é“¾æ¥é¢„æµ‹
import torch
import torch.nn as nn
from torch_geometric.nn import SAGEConv

class RecommenderGNN(nn.Module):
    """
    ç®€åŒ–çš„æ¨èç³»ç»Ÿ GNN (PinSage é£æ ¼)
    
    GDL è§†è§’:
    - åŸŸ: ç”¨æˆ·-ç‰©å“äºŒéƒ¨å›¾
    - å¯¹ç§°ç¾¤: èŠ‚ç‚¹ç½®æ¢ Î£_n
    - ä»»åŠ¡: é“¾æ¥é¢„æµ‹ (é¢„æµ‹ç”¨æˆ·æ˜¯å¦ä¼šä¸ç‰©å“äº¤äº’)
    """
    def __init__(self, num_features=128, hidden=256, out=128):
        super().__init__()
        self.conv1 = SAGEConv(num_features, hidden)
        self.conv2 = SAGEConv(hidden, out)
        self.relu = nn.ReLU()
    
    def encode(self, x, edge_index):
        """ç­‰å˜ç¼–ç : ç”ŸæˆèŠ‚ç‚¹åµŒå…¥"""
        h = self.relu(self.conv1(x, edge_index))
        h = self.conv2(h, edge_index)
        return h
    
    def predict_link(self, z, edge_label_index):
        """é“¾æ¥é¢„æµ‹: å†…ç§¯ (ä¸å˜)"""
        src, dst = edge_label_index
        return (z[src] * z[dst]).sum(dim=-1)  # å†…ç§¯ â†’ ä¸å˜
    
    def forward(self, x, edge_index, edge_label_index):
        z = self.encode(x, edge_index)
        return self.predict_link(z, edge_label_index)

print("æ¨èç³»ç»Ÿ GNN: ç­‰å˜ç¼–ç  + ä¸å˜é¢„æµ‹")
print("åµŒå…¥ç©ºé—´ä¸­çš„è¿‘é‚» = æ¨èå€™é€‰")</code></pre>

    <h3 id="misinformation">è™šå‡ä¿¡æ¯æ£€æµ‹</h3>

    <div class="bilingual">
      <div class="zh">
        <p>Fabula AIï¼ˆç”±æœ¬ä¹¦ä½œè€…ä¹‹ä¸€åˆ›ç«‹ï¼Œ2019å¹´è¢« Twitter æ”¶è´­ï¼‰å¼€å‘äº†åŸºäº GNN çš„<strong>è™šå‡ä¿¡æ¯æ£€æµ‹</strong>æŠ€æœ¯ã€‚æ–¹æ³•æ˜¯å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºåˆ†äº«ç”¨æˆ·æ„æˆçš„å›¾ï¼Œç„¶åç”¨ GNN å¯¹æ•´ä¸ªå›¾è¿›è¡Œåˆ†ç±»ï¼ˆçœŸå® vs è™šå‡ï¼‰ã€‚åˆ†æèŠ‚ç‚¹åµŒå…¥æ­ç¤ºäº†"<strong>å›éŸ³å®¤æ•ˆåº”</strong>"â€”â€”å€¾å‘äºåˆ†äº«é”™è¯¯ä¿¡æ¯çš„ç”¨æˆ·å½¢æˆæ˜æ˜¾çš„èšç±»ã€‚</p>
      </div>
      <div class="en">
        Fabula AI (acquired by Twitter in 2019) modeled news spread as a graph of sharing users, using GNN to classify the graph as true/fake content. Analyzing embeddings revealed clear "echo chamber" clustering.
      </div>
    </div>

    <!-- ========= 6.4 äº¤é€šé¢„æµ‹ ========= -->
    <h2 id="traffic">6.4 äº¤é€šé¢„æµ‹<br><span style="font-size:0.7em;color:var(--text-secondary)">Traffic Forecasting</span></h2>

    <div class="figure">
      <img src="../assets/ch6_p110_img0.png" alt="Road network graph">
      <figcaption>é“è·¯ç½‘ç»œï¼ˆä¸Šï¼‰åŠå…¶å¯¹åº”çš„å›¾è¡¨ç¤ºï¼ˆä¸‹ï¼‰ã€‚äº¤å‰å£ä½œä¸ºèŠ‚ç‚¹ï¼Œé“è·¯æ®µä½œä¸ºè¿æ¥å®ƒä»¬çš„è¾¹ã€‚</figcaption>
    </div>

    <h3 id="google-maps">Google Maps ä¸­çš„ GNN</h3>

    <div class="bilingual">
      <div class="zh">
        <p>äº¤é€šç½‘ç»œæ˜¯ GDL æŠ€æœ¯äº§ç”Ÿ<strong>æ•°åäº¿ç”¨æˆ·</strong>å½±å“çš„å¦ä¸€ä¸ªé¢†åŸŸã€‚åœ¨é“è·¯ç½‘ç»œä¸Šï¼Œäº¤å‰å£æ˜¯èŠ‚ç‚¹ï¼Œé“è·¯æ®µæ˜¯è¾¹â€”â€”è¾¹å¯ä»¥ç”¨é“è·¯é•¿åº¦ã€å½“å‰æˆ–å†å²é€Ÿåº¦ç­‰ç‰¹å¾åŒ–ã€‚</p>
        <p>DeepMind çš„åŸºäº GNN çš„ ETA é¢„æµ‹å™¨ç°å·²éƒ¨ç½²åœ¨ <strong>Google Maps</strong> ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåœ¨å…¨çƒå¤šä¸ªä¸»è¦åŸå¸‚æä¾› ETA æŸ¥è¯¢æœåŠ¡ã€‚åœ¨æ‚‰å°¼ç­‰åŸå¸‚ï¼Œ<strong>é¢„æµ‹è´¨é‡æå‡è¶…è¿‡ 40%</strong>ã€‚</p>
        <p>ç™¾åº¦åœ°å›¾ä¹Ÿä½¿ç”¨ <strong>ConSTGAT</strong>ï¼ˆæ—¶ç©ºå›¾æ³¨æ„åŠ›ç½‘ç»œå˜ä½“ï¼‰æ¥æä¾›å‡ºè¡Œæ—¶é—´é¢„æµ‹ã€‚</p>
      </div>
      <div class="en">
        DeepMind's GNN-based ETA predictor is deployed in Google Maps, yielding 40+% improvements in prediction quality in cities like Sydney. Baidu Maps uses a spatio-temporal GAT variant (ConSTGAT).
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p110_img1.png" alt="Google Maps GNN improvements">
      <figcaption>GNN åœ¨ Google Maps ä¸­éƒ¨ç½²çš„åŸå¸‚åŠå…¶é¢„æµ‹è´¨é‡çš„ç›¸å¯¹æ”¹å–„ï¼ˆæ‚‰å°¼ç­‰åŸå¸‚è¶…è¿‡ 40%ï¼‰ã€‚</figcaption>
    </div>

    <pre><code># äº¤é€šé¢„æµ‹çš„æ—¶ç©º GNN (ç®€åŒ–ç‰ˆ)
import torch
import torch.nn as nn

class SpatioTemporalGNN(nn.Module):
    """
    æ—¶ç©ºå›¾ç¥ç»ç½‘ç»œç”¨äºäº¤é€šé¢„æµ‹
    
    GDL è§†è§’:
    - ç©ºé—´åŸŸ: é“è·¯ç½‘ç»œå›¾ (äº¤å‰å£=èŠ‚ç‚¹, é“è·¯=è¾¹)
    - æ—¶é—´åŸŸ: æ—¶é—´åºåˆ— (1D ç½‘æ ¼)
    - å¯¹ç§°ç¾¤: ç©ºé—´ä¸Šçš„å›¾ç½®æ¢ Ã— æ—¶é—´ä¸Šçš„å¹³ç§»
    - ä»»åŠ¡: é¢„æµ‹åˆ°è¾¾æ—¶é—´ (ETA) â€” å›¾å›å½’
    """
    def __init__(self, node_features=8, hidden=64, time_steps=12):
        super().__init__()
        # ç©ºé—´ç¼–ç : GNN
        self.spatial_conv1 = nn.Linear(node_features, hidden)
        self.spatial_conv2 = nn.Linear(hidden, hidden)
        
        # æ—¶é—´ç¼–ç : 1D å·ç§¯ (æ—¶é—´å¹³ç§»ç­‰å˜)
        self.temporal_conv = nn.Conv1d(hidden, hidden, kernel_size=3, padding=1)
        
        # è¾“å‡º: é¢„æµ‹ ETA
        self.predictor = nn.Linear(hidden, 1)
    
    def message_passing(self, x, adj):
        """ç®€å•çš„æ¶ˆæ¯ä¼ é€’ (ç©ºé—´ç­‰å˜)"""
        return torch.relu(self.spatial_conv1(adj @ x))
    
    def forward(self, x_seq, adj):
        """
        x_seq: [batch, time, nodes, features]
        adj: [nodes, nodes] é‚»æ¥çŸ©é˜µ
        """
        B, T, N, F = x_seq.shape
        
        # 1. ç©ºé—´æ¶ˆæ¯ä¼ é€’ (æ¯ä¸ªæ—¶é—´æ­¥)
        spatial_out = []
        for t in range(T):
            h = self.message_passing(x_seq[:, t], adj)
            spatial_out.append(h)
        spatial = torch.stack(spatial_out, dim=1)  # [B, T, N, H]
        
        # 2. æ—¶é—´å·ç§¯ (æ¯ä¸ªèŠ‚ç‚¹)
        B, T, N, H = spatial.shape
        temporal = spatial.permute(0, 2, 3, 1).reshape(B*N, H, T)
        temporal = self.temporal_conv(temporal)  # æ—¶é—´å¹³ç§»ç­‰å˜
        temporal = temporal[:, :, -1]  # æœ€åæ—¶é—´æ­¥
        temporal = temporal.reshape(B, N, H)
        
        # 3. å…¨å±€æ± åŒ– â†’ ETA é¢„æµ‹
        graph_feat = temporal.mean(dim=1)  # å…¨å±€å¹³å‡ (ä¸å˜)
        return self.predictor(graph_feat)

print("æ—¶ç©º GNN: ç©ºé—´æ¶ˆæ¯ä¼ é€’ + æ—¶é—´å·ç§¯")
print("éƒ¨ç½²äº Google Maps, å½±å“æ•°åäº¿ç”¨æˆ·")</code></pre>

    <!-- ========= 6.5 è®¡ç®—æœºè§†è§‰ ========= -->
    <h2 id="vision">6.5 è®¡ç®—æœºè§†è§‰<br><span style="font-size:0.7em;color:var(--text-secondary)">Object Recognition</span></h2>

    <h3 id="imagenet">ImageNet é©å‘½</h3>

    <div class="bilingual">
      <div class="zh">
        <p>æœºå™¨å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸»è¦åŸºå‡†æ˜¯<strong>å¯¹è±¡åˆ†ç±»</strong>â€”â€”åˆ†ç±»å›¾åƒä¸­çš„ä¸­å¿ƒå¯¹è±¡ã€‚<strong>ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›</strong>ï¼ˆILSVRCï¼‰æ¨åŠ¨äº†æ—©æœŸ GDL çš„å¤§éƒ¨åˆ†å‘å±•ã€‚</p>
        <p><strong>AlexNet</strong> (Krizhevsky et al., 2012) åœ¨ ILSVRC 2012 ä¸­ä»¥å·¨å¤§ä¼˜åŠ¿è·èƒœï¼Œ<strong>å¼€åˆ›äº†æ·±åº¦å­¦ä¹ çš„å¤§è§„æ¨¡é‡‡ç”¨</strong>ã€‚æ­¤åï¼ŒCNN è¡ç”Ÿäº†è®¸å¤šè‘—åæ¶æ„ï¼š</p>
      </div>
      <div class="en">
        AlexNet's sweeping victory at ILSVRC 2012 spearheaded the adoption of deep learning. CNNs consistently ranked on top, spawning many popular architectures.
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p111_img0.jpeg" alt="ImageNet cat">
      <figcaption>ImageNet ç¤ºä¾‹å›¾åƒï¼Œä»£è¡¨ "tabby cat" ç±»åˆ«ã€‚ImageNet éœ€è¦æ¨¡å‹å°†çœŸå®å›¾åƒåˆ†ä¸º 1000 ä¸ªç±»åˆ«ã€‚</figcaption>
    </div>

    <table>
      <thead>
        <tr><th>æ¶æ„</th><th>å¹´ä»½</th><th>å…³é”®åˆ›æ–°</th><th>GDL è§†è§’</th></tr>
      </thead>
      <tbody>
        <tr><td><strong>AlexNet</strong></td><td>2012</td><td>ReLU, Dropout, GPU è®­ç»ƒ</td><td>2D ç½‘æ ¼ä¸Šçš„å¹³ç§»ç­‰å˜</td></tr>
        <tr><td><strong>VGG-16</strong></td><td>2014</td><td>å° 3Ã—3 æ»¤æ³¢å™¨å †å </td><td>æ›´æ·±çš„ç­‰å˜å±‚çº§</td></tr>
        <tr><td><strong>Inception</strong></td><td>2015</td><td>å¤šå°ºåº¦å¹¶è¡Œæ»¤æ³¢</td><td>ä¸åŒå°ºåº¦çš„ç­‰å˜ç‰¹å¾</td></tr>
        <tr><td><strong>ResNet</strong></td><td>2015</td><td>æ®‹å·®è¿æ¥</td><td>æ·±åº¦ç­‰å˜ç½‘ç»œ + skip</td></tr>
        <tr><td><strong>ViT</strong></td><td>2020</td><td>å›¾åƒ patch ä¸Šçš„ Transformer</td><td>ä»ç½‘æ ¼ç­‰å˜åˆ°é›†åˆç­‰å˜</td></tr>
      </tbody>
    </table>

    <h3 id="detection">ç›®æ ‡æ£€æµ‹ä¸è¯­ä¹‰åˆ†å‰²</h3>

    <div class="bilingual">
      <div class="zh">
        <p>ä¸åˆ†ç±»å¹¶è¡Œï¼Œ<strong>ç›®æ ‡æ£€æµ‹</strong>ä¹Ÿå–å¾—äº†é‡å¤§è¿›å±•â€”â€”åœ¨å›¾åƒä¸­å®šä½æ‰€æœ‰æ„Ÿå…´è¶£çš„å¯¹è±¡å¹¶æ ‡è®°ç±»åˆ«ã€‚è¿™éœ€è¦æ›´ç»†ç²’åº¦çš„æ–¹æ³•ï¼Œå› ä¸ºé¢„æµ‹éœ€è¦è¢«<strong>å®šä½</strong>â€”â€”å¹³ç§»<strong>ç­‰å˜</strong>æ¨¡å‹åœ¨æ­¤é¢†åŸŸè¯æ˜äº†å…¶ä»·å€¼ã€‚</p>
        <ul>
          <li><strong>R-CNN ç³»åˆ—</strong> (Girshick et al., 2014-2017): Region-based CNN</li>
          <li><strong>SegNet</strong> (Badrinarayanan et al., 2017): ç¼–ç å™¨-è§£ç å™¨åˆ†å‰²</li>
          <li><strong>U-Net</strong>: åŒ»å­¦å›¾åƒåˆ†å‰²çš„æ ‡å‡†æ¶æ„</li>
        </ul>
      </div>
      <div class="en">
        Object detection requires localized predictions â€” translation equivariant models proved their worth. R-CNN family and SegNet are influential examples.
      </div>
    </div>

    <!-- ========= 6.6 æ¸¸æˆ AI ========= -->
    <h2 id="gaming">6.6 æ¸¸æˆ AI<br><span style="font-size:0.7em;color:var(--text-secondary)">Game Playing</span></h2>

    <h3 id="alphago">AlphaGo: CNN + å¼ºåŒ–å­¦ä¹ </h3>

    <div class="bilingual">
      <div class="zh">
        <p>DeepMind çš„ <strong>AlphaGo</strong> (Silver et al., 2016) å°† CNN åº”ç”¨äº $19 \times 19$ çš„å›´æ£‹æ£‹ç›˜ï¼ˆ2D ç½‘æ ¼ï¼‰ï¼Œç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢å’Œè‡ªæˆ‘å¯¹å¼ˆï¼ŒæˆåŠŸå‡»è´¥äº†æœ€å¼ºå›´æ£‹é€‰æ‰‹ä¹‹ä¸€æä¸–ä¹­ã€‚</p>
        <p>åç»­å‘å±•ä¸æ–­å‡å°‘ç‰¹å®šé¢†åŸŸçš„åç½®ï¼š</p>
        <ul>
          <li><strong>AlphaGo Zero</strong>: çº¯è‡ªæˆ‘å¯¹å¼ˆï¼Œæ— äººç±»ç»éªŒ</li>
          <li><strong>AlphaZero</strong>: æ‰©å±•åˆ°å›½é™…è±¡æ£‹å’Œå°†æ£‹</li>
          <li><strong>MuZero</strong>: åœ¨çº¿å­¦ä¹ æ¸¸æˆè§„åˆ™</li>
        </ul>
        <p>åœ¨æ‰€æœ‰è¿™äº›å‘å±•ä¸­ï¼Œ<strong>CNN å§‹ç»ˆæ˜¯</strong>è¿™äº›æ¨¡å‹è¾“å…¥è¡¨ç¤ºçš„éª¨å¹²ã€‚</p>
      </div>
      <div class="en">
        AlphaGo applied CNNs to the 19Ã—19 Go board (2D grid), combined with MCTS and self-play. CNNs remained the backbone throughout AlphaGo â†’ AlphaGo Zero â†’ AlphaZero â†’ MuZero.
      </div>
    </div>

    <div class="math-block">
      $$\text{å›´æ£‹çŠ¶æ€ç©ºé—´: } \sim 2 \times 10^{170} \text{ åˆæ³•çŠ¶æ€}$$
      $$\text{è¿œè¶…å®‡å®™åŸå­æ•°: } \sim 10^{80}$$
      <div class="math-explain">
        å›´æ£‹çš„çŠ¶æ€ç©ºé—´æå…¶åºå¤§ï¼Œä½† CNN åˆ©ç”¨äº†æ£‹ç›˜çš„<strong>2D ç½‘æ ¼ç»“æ„</strong>å’Œ<strong>å¹³ç§»ç­‰å˜æ€§</strong>ï¼ˆå±€éƒ¨æ¨¡å¼åœ¨ä¸åŒä½ç½®æœ‰ç±»ä¼¼å«ä¹‰ï¼‰ï¼Œä½¿å¾—å­¦ä¹ å¯è¡Œã€‚è¿™æ˜¯ GDL åŸåˆ™åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„å®Œç¾ä½“ç°ã€‚
      </div>
    </div>

    <h3 id="atari">Atari ä¸ Agent57</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å¤šå¹´æ¥è®¸å¤šé«˜æ€§èƒ½ RL æ™ºèƒ½ä½“è¢«æå‡ºç”¨äº Atari 2600 å¹³å°ï¼Œä½†é•¿æœŸæ— æ³•åœ¨æ‰€æœ‰ 57 ä¸ªæ¸¸æˆä¸­è¾¾åˆ°äººç±»æ°´å¹³ã€‚è¿™ä¸ªéšœç¢æœ€ç»ˆè¢« <strong>Agent57</strong> (Badia et al., 2020) æ‰“ç ´â€”â€”å®ƒä½¿ç”¨å‚æ•°åŒ–ç­–ç•¥æ—å’Œåˆ†é˜¶æ®µè®­ç»ƒçš„ä¼˜å…ˆçº§ç­–ç•¥ã€‚å®ƒçš„è®¡ç®—éª¨å¹²ä»ç„¶æ˜¯åº”ç”¨äºæ¸¸æˆå¸§ç¼“å†²åŒºçš„ CNNã€‚</p>
      </div>
      <div class="en">
        Agent57 broke the barrier of human-level performance on all 57 Atari 2600 games, using parametric policy families with CNN backbone applied to the game's framebuffer.
      </div>
    </div>

    <!-- ========= 6.7 æ–‡æœ¬ä¸è¯­éŸ³ ========= -->
    <h2 id="text-speech">6.7 æ–‡æœ¬ä¸è¯­éŸ³åˆæˆ<br><span style="font-size:0.7em;color:var(--text-secondary)">Text and Speech Synthesis</span></h2>

    <h3 id="wavenet">WaveNet: ç©ºæ´å·ç§¯</h3>

    <div class="bilingual">
      <div class="zh">
        <p>é™¤äº†å›¾åƒï¼ˆ2D ç½‘æ ¼ï¼‰ï¼ŒGDL åœ¨<strong>ä¸€ç»´ç½‘æ ¼</strong>ä¸Šä¹Ÿå–å¾—äº†å·¨å¤§æˆåŠŸã€‚<strong>WaveNet</strong> (van den Oord et al., 2016) ä½¿ç”¨<strong>ç©ºæ´å·ç§¯</strong>ï¼ˆdilated convolutionsï¼‰ï¼Œä»¥æŒ‡æ•°å¢é•¿çš„æ„Ÿå—é‡åœ¨åŸå§‹æ³¢å½¢çº§åˆ«åˆæˆè¯­éŸ³â€”â€”äº§ç”Ÿäº†æ¯”ä»¥å‰çš„ TTS ç³»ç»Ÿ<strong>æ›´åƒäººç±»</strong>çš„è¯­éŸ³æ ·æœ¬ã€‚</p>
        <p>WaveNet çš„è®¡ç®—åæ¥è¢«è’¸é¦åˆ°æ›´ç®€å•çš„ <strong>WaveRNN</strong> æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ Google Assistant å’Œ Google Duo ç­‰æœåŠ¡ä¸­å¤§è§„æ¨¡éƒ¨ç½²ã€‚</p>
      </div>
      <div class="en">
        WaveNet used dilated convolutions for raw waveform speech synthesis (16,000+ samples/sec), producing significantly more human-like speech than previous TTS systems. Later distilled into WaveRNN for industrial-scale deployment at Google.
      </div>
    </div>

    <h3 id="gpt">GPT ä¸ Transformer é©å‘½</h3>

    <div class="bilingual">
      <div class="zh">
        <p><strong>Transformer</strong> (Vaswani et al., 2017) è¶…è¶Šäº†å¾ªç¯å’Œå·ç§¯æ¶æ„çš„å±€é™ï¼Œå±•ç¤ºäº†<strong>è‡ªæ³¨æ„åŠ›</strong>è¶³ä»¥å®ç°æœºå™¨ç¿»è¯‘çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚éšåé€šè¿‡ <strong>BERT</strong> å’Œ <strong>GPT</strong> ç³»åˆ—æ¨¡å‹ï¼Œé©å‘½äº†è‡ªç„¶è¯­è¨€å¤„ç†ã€‚</p>
        <p><strong>GPT-3</strong> (Brown et al., 2020) å°†è¯­è¨€æ¨¡å‹å­¦ä¹ æ‰©å±•åˆ° <strong>1750 äº¿</strong>ä¸ªå¯å­¦ä¹ å‚æ•°ï¼Œè®­ç»ƒäºç½‘ç»œè§„æ¨¡çš„æ–‡æœ¬è¯­æ–™ä¸Šçš„ä¸‹ä¸€è¯é¢„æµ‹ã€‚è¿™ä½¿å®ƒä¸ä»…æˆä¸ºå¼ºå¤§çš„å°‘æ ·æœ¬å­¦ä¹ å™¨ï¼Œè¿˜èƒ½ç”Ÿæˆè¿è´¯ä¸”å¬èµ·æ¥åƒäººç±»çš„æ–‡æœ¬ã€‚</p>
        <p>ä» GDL è§†è§’ï¼šGPT æ˜¯åœ¨<strong>è¯åºåˆ—</strong>ï¼ˆ1D é›†åˆ/å®Œå…¨å›¾ï¼‰ä¸Šçš„<strong>ç½®æ¢ç­‰å˜</strong>ï¼ˆé€šè¿‡ä½ç½®ç¼–ç æ‰“ç ´ï¼‰è®¡ç®—ã€‚</p>
      </div>
      <div class="en">
        Transformers surpassed the limitations of both recurrent and convolutional architectures. GPT-3 (175B parameters) demonstrated powerful few-shot learning and human-like text generation.
      </div>
    </div>

    <!-- ========= 6.8 åŒ»ç–—å¥åº· ========= -->
    <h2 id="healthcare">6.8 åŒ»ç–—å¥åº·<br><span style="font-size:0.7em;color:var(--text-secondary)">Healthcare</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>åŒ»ç–—é¢†åŸŸçš„åº”ç”¨æ˜¯ GDL çš„å¦ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ã€‚GDL æ–¹æ³•åœ¨åŒ»ç–—ä¸­çš„å¤šç§ä½¿ç”¨æ–¹å¼ï¼š</p>
      </div>
      <div class="en">
        Applications in the medical domain are a promising area for GDL, with multiple ways these methods are being used.
      </div>
    </div>

    <table>
      <thead>
        <tr><th>æ–¹æ³•</th><th>æ•°æ®ç±»å‹</th><th>GDL åŸŸ</th><th>ä»»åŠ¡</th></tr>
      </thead>
      <tbody>
        <tr><td>CNN</td><td>åŒ»å­¦å½±åƒ (CT, MRI, è§†ç½‘è†œæ‰«æ)</td><td>ç½‘æ ¼ (2D/3D)</td><td>ç–¾ç—…è¯Šæ–­ã€ICU ä½é™¢æ—¶é•¿é¢„æµ‹</td></tr>
        <tr><td>3D Roto-CNN</td><td>è‚ºéƒ¨ CT</td><td>ç¾¤ (æ—‹è½¬)</td><td>è‚ºç»“èŠ‚æ£€æµ‹ï¼ˆç²¾åº¦æå‡ï¼‰</td></tr>
        <tr><td>Mesh CNN</td><td>å™¨å®˜è¡¨é¢</td><td>æµå½¢</td><td>é¢éƒ¨é‡å»ºã€è„‘çš®å±‚åˆ†å‰²</td></tr>
        <tr><td>GNN</td><td>è„‘åŠŸèƒ½ç½‘ç»œ</td><td>å›¾</td><td>æ€§åˆ«/å¹´é¾„é¢„æµ‹ã€è‡ªé—­ç—‡è¯Šæ–­</td></tr>
        <tr><td>GNN</td><td>æ‚£è€…ç½‘ç»œ</td><td>å›¾</td><td>åŸºäºç›¸ä¼¼æ‚£è€…çš„è¯Šæ–­</td></tr>
        <tr><td>GNN</td><td>ç”µå­å¥åº·è®°å½•</td><td>å›¾</td><td>æ¨¡å¼è¯†åˆ«è¯Šæ–­</td></tr>
      </tbody>
    </table>

    <h3 id="brain">è„‘ç½‘ç»œåˆ†æ</h3>

    <div class="bilingual">
      <div class="zh">
        <p>ç¥ç»ç§‘å­¦å®¶è¶Šæ¥è¶Šå°†å¤§è„‘è§†ä¸ºå…·æœ‰å¤æ‚è¤¶çš±çš„<strong>è¡¨é¢</strong>ï¼Œäº§ç”Ÿé«˜åº¦éæ¬§å‡ é‡Œå¾—çš„ç»“æ„ã€‚åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒ (fMRI) æ„å»ºçš„<strong>è„‘åŠŸèƒ½ç½‘ç»œ</strong>è¡¨ç¤ºåœ¨æ‰§è¡ŒæŸäº›è®¤çŸ¥åŠŸèƒ½æ—¶ä¸€èµ·æ¿€æ´»çš„è„‘åŒºåŸŸã€‚</p>
        <p><strong>Ktena et al. (2017)</strong> ç‡å…ˆä½¿ç”¨ GNN é¢„æµ‹è‡ªé—­ç—‡è°±ç³»éšœç¢ç­‰ç¥ç»å­¦çŠ¶å†µã€‚<strong>Itani and Thanou (2021)</strong> æŒ‡å‡ºè”åˆåˆ©ç”¨è„‘çš„å‡ ä½•å’ŒåŠŸèƒ½ç»“æ„åœ¨ç¥ç»ç–¾ç—…åˆ†æä¸­çš„ä¼˜åŠ¿ã€‚</p>
      </div>
      <div class="en">
        Neuroscientists increasingly view the brain as a surface with complex folds giving rise to non-Euclidean structures. fMRI-based functional networks are analyzed with GNNs for conditions like Autism Spectrum Disorder.
      </div>
    </div>

    <h3 id="ehr">ç”µå­å¥åº·è®°å½• (EHR)</h3>

    <div class="bilingual">
      <div class="zh">
        <p>å…³äºä½é™¢æ‚£è€…çš„å¤§é‡æ•°æ®å¯ä»¥åœ¨<strong>ç”µå­å¥åº·è®°å½•</strong> (EHR) ä¸­æ‰¾åˆ°ã€‚å¤šé¡¹å·¥ä½œå°è¯•åŸºäº EHR æ•°æ®æ„å»º<strong>æ‚£è€…å›¾</strong>ï¼š</p>
        <ul>
          <li>é€šè¿‡åˆ†æåŒ»ç”Ÿç¬”è®°çš„åµŒå…¥ (Malone et al., 2018)</li>
          <li>é€šè¿‡å…¥é™¢è¯Šæ–­ç›¸ä¼¼æ€§ (Rocheteau et al., 2021)</li>
          <li>é€šè¿‡å‡è®¾å®Œå…¨è¿æ¥å›¾ (Zhu and Razavian, 2019)</li>
        </ul>
        <p>æ‰€æœ‰æƒ…å†µä¸‹ï¼Œä½¿ç”¨å›¾è¡¨å¾å­¦ä¹ å¤„ç† EHR éƒ½æ˜¾ç¤ºäº†æœ‰å‰æ™¯çš„ç»“æœã€‚</p>
      </div>
      <div class="en">
        Electronic Health Records contain a wealth of patient data. Several works construct patient graphs from EHR data (doctor's notes embeddings, diagnosis similarity, or fully-connected), all showing promising results with graph representation learning.
      </div>
    </div>

    <!-- ========= 6.9 ç²’å­ç‰©ç† ========= -->
    <h2 id="physics">6.9 ç²’å­ç‰©ç†ä¸å¤©ä½“ç‰©ç†<br><span style="font-size:0.7em;color:var(--text-secondary)">Particle Physics and Astrophysics</span></h2>

    <h3 id="jets">ç²’å­ Jet åˆ†ç±»</h3>

    <div class="bilingual">
      <div class="zh">
        <p>é«˜èƒ½ç‰©ç†å­¦å®¶å¯èƒ½æ˜¯è‡ªç„¶ç§‘å­¦é¢†åŸŸä¸­æœ€æ—©æ‹¥æŠ± GNN çš„ä¸“å®¶ã€‚ç‰©ç†å­¦ä¸­çš„è®¸å¤šé—®é¢˜æ¶‰åŠ<strong>æ— åºé›†åˆ</strong>å½¢å¼çš„æ•°æ®ï¼Œå…·æœ‰ä¸°å¯Œçš„å…³ç³»å’Œç›¸äº’ä½œç”¨â€”â€”è¿™è‡ªç„¶åœ°è¡¨ç¤ºä¸ºå›¾ã€‚</p>
        <p>ç²’å­ <strong>Jet</strong>ï¼ˆå–·æ³¨ï¼‰â€”â€”ç”±å•ä¸ªåˆå§‹äº‹ä»¶äº§ç”Ÿçš„ç¨³å®šç²’å­å–·é›¾â€”â€”çš„é‡å»ºå’Œåˆ†ç±»æ˜¯é«˜èƒ½ç‰©ç†ä¸­çš„é‡è¦åº”ç”¨ã€‚åœ¨å¤§å‹å¼ºå­å¯¹æ’æœº (LHC) ä¸­ï¼Œè¿™äº› Jet æ˜¯è´¨å­è¿‘å…‰é€Ÿç¢°æ’çš„ç»“æœï¼Œå¯èƒ½æä¾›æ–°ç²’å­å­˜åœ¨çš„å®éªŒè¯æ®ã€‚</p>
      </div>
      <div class="en">
        High energy physicists were among the first to embrace GNNs. Particle jet classification is crucial in the LHC, providing experimental evidence for new particles like the Higgs boson.
      </div>
    </div>

    <div class="figure">
      <img src="../assets/ch6_p112_img0.jpeg" alt="LHC detector">
      <figcaption>å¤§å‹å¼ºå­å¯¹æ’æœºæ¢æµ‹å™¨çš„ä¸€éƒ¨åˆ†ã€‚GNN ç”¨äºå¯¹ç¢°æ’äº§ç”Ÿçš„ç²’å­å–·æ³¨è¿›è¡Œåˆ†ç±»ï¼Œå¯»æ‰¾å¸Œæ ¼æ–¯ç»è‰²å­ç­‰ç²’å­çš„è¯æ®ã€‚</figcaption>
    </div>

    <div class="math-block">
      $$\text{ç²’å­ Jet ä¸­çš„ GDL:}$$
      $$\text{èŠ‚ç‚¹} = \text{ç²’å­ (èƒ½é‡, åŠ¨é‡, PID)}, \quad \text{è¾¹} = \text{ç©ºé—´/èƒ½é‡é‚»è¿‘}$$
      $$\text{å¯¹ç§°ç¾¤: æ´›ä¼¦å…¹ç¾¤ } SO(3,1) \text{ (æ—¶ç©ºçš„åŸºæœ¬å¯¹ç§°æ€§)}$$
      <div class="math-explain">
        ç²’å­ç‰©ç†çš„ç‰¹æ®Šä¹‹å¤„åœ¨äºå…¶å¯¹ç§°ç¾¤ä¸æ˜¯ SE(3) è€Œæ˜¯<strong>æ´›ä¼¦å…¹ç¾¤</strong> $SO(3,1)$â€”â€”æ—¶ç©ºçš„åŸºæœ¬å¯¹ç§°æ€§ã€‚Bogatskiy et al. (2020) å¼€å‘äº†æ´›ä¼¦å…¹ç¾¤ç­‰å˜çš„ç¥ç»ç½‘ç»œï¼Œæä¾›äº†æ›´å¥½çš„æ³›åŒ–å’Œå¯è§£é‡Šæ€§ã€‚
      </div>
    </div>

    <pre><code># ç²’å­ Jet åˆ†ç±»çš„ GNN (ç®€åŒ–)
import torch
import torch.nn as nn
from torch_geometric.nn import EdgeConv, global_mean_pool

class ParticleJetGNN(nn.Module):
    """
    ç²’å­ Jet åˆ†ç±»
    
    GDL è§†è§’:
    - åŸŸ: ç²’å­é›†åˆ/å›¾
    - å¯¹ç§°ç¾¤: Lorentz group SO(3,1)
    - ç­‰å˜å±‚: EdgeConv (åŠ¨æ€å›¾ CNN)
    - ä¸å˜è¾“å‡º: å…¨å±€æ± åŒ– â†’ Jet ç±»åˆ«
    
    ç±»ä¼¼äº DGCNN (Wang et al., 2019) å’Œ 
    ParticleNet (Qu & Gouskos, 2019)
    """
    def __init__(self, input_dim=4, hidden=64, n_classes=5):
        super().__init__()
        # 4-momentum: (E, px, py, pz)
        
        self.edge_conv1 = EdgeConv(
            nn.Sequential(nn.Linear(2*input_dim, hidden), nn.ReLU()),
            aggr='max'
        )
        self.edge_conv2 = EdgeConv(
            nn.Sequential(nn.Linear(2*hidden, hidden), nn.ReLU()),
            aggr='max'
        )
        self.classifier = nn.Sequential(
            nn.Linear(hidden, 32),
            nn.ReLU(),
            nn.Linear(32, n_classes)
        )
    
    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.edge_conv1(x, edge_index)
        x = self.edge_conv2(x, edge_index)
        x = global_mean_pool(x, batch)  # ç½®æ¢ä¸å˜
        return self.classifier(x)

# Jet ç±»åˆ«: QCD jet, W/Z/Higgs/top jet
jet_classes = ['QCD', 'W boson', 'Z boson', 'Higgs', 'Top quark']
print(f"ç²’å­ Jet åˆ†ç±»: {len(jet_classes)} ç±»")
print("ä½¿ç”¨ Lorentz ä¸å˜é‡ä½œä¸ºç‰¹å¾å¯ä»¥æå‡æ€§èƒ½")</code></pre>

    <h3 id="neutrino">ä¸­å¾®å­å¤©æ–‡å­¦</h3>

    <div class="bilingual">
      <div class="zh">
        <p><strong>IceCube</strong> ä¸­å¾®å­å¤©æ–‡å°ä½¿ç”¨ä¸€ç«‹æ–¹å…¬é‡Œçš„å—æå†°æ¶ä½œä¸ºæ¢æµ‹å™¨ã€‚<strong>Choma et al. (2018)</strong> ä½¿ç”¨ GNN æ¨¡æ‹Ÿ IceCube æ¢æµ‹å™¨çš„ä¸è§„åˆ™å‡ ä½•ç»“æ„ï¼Œåœ¨æ£€æµ‹å¤©ä½“ç‰©ç†æºä¸­å¾®å­å’Œåˆ†ç¦»èƒŒæ™¯äº‹ä»¶æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æ›´å¥½çš„æ€§èƒ½ã€‚</p>
      </div>
      <div class="en">
        IceCube uses a cubic kilometer of Antarctic ice as a neutrino detector. Choma et al. (2018) used GNNs to model its irregular geometry, showing significantly better performance in detecting astrophysical neutrinos.
      </div>
    </div>

    <!-- ========= 6.10 VR/AR ========= -->
    <h2 id="vr">6.10 è™šæ‹Ÿ/å¢å¼ºç°å®<br><span style="font-size:0.7em;color:var(--text-secondary)">Virtual and Augmented Reality</span></h2>

    <div class="bilingual">
      <div class="zh">
        <p>è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦æ˜¯æ¨åŠ¨å¤§é‡ GDL æ–¹æ³•å‘å±•çš„å¦ä¸€ä¸ªåº”ç”¨é¢†åŸŸã€‚åŠ¨ä½œæ•æ‰æŠ€æœ¯é€šå¸¸åˆ†ä¸¤é˜¶æ®µè¿ä½œï¼š</p>
        <ol>
          <li><strong>åˆ†æ</strong>ï¼šå°† 3D æ‰«æä»ªè¾“å…¥ä¸æ ‡å‡†å½¢çŠ¶ï¼ˆç½‘æ ¼ï¼‰å¯¹åº”</li>
          <li><strong>åˆæˆ</strong>ï¼šç”Ÿæˆæ–°å½¢çŠ¶ä»¥é‡å¤è¾“å…¥çš„è¿åŠ¨</li>
        </ol>
        <p><strong>Kulon et al. (2020)</strong> å±•ç¤ºäº†æ··åˆç®¡çº¿ï¼šå›¾åƒ CNN ç¼–ç å™¨ + å‡ ä½•è§£ç å™¨ï¼Œä» 2D å›¾åƒä¼°è®¡ 3D æ‰‹åŠ¿ï¼Œåœ¨æ‰‹æœºä¸Šå®ç°<strong>è¶…å®æ—¶</strong>è¿è¡Œã€‚è¯¥æŠ€æœ¯ï¼ˆAriel AI, 2020å¹´è¢« Snap æ”¶è´­ï¼‰ç°ç”¨äº Snap çš„å¢å¼ºç°å®äº§å“ã€‚</p>
      </div>
      <div class="en">
        Motion capture for VR/AR operates in analysis (3D scan â†’ mesh correspondence) and synthesis (generating new shapes). Kulon et al.'s hybrid CNN-encoder + geometric-decoder pipeline runs faster than real-time on mobile phones. Now used in Snap's AR products.
      </div>
    </div>

    <!-- ========= 6.11 åŒ»ç–—æœºå™¨äºº ========= -->
    <h2 id="medical-robotics">6.11 åŒ»ç–—æœºå™¨äºº â€” PhysRobot ç›´æ¥å…³è”<br><span style="font-size:0.7em;color:var(--text-secondary)">Medical Robotics â€” Direct PhysRobot Connection ğŸ¤–</span></h2>

    <div class="callout callout-project">
      <h4>è¿™ä¸€èŠ‚ä¸æˆ‘ä»¬çš„ PhysRobot é¡¹ç›®ç›´æ¥ç›¸å…³ï¼</h4>
      <p>è™½ç„¶åŸä¹¦æ²¡æœ‰ä¸“é—¨è®¨è®ºåŒ»ç–—æœºå™¨äººï¼Œä½†ä¹¦ä¸­æè¿°çš„è®¸å¤šæŠ€æœ¯â€”â€”GNN ç‰©ç†ä»¿çœŸã€ç­‰å˜ç½‘ç»œã€ç½‘æ ¼å¤„ç†â€”â€”æ­£æ˜¯ PhysRobot çš„æŠ€æœ¯åŸºç¡€ã€‚è¿™ä¸€èŠ‚å°†åŸä¹¦çš„åº”ç”¨ä¸æˆ‘ä»¬çš„é¡¹ç›®ä¸²è”èµ·æ¥ã€‚</p>
    </div>

    <h3 id="surgery-sim">æ‰‹æœ¯ä»¿çœŸ</h3>

    <div class="bilingual">
      <div class="zh">
        <p>æ‰‹æœ¯ä»¿çœŸæ˜¯åŒ»ç–—æœºå™¨äººçš„æ ¸å¿ƒéœ€æ±‚ï¼šå¤–ç§‘åŒ»ç”Ÿéœ€è¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è®­ç»ƒï¼Œæœºå™¨äººæ§åˆ¶ç³»ç»Ÿéœ€è¦é¢„æµ‹æ‰‹æœ¯æ“ä½œçš„ç‰©ç†åæœã€‚ä¼ ç»Ÿæ–¹æ³•ï¼ˆFEM æœ‰é™å…ƒï¼‰ç²¾ç¡®ä½†<strong>å¤ªæ…¢</strong>â€”â€”æ— æ³•å®ç°å®æ—¶äº¤äº’ã€‚</p>
        <p>GDL æ–¹æ³•å¯ä»¥æä¾›<strong>å‡†ç¡®ä¸”å¿«é€Ÿ</strong>çš„æ›¿ä»£æ–¹æ¡ˆï¼š</p>
        <ul>
          <li><strong>GNS</strong> (Graph Network Simulator): ç”¨ GNN å­¦ä¹ ç‰©ç†å®šå¾‹</li>
          <li><strong>MeshGraphNet</strong>: ç”¨ GNN åœ¨ç½‘æ ¼ä¸Šä»¿çœŸå˜å½¢</li>
          <li><strong>ç­‰å˜ GNN</strong>: ä¿è¯ç‰©ç†å¯¹ç§°æ€§</li>
        </ul>
      </div>
    </div>

    <div class="math-block">
      $$\text{æ‰‹æœ¯ä»¿çœŸçš„ GDL æ¡†æ¶:}$$
      $$\underbrace{(\text{ç»„ç»‡ç²’å­}, \text{å™¨æ¢°ç²’å­})}_{\text{å¼‚æ„å›¾}} \xrightarrow{\text{GNN}} \underbrace{(a_1, \ldots, a_N)}_{\text{åŠ é€Ÿåº¦ (SE(3)-ç­‰å˜)}} \xrightarrow{\text{ç§¯åˆ†}} \underbrace{(r_1, \ldots, r_N)}_{\text{æ–°ä½ç½®}}$$
      <div class="math-explain">
        <strong>æ‰‹æœ¯ä»¿çœŸ = ç²’å­ç³»ç»Ÿç‰©ç†ä»¿çœŸçš„ç‰¹ä¾‹</strong>ï¼š
        <br>â€¢ è½¯ç»„ç»‡ â†’ ç²’å­ï¼ˆç½‘æ ¼èŠ‚ç‚¹ï¼‰+ å¼¹æ€§çº¦æŸï¼ˆè¾¹ï¼‰
        <br>â€¢ æ‰‹æœ¯å™¨æ¢° â†’ åˆšä½“ç²’å­ + å¤–åŠ›
        <br>â€¢ äº¤äº’ â†’ å™¨æ¢°-ç»„ç»‡ä¹‹é—´çš„ç¢°æ’å’ŒåŠ›ä¼ é€’
        <br>â€¢ ç‰©ç†å¯¹ç§°æ€§ï¼šSE(3)ï¼ˆæ—‹è½¬+å¹³ç§»ä¸å˜æ€§ï¼‰
      </div>
    </div>

    <h3 id="tissue-modeling">è½¯ç»„ç»‡å»ºæ¨¡</h3>

    <pre><code># è½¯ç»„ç»‡ä»¿çœŸçš„ GNN (PhysRobot æ ¸å¿ƒ)
import torch
import torch.nn as nn

class SoftTissueGNN(nn.Module):
    """
    è½¯ç»„ç»‡å˜å½¢ä»¿çœŸçš„å›¾ç¥ç»ç½‘ç»œ
    
    GDL è®¾è®¡åŸåˆ™:
    1. åŸŸ: ç²’å­å›¾ (ç»„ç»‡èŠ‚ç‚¹ + å™¨æ¢°èŠ‚ç‚¹ + è¾¹ç•ŒèŠ‚ç‚¹)
    2. å¯¹ç§°ç¾¤: SE(3) (ç‰©ç†å®šå¾‹åœ¨æ—‹è½¬å’Œå¹³ç§»ä¸‹ä¸å˜)
    3. ç­‰å˜æ€§: ä½¿ç”¨ç›¸å¯¹ä½ç½® (å¹³ç§»ä¸å˜) å’Œè·ç¦» (æ—‹è½¬ä¸å˜)
    4. å±€éƒ¨æ€§: åªå¯¹ k-NN é‚»å±…åšæ¶ˆæ¯ä¼ é€’
    """
    def __init__(self, node_dim=16, edge_dim=4, hidden=128, n_layers=10):
        super().__init__()
        
        # èŠ‚ç‚¹ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden)
        )
        
        # è¾¹ç¼–ç å™¨ (ä½¿ç”¨ SE(3)-ä¸å˜ç‰¹å¾)
        self.edge_encoder = nn.Sequential(
            nn.Linear(edge_dim, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden)
        )
        
        # æ¶ˆæ¯ä¼ é€’å±‚
        self.message_layers = nn.ModuleList([
            MessagePassingLayer(hidden) for _ in range(n_layers)
        ])
        
        # åŠ é€Ÿåº¦é¢„æµ‹å™¨
        self.decoder = nn.Sequential(
            nn.Linear(hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, 3)  # 3D åŠ é€Ÿåº¦
        )
    
    def compute_edge_features(self, pos, edge_index):
        """
        è®¡ç®— SE(3)-ä¸å˜çš„è¾¹ç‰¹å¾
        - ç›¸å¯¹ä½ç½® (å¹³ç§»ä¸å˜)
        - è·ç¦» (æ—‹è½¬ä¸å˜)
        """
        src, dst = edge_index
        rel_pos = pos[dst] - pos[src]  # å¹³ç§»ä¸å˜!
        dist = rel_pos.norm(dim=-1, keepdim=True)  # æ—‹è½¬ä¸å˜!
        return torch.cat([rel_pos, dist], dim=-1)  # [E, 4]
    
    def forward(self, node_feat, pos, edge_index):
        # ç¼–ç 
        h = self.node_encoder(node_feat)
        edge_attr = self.edge_encoder(
            self.compute_edge_features(pos, edge_index)
        )
        
        # æ¶ˆæ¯ä¼ é€’ (10 å±‚, ç­‰å˜)
        for layer in self.message_layers:
            h = h + layer(h, edge_index, edge_attr)  # æ®‹å·®è¿æ¥
        
        # è§£ç åŠ é€Ÿåº¦
        acc = self.decoder(h)
        return acc

class MessagePassingLayer(nn.Module):
    def __init__(self, hidden):
        super().__init__()
        self.message_fn = nn.Sequential(
            nn.Linear(3 * hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden)
        )
        self.update_fn = nn.Sequential(
            nn.Linear(2 * hidden, hidden),
            nn.ReLU(),
            nn.Linear(hidden, hidden)
        )
    
    def forward(self, h, edge_index, edge_attr):
        src, dst = edge_index
        # æ¶ˆæ¯: m_ij = Ï†(h_i, h_j, e_ij)
        messages = self.message_fn(
            torch.cat([h[src], h[dst], edge_attr], dim=-1)
        )
        # èšåˆ: Î£ m_ij (ç½®æ¢ä¸å˜)
        agg = torch.zeros_like(h)
        agg.index_add_(0, dst, messages)
        # æ›´æ–°: h_i' = Ïˆ(h_i, agg_i)
        return self.update_fn(torch.cat([h, agg], dim=-1))

# ç¤ºä¾‹è¿è¡Œ
model = SoftTissueGNN()
N = 100  # 100 ä¸ªç»„ç»‡ç²’å­
node_feat = torch.randn(N, 16)
pos = torch.randn(N, 3)
# k-NN å›¾ (ç®€åŒ–: éšæœºè¾¹)
edge_index = torch.randint(0, N, (2, N * 10))

acc = model(node_feat, pos, edge_index)
print(f"è½¯ç»„ç»‡ä»¿çœŸ:")
print(f"  ç²’å­æ•°: {N}")
print(f"  é¢„æµ‹åŠ é€Ÿåº¦: {acc.shape}")
print(f"  æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
print(f"  SE(3) ä¸å˜æ€§é€šè¿‡ç›¸å¯¹ä½ç½®å’Œè·ç¦»ä¿è¯")</code></pre>

    <h3 id="instrument">æ‰‹æœ¯å™¨æ¢°æ§åˆ¶</h3>

    <div class="bilingual">
      <div class="zh">
        <p>æ‰‹æœ¯å™¨æ¢°åœ¨ SE(3) ç©ºé—´ä¸­è¿åŠ¨â€”â€”å…¶å§¿æ€ç”± 3D ä½ç½®å’Œ 3D æ–¹å‘æè¿°ã€‚GDL åŸåˆ™åœ¨æ­¤çš„åº”ç”¨ï¼š</p>
        <ul>
          <li><strong>å™¨æ¢°-ç»„ç»‡äº¤äº’</strong>ï¼šå¼‚æ„å›¾ä¸­çš„æ¶ˆæ¯ä¼ é€’ï¼ˆå™¨æ¢°èŠ‚ç‚¹ â†” ç»„ç»‡èŠ‚ç‚¹ï¼‰</li>
          <li><strong>åŠ›åé¦ˆé¢„æµ‹</strong>ï¼šä»å‡ ä½•æ¥è§¦ä¿¡æ¯é¢„æµ‹åŠ›â€”â€”åŠ›æ˜¯ SE(3)-ç­‰å˜çš„å‘é‡é‡</li>
          <li><strong>è½¨è¿¹è§„åˆ’</strong>ï¼šåœ¨ SE(3) ç©ºé—´ä¸­ä½¿ç”¨ç­‰å˜ç­–ç•¥ç½‘ç»œ</li>
          <li><strong>ç¢°æ’æ£€æµ‹</strong>ï¼šGNN é¢„æµ‹å™¨æ¢°ä¸ç»„ç»‡ä¹‹é—´çš„ç¢°æ’</li>
        </ul>
      </div>
    </div>

    <div class="callout callout-project">
      <h4>PhysRobot ä¸­çš„å®Œæ•´ GDL æµç¨‹</h4>
      <ol>
        <li><strong>åœºæ™¯æ„å»º</strong>ï¼šå°†è½¯ç»„ç»‡å’Œå™¨æ¢°ç¦»æ•£åŒ–ä¸ºç²’å­å›¾</li>
        <li><strong>ç‰¹å¾æå–</strong>ï¼šSE(3)-ä¸å˜ç‰¹å¾ï¼ˆè·ç¦»ã€ç›¸å¯¹ä½ç½®ã€ç‰©è´¨å±æ€§ï¼‰</li>
        <li><strong>GNN æ¶ˆæ¯ä¼ é€’</strong>ï¼š10 å±‚ç­‰å˜æ¶ˆæ¯ä¼ é€’ï¼Œå­¦ä¹ ç²’å­é—´ç›¸äº’ä½œç”¨</li>
        <li><strong>åŠ›/åŠ é€Ÿåº¦é¢„æµ‹</strong>ï¼šSE(3)-ç­‰å˜çš„å‘é‡è¾“å‡º</li>
        <li><strong>æ—¶é—´ç§¯åˆ†</strong>ï¼šVerlet ç§¯åˆ†æ›´æ–°ä½ç½®å’Œé€Ÿåº¦</li>
        <li><strong>åé¦ˆ</strong>ï¼šé¢„æµ‹çš„åŠ›ä¼ å›å™¨æ¢°æ§åˆ¶ç³»ç»Ÿ</li>
      </ol>
      <p>æ•´ä¸ªæµç¨‹çš„æ¯ä¸€æ­¥éƒ½éµå¾ª GDL è“å›¾ï¼š<strong>ç­‰å˜å±‚</strong>â†’<strong>èšåˆ</strong>â†’<strong>ç­‰å˜/ä¸å˜è¾“å‡º</strong>ã€‚</p>
    </div>

    <!-- ========= æ€»ç»“ ========= -->
    <h2 id="summary">æ€»ç»“ï¼šGDL åº”ç”¨å…¨æ™¯<br><span style="font-size:0.7em;color:var(--text-secondary)">Summary</span></h2>

    <table>
      <thead>
        <tr><th>åº”ç”¨é¢†åŸŸ</th><th>GDL åŸŸ</th><th>å¯¹ç§°ç¾¤</th><th>å…¸å‹æ¶æ„</th><th>ä»£è¡¨æ€§æˆæœ</th></tr>
      </thead>
      <tbody>
        <tr><td>è¯ç‰©å‘ç°</td><td>åˆ†å­å›¾</td><td>$\Sigma_n$, SE(3)</td><td>MPNN, EGNN</td><td>Halicin æŠ—ç”Ÿç´ </td></tr>
        <tr><td>è›‹ç™½è´¨</td><td>å›¾/æµå½¢</td><td>SE(3)</td><td>AlphaFold, MaSIF</td><td>CASP14 é©å‘½</td></tr>
        <tr><td>æ¨èç³»ç»Ÿ</td><td>äºŒéƒ¨å›¾</td><td>$\Sigma_n$</td><td>PinSage, GCN</td><td>æ•°åäº¿ç”¨æˆ·</td></tr>
        <tr><td>äº¤é€š</td><td>æ—¶ç©ºå›¾</td><td>$\Sigma_n$ Ã— æ—¶é—´</td><td>ST-GNN, GAT</td><td>Google Maps</td></tr>
        <tr><td>è®¡ç®—æœºè§†è§‰</td><td>2D ç½‘æ ¼</td><td>$\mathbb{Z}^2$</td><td>CNN, ViT</td><td>ImageNet è¶…äºº</td></tr>
        <tr><td>æ¸¸æˆ AI</td><td>2D ç½‘æ ¼</td><td>$\mathbb{Z}^2$</td><td>CNN + RL</td><td>AlphaGo</td></tr>
        <tr><td>è¯­éŸ³</td><td>1D ç½‘æ ¼</td><td>$\mathbb{Z}$</td><td>WaveNet, RNN</td><td>Google TTS</td></tr>
        <tr><td>NLP</td><td>é›†åˆ/å®Œå…¨å›¾</td><td>$\Sigma_n$</td><td>Transformer</td><td>GPT-3</td></tr>
        <tr><td>åŒ»ç–—</td><td>å›¾/ç½‘æ ¼/æµå½¢</td><td>å¤šç§</td><td>GNN, Mesh CNN</td><td>è„‘ç–¾ç—…è¯Šæ–­</td></tr>
        <tr><td>ç²’å­ç‰©ç†</td><td>ç²’å­é›†åˆ</td><td>Lorentz</td><td>DGCNN, DeepSets</td><td>Jet åˆ†ç±»</td></tr>
        <tr><td>VR/AR</td><td>æµå½¢/ç½‘æ ¼</td><td>Iso($\mathcal{M}$)</td><td>Mesh CNN</td><td>Snap AR</td></tr>
        <tr><td><strong>åŒ»ç–—æœºå™¨äºº</strong></td><td><strong>ç²’å­å›¾</strong></td><td><strong>SE(3) Ã— $\Sigma_n$</strong></td><td><strong>GNS, EGNN</strong></td><td><strong>PhysRobot</strong></td></tr>
      </tbody>
    </table>

    <div class="callout callout-key">
      <h4>è·¨é¢†åŸŸçš„ç»Ÿä¸€æ¨¡å¼</h4>
      <p>å°½ç®¡è¿™äº›åº”ç”¨çœ‹èµ·æ¥æˆªç„¶ä¸åŒï¼Œä½†å®ƒä»¬éƒ½éµå¾ª<strong>åŒä¸€ä¸ª GDL è“å›¾</strong>ï¼š</p>
      <ol>
        <li><strong>è¯†åˆ«åŸŸå’Œå¯¹ç§°æ€§</strong>ï¼šæ•°æ®çš„è‡ªç„¶å‡ ä½•ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ</li>
        <li><strong>æ„å»ºç­‰å˜å±‚</strong>ï¼šæ¶ˆæ¯ä¼ é€’ã€å·ç§¯ã€æ³¨æ„åŠ›â€”â€”éƒ½æ˜¯ç­‰å˜çš„çº¿æ€§æ“ä½œ</li>
        <li><strong>å †å å±‚çº§</strong>ï¼šç­‰å˜å±‚ + éçº¿æ€§ + å¯é€‰çš„æ± åŒ–</li>
        <li><strong>ä¸å˜è¾“å‡º</strong>ï¼šå…¨å±€æ± åŒ–å°†ç­‰å˜è¡¨ç¤ºè½¬åŒ–ä¸ºä¸å˜é¢„æµ‹</li>
      </ol>
      <p>è¿™ç§ç»Ÿä¸€æ€§æ­£æ˜¯ Geometric Deep Learning çš„æ ¸å¿ƒä»·å€¼ã€‚</p>
    </div>

    <!-- ========= ç»ƒä¹ é¢˜ ========= -->
    <div class="exercises" id="exercises">
      <h3>ç»ƒä¹ é¢˜ Exercises</h3>
      <ol>
        <li><strong>åˆ†å­å±æ€§é¢„æµ‹</strong>ï¼šä½¿ç”¨ PyTorch Geometric åœ¨ MoleculeNet çš„ ESOL æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ª GNNã€‚
          (a) å®ç° 3 å±‚ GCN + å…¨å±€å¹³å‡æ± åŒ– + çº¿æ€§å›å½’
          (b) æŠ¥å‘Š RMSEï¼Œä¸éšæœºåŸºçº¿å’Œ Morgan æŒ‡çº¹ + çº¿æ€§å›å½’æ¯”è¾ƒ
          (c) å¯è§†åŒ–å­¦åˆ°çš„åˆ†å­åµŒå…¥ï¼ˆä½¿ç”¨ t-SNEï¼‰
        </li>
        <li><strong>ç­‰å˜æ€§éªŒè¯</strong>ï¼š
          (a) å®ç°ä¸Šé¢çš„ EGNN å±‚
          (b) å¯¹ä¸€ç»„ 3D åˆ†å­åæ ‡ï¼ŒéªŒè¯ï¼šæ—‹è½¬è¾“å…¥ â†’ è¾“å‡ºä¹Ÿç›¸åº”æ—‹è½¬
          (c) å°è¯•ç”¨æ™®é€š GCNï¼ˆä¸ä½¿ç”¨è·ç¦»ç‰¹å¾ï¼‰â€”â€”ç­‰å˜æ€§æ˜¯å¦æˆç«‹ï¼Ÿ
        </li>
        <li><strong>æ¨èç³»ç»Ÿ</strong>ï¼šåœ¨ MovieLens æ•°æ®é›†ä¸Šå®ç°ç®€å•çš„ GNN æ¨èç³»ç»Ÿã€‚
          (a) æ„å»ºç”¨æˆ·-ç”µå½±äºŒéƒ¨å›¾
          (b) ç”¨ GraphSAGE å­¦ä¹ èŠ‚ç‚¹åµŒå…¥
          (c) ç”¨å†…ç§¯é¢„æµ‹è¯„åˆ†ï¼Œè®¡ç®— RMSE
        </li>
        <li><strong>äº¤é€šé¢„æµ‹</strong>ï¼š
          (a) æè¿°ä¸ºä»€ä¹ˆäº¤é€šç½‘ç»œå¤©ç„¶æ˜¯å›¾ç»“æ„
          (b) è§£é‡Šä¸ºä»€ä¹ˆæ—¶ç©º GNN æ¯”çº¯ CNN æˆ–çº¯ RNN æ›´é€‚åˆäº¤é€šé¢„æµ‹
          (c) è®¾è®¡ä¸€ä¸ªåŒæ—¶æ•è·ç©ºé—´å’Œæ—¶é—´ä¾èµ–æ€§çš„æ¶æ„ï¼ˆç”»æ¡†å›¾ï¼‰
        </li>
        <li><strong>PhysRobot åº”ç”¨è®¾è®¡</strong>ï¼š
          å‡è®¾ä½ éœ€è¦ä»¿çœŸä¸€ä¸ªè…¹è…”é•œæ‰‹æœ¯åœºæ™¯ï¼ˆä¸€ä¸ªæŠ“å–å™¨ + ä¸€å—è½¯ç»„ç»‡ + ä¸€ä¸ªå›ºå®šå¹³é¢ï¼‰ã€‚
          (a) å¦‚ä½•å°†åœºæ™¯å»ºæ¨¡ä¸ºç²’å­å›¾ï¼Ÿï¼ˆå®šä¹‰èŠ‚ç‚¹ç±»å‹ã€è¾¹ç±»å‹ã€ç‰¹å¾ï¼‰
          (b) è¿™ä¸ªç³»ç»Ÿæœ‰å“ªäº›å¯¹ç§°æ€§ï¼Ÿ
          (c) å“ªäº›å¯¹ç§°æ€§è¢«æ‰“ç ´äº†ï¼ˆå¦‚é‡åŠ›æ–¹å‘ï¼‰ï¼Ÿ
          (d) è®¾è®¡ GNN æ¶æ„ï¼ˆç”»å›¾ + å†™ä¼ªä»£ç ï¼‰
          (e) è®­ç»ƒæ•°æ®æ¥è‡ªå“ªé‡Œï¼Ÿå¦‚ä½•ç”Ÿæˆï¼Ÿ
        </li>
        <li><strong>è·¨é¢†åŸŸè¿ç§»</strong>ï¼šæœ¬ç« æè¿°çš„ GDL åº”ç”¨æœ‰è®¸å¤šå…±åŒç‚¹ã€‚é€‰æ‹©ä¸¤ä¸ªä¸åŒé¢†åŸŸçš„åº”ç”¨ï¼ˆå¦‚è¯ç‰©å‘ç°å’Œäº¤é€šé¢„æµ‹ï¼‰ï¼Œè¯¦ç»†æ¯”è¾ƒï¼š
          (a) é—®é¢˜å®šä¹‰
          (b) å›¾ç»“æ„
          (c) å¯¹ç§°æ€§
          (d) GNN æ¶æ„çš„å¼‚åŒ
          (e) æ˜¯å¦å¯ä»¥å°†ä¸€ä¸ªé¢†åŸŸçš„åˆ›æ–°è¿ç§»åˆ°å¦ä¸€ä¸ªï¼Ÿ
        </li>
      </ol>
    </div>

    <!-- ========= ç« èŠ‚å¯¼èˆª ========= -->
    <div class="chapter-nav">
      <a href="../chapter5/index.html">â† Chapter 5: GDL æ¨¡å‹</a>
      <a href="../chapter7/index.html">Chapter 7: å†å²è§†è§’ â†’</a>
    </div>
  </main>

  <script src="../assets/script.js"></script>
</body>
</html>
