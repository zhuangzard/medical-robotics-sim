<div class="enrichment-block" style="border-left-color: #ec4899;">
  <h4>📖 核心概念详解</h4>
  
  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">群 (Group) 🔑</h5>
    <p><strong>一句话</strong>：群就是一组"操作"，它们可以组合、可以撤销、有一个"什么都不做"的操作。</p>
    
    <p><strong>正式定义</strong>：集合 $G$ 加上运算 $\cdot: G \times G \to G$，满足四个公理：</p>
    <ul style="margin-left: 1.5rem;">
      <li><strong>结合律</strong>：$(g \cdot h) \cdot k = g \cdot (h \cdot k)$</li>
      <li><strong>单位元</strong>：存在唯一的 $e \in G$ 使得 $e \cdot g = g \cdot e = g$</li>
      <li><strong>逆元</strong>：每个 $g$ 都有唯一的 $g^{-1}$ 使得 $g \cdot g^{-1} = g^{-1} \cdot g = e$</li>
      <li><strong>封闭性</strong>：$g, h \in G \Rightarrow g \cdot h \in G$</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🎲 <strong>旋转魔方</strong>：每次转动是一个群元素，连续转动=群运算，转回原状=逆元，什么都不转=单位元</li>
      <li>🕐 <strong>时钟</strong>：12小时的加法 → 循环群 $\mathbb{Z}_{12}$。例如 9点+5小时=2点，这就是群运算 $9 + 5 = 2 \pmod{12}$</li>
      <li>🃏 <strong>洗牌</strong>：52张牌的所有排列方式 → 对称群 $S_{52}$。每种洗牌方式可以组合，可以"反洗"回去</li>
      <li>🔄 <strong>平面旋转</strong>：旋转30° + 旋转45° = 旋转75°，旋转0°=单位元，旋转-30°是逆元</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：群是描述对称性的数学语言。CNN 的平移不变性 = 平移群 $(\mathbb{R}^2, +)$，GNN 的节点排列不变性 = 置换群 $S_n$，3D点云的旋转不变性 = 旋转群 $SO(3)$。理解群 = 理解"什么样的变换不改变数据的本质"。</p>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 群是一组"东西"（如一群人）→ ✅ 群是一组"操作/变换"</li>
      <li>❌ 群运算一定满足交换律（$g \cdot h = h \cdot g$）→ ✅ 大部分群是<strong>非交换</strong>的（如旋转群、矩阵乘法）</li>
      <li>❌ 单位元就是数字1 → ✅ 单位元是"什么都不做的操作"，可以是恒等映射、0度旋转、空置换等</li>
    </ul>
    
    <p><strong>与其他概念的联系</strong>：群 → 群作用（如何作用在数据上）→ 群表示（用矩阵实现群作用）→ 等变性（网络层保持群结构）</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">群作用 (Group Action) 🎯</h5>
    <p><strong>一句话</strong>：群作用就是"群如何操作/变换某个对象"，比如旋转群如何旋转图片。</p>
    
    <p><strong>正式定义</strong>：群 $G$ 在集合 $\Omega$ 上的作用是映射 $(g, u) \mapsto g \cdot u$，满足：</p>
    <ul style="margin-left: 1.5rem;">
      <li>$(g \cdot h) \cdot u = g \cdot (h \cdot u)$（作用的复合 = 群元素的复合）</li>
      <li>$e \cdot u = u$（单位元不改变对象）</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>📐 <strong>平移群作用在图片上</strong>：平移向量 $(2, 3)$ 作用在像素 $(x, y)$ 上 → 新位置 $(x+2, y+3)$</li>
      <li>🎨 <strong>旋转群作用在画布上</strong>：旋转90° 作用在正方形上 → 正方形转了90°</li>
      <li>🔀 <strong>置换群作用在序列上</strong>：置换 $(1 \to 3, 2 \to 1, 3 \to 2)$ 作用在 $[A, B, C]$ 上 → $[B, C, A]$</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：群作用把抽象的"对称性"变成具体的"数据变换"。在图片上：$g \cdot x(u) = x(g^{-1}u)$（平移图片 = 反向平移坐标）。这是理解等变网络的核心：<strong>网络层必须"尊重"群作用</strong>。</p>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 群作用只能作用在几何对象上 → ✅ 可以作用在任何集合上（图、序列、函数空间）</li>
      <li>❌ $g \cdot u$ 里的 $\cdot$ 是普通乘法 → ✅ 这只是符号，具体操作取决于 $G$ 和 $\Omega$ 的定义</li>
    </ul>
    
    <p><strong>与其他概念的联系</strong>：群作用 → 轨道（$g$ 能把 $u$ 移动到哪些位置）+ 稳定子（哪些 $g$ 不移动 $u$）</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">群表示 (Group Representation) 🎭</h5>
    <p><strong>一句话</strong>：群表示就是"用矩阵来实现群作用"，让抽象的群变成可以计算的线性变换。</p>
    
    <p><strong>正式定义</strong>：$n$ 维群表示是映射 $\rho: G \to \mathbb{R}^{n \times n}$，满足：</p>
    <ul style="margin-left: 1.5rem;">
      <li>$\rho(g \cdot h) = \rho(g) \cdot \rho(h)$（群乘法 → 矩阵乘法）</li>
      <li>$\rho(g)$ 是可逆矩阵</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🔄 <strong>2D旋转</strong>：旋转 $\theta$ 角度 → 旋转矩阵 $\begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix}$</li>
      <li>🪞 <strong>镜像翻转</strong>：水平翻转 → 矩阵 $\begin{pmatrix} -1 & 0 \\ 0 & 1 \end{pmatrix}$</li>
      <li>🔀 <strong>置换</strong>：交换第1和第3个元素 → 置换矩阵 $\begin{pmatrix} 0&0&1 \\ 0&1&0 \\ 1&0&0 \end{pmatrix}$</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：神经网络处理的是向量/张量，群表示让我们可以用矩阵乘法 $\rho(g)x$ 来实现群作用。例如在CNN中，平移群的表示就是"shift矩阵"；在E(n)-等变网络中，旋转群的表示就是旋转矩阵。</p>
    
    <p><strong>为什么要"线性"</strong>：因为深度学习的基本操作（矩阵乘法、卷积）都是线性的。线性表示让我们可以用 GPU 高效计算。</p>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 群表示的维度 $n$ = 群的"大小" → ✅ $n$ 是特征空间的维度，可以任意选择（同一个群可以有无穷多种表示）</li>
      <li>❌ 一个群只有一种表示 → ✅ 同一个群有无穷多种表示（例如旋转群可以表示在2D平面、3D空间、球谐函数空间等）</li>
    </ul>
    
    <p><strong>与其他概念的联系</strong>：群表示 → 不可约表示（最简单的"积木"）→ 等变网络层（$f(\rho(g)x) = \rho'(g)f(x)$）</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">不变映射 vs 等变映射 (Invariant vs Equivariant) ⚖️</h5>
    <p><strong>一句话</strong>：不变 = "输入怎么变换，输出都不变"；等变 = "输入怎么变换，输出也跟着同样地变换"。</p>
    
    <p><strong>正式定义</strong>：</p>
    <ul style="margin-left: 1.5rem;">
      <li><strong>不变 (Invariant)</strong>：$f(\rho(g)x) = f(x)$ 对所有 $g \in G$</li>
      <li><strong>等变 (Equivariant)</strong>：$f(\rho(g)x) = \rho'(g)f(x)$ 对所有 $g \in G$</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>📸 <strong>不变：图片分类</strong>：猫的照片无论放在左上角还是右下角，都是"猫" → 平移不变</li>
      <li>🎯 <strong>等变：目标检测</strong>：如果图片向右移动10像素，检测框也应该向右移动10像素 → 平移等变</li>
      <li>🧬 <strong>不变：分子性质预测</strong>：旋转分子不改变其能量 → 旋转不变</li>
      <li>🗺️ <strong>等变：语义分割</strong>：旋转输入图片，输出的分割mask也应该旋转同样角度 → 旋转等变</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>等变层</strong>：CNN的卷积层、GNN的消息传递层 → 保持数据结构，适合作为中间层</li>
      <li><strong>不变层</strong>：全局池化(Global Pooling)、求和聚合 → 适合作为最后一层，输出标量/向量</li>
      <li><strong>组合原则</strong>：等变层 × N → 不变层 = 完整的深度学习架构</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 所有层都应该是不变的 → ✅ 只有<strong>最终输出</strong>需要不变（如果任务要求），中间层应该是<strong>等变</strong>的</li>
      <li>❌ 等变 = 相等 → ✅ 等变是"<strong>以同样的方式</strong>变化"，不是"不变"</li>
      <li>❌ CNN的卷积是平移不变的 → ✅ 卷积是平移<strong>等变</strong>的，pooling之后才变成平移<strong>不变</strong></li>
    </ul>
    
    <p><strong>数学直觉</strong>：不变 = 等变的特殊情况，当 $\rho'(g) = \text{id}$（恒等表示）时。或者说，等变是"保持结构"，不变是"忽略结构"。</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">同态 / 同构 / 自同构 (Homomorphism / Isomorphism / Automorphism) 🔗</h5>
    <p><strong>一句话</strong>：同态 = "保持结构的映射"；同构 = "可逆的同态"（两个对象本质相同）；自同构 = "自己到自己的同构"（对称性）。</p>
    
    <p><strong>正式定义</strong>：</p>
    <ul style="margin-left: 1.5rem;">
      <li><strong>同态 (Homomorphism)</strong>：$\phi: G \to H$ 满足 $\phi(g_1 \cdot g_2) = \phi(g_1) \cdot \phi(g_2)$</li>
      <li><strong>同构 (Isomorphism)</strong>：可逆的同态（双射 + 同态）</li>
      <li><strong>自同构 (Automorphism)</strong>：$G$ 到自己的同构 $\tau: G \to G$</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🔢 <strong>同态：对数</strong>：$\log(a \times b) = \log(a) + \log(b)$ → 把乘法群映射到加法群</li>
      <li>🎼 <strong>同构：乐谱和声音</strong>：乐谱和实际演奏"本质相同"（结构一致），只是表示不同</li>
      <li>🧩 <strong>图同构</strong>：两个社交网络图，节点标签不同但连接结构完全相同 → 同构</li>
      <li>🔄 <strong>自同构：正方形的对称性</strong>：旋转90°/180°/270°、翻转 → 正方形的8个自同构</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>群表示就是同态</strong>：$\rho: G \to GL_n(\mathbb{R})$ 把抽象的群映射到矩阵群</li>
      <li><strong>图同构问题</strong>：两个图是否本质相同？GNN能否区分非同构图？（这是GNN表达能力的核心问题）</li>
      <li><strong>自同构 = 对称性</strong>：图的自同构群 = 图的对称性，决定了等变网络的设计</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 同构 = 相等 → ✅ 同构是"结构相同但可能长得不一样"（如两个不同画法的同一个图）</li>
      <li>❌ 自同构 = 恒等映射 → ✅ 非平凡的自同构才有意思（如旋转、翻转），恒等映射是平凡自同构</li>
    </ul>
    
    <p><strong>记忆技巧</strong>：</p>
    <ul>
      <li><strong>Homo</strong> = 相同 + morphism = 形状 → "保持形状/结构的映射"</li>
      <li><strong>Iso</strong> = 完全相同 → "完全保持结构的可逆映射"</li>
      <li><strong>Auto</strong> = 自己 → "自己到自己的同构 = 对称操作"</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">轨道 / 稳定子 (Orbit / Stabilizer) 🛸</h5>
    <p><strong>一句话</strong>：轨道 = "群能把一个点移动到的所有位置"；稳定子 = "不移动这个点的所有群元素"。</p>
    
    <p><strong>正式定义</strong>：给定群作用 $G \curvearrowright \Omega$，对于 $u \in \Omega$：</p>
    <ul style="margin-left: 1.5rem;">
      <li><strong>轨道 (Orbit)</strong>：$\mathcal{O}(u) = \{g \cdot u : g \in G\}$</li>
      <li><strong>稳定子 (Stabilizer)</strong>：$\text{Stab}(u) = \{g \in G : g \cdot u = u\}$</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🌍 <strong>地球自转</strong>：
        <ul>
          <li>轨道：赤道上一点经过自转能到达赤道上所有点 → 轨道 = 整个赤道圈</li>
          <li>稳定子：只有"转0°"（单位元）不移动这个点 → 稳定子 = $\{e\}$</li>
          <li>北极点：无论怎么自转都在原地 → 轨道 = $\{\text{北极}\}$，稳定子 = 整个旋转群</li>
        </ul>
      </li>
      <li>🎨 <strong>正方形旋转</strong>：
        <ul>
          <li>顶点的轨道：4个顶点（旋转可以把任意顶点移到任意顶点）</li>
          <li>中心点的稳定子：所有8个对称操作（旋转、翻转）都不移动中心</li>
        </ul>
      </li>
      <li>🔀 <strong>置换群作用在序列上</strong>：序列 $[1,2,2]$ 在置换下的轨道只有3个元素：$\{[1,2,2], [2,1,2], [2,2,1]\}$（因为两个2不可区分）</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>轨道 = 等价类</strong>：同一轨道上的点"本质相同"（可以通过对称变换互相转换）</li>
      <li><strong>稳定子 = 点的对称性</strong>：稳定子越大，点越"对称"</li>
      <li><strong>轨道-稳定子定理</strong>：$|G| = |\mathcal{O}(u)| \times |\text{Stab}(u)|$ → 群的大小 = 轨道大小 × 稳定子大小</li>
      <li><strong>在GNN中</strong>：节点的轨道 = 可以通过自同构互换的节点集合；稳定子描述了节点的"局部对称性"</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 轨道一定是整个空间 → ✅ 轨道可以只是空间的一部分（如地球自转下，北极的轨道只有一个点）</li>
      <li>❌ 稳定子一定只有单位元 → ✅ 高度对称的点可能有很大的稳定子（如正方形中心的稳定子是整个对称群）</li>
    </ul>
    
    <p><strong>记忆口诀</strong>："轨道是<strong>点在群下的旅程</strong>，稳定子是<strong>让点待在原地的操作</strong>"</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">子群 (Subgroup) 📦</h5>
    <p><strong>一句话</strong>：子群就是"大群里的一个小群"，它自己也满足群的所有性质。</p>
    
    <p><strong>正式定义</strong>：$H \subseteq G$ 是 $G$ 的子群，如果：</p>
    <ul style="margin-left: 1.5rem;">
      <li>$H$ 在群运算下封闭：$h_1, h_2 \in H \Rightarrow h_1 \cdot h_2 \in H$</li>
      <li>单位元 $e \in H$</li>
      <li>$h \in H \Rightarrow h^{-1} \in H$</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🔄 <strong>欧几里得群的层次</strong>：
        <ul>
          <li>平移 $(\mathbb{R}^2, +)$ ⊂ 刚体变换 $SE(2)$ ⊂ 相似变换 ⊂ 仿射变换 ⊂ 所有可逆变换</li>
        </ul>
      </li>
      <li>🎲 <strong>正方形对称性</strong>：
        <ul>
          <li>所有对称操作（8个）是大群</li>
          <li>只有旋转（4个）是子群</li>
          <li>只有翻转？<strong>不是子群</strong>（两次翻转 = 旋转，不在"只有翻转"的集合里）</li>
        </ul>
      </li>
      <li>🔢 <strong>整数加法</strong>：偶数 ⊂ 整数 ⊂ 有理数 ⊂ 实数（每一层都是下一层的子群）</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>结构层次</strong>：Erlangen纲领的核心思想 → 不同的几何对应不同的对称群，它们是逐层嵌套的子群</li>
      <li><strong>归纳偏置的选择</strong>：选择更小的子群 = 施加更强的约束。例如：
        <ul>
          <li>要求平移等变 → 使用平移群</li>
          <li>要求旋转等变 → 使用 $SE(2)$ 或 $SE(3)$（包含旋转+平移）</li>
          <li>只要求置换等变 → 使用置换群（最大的对称群）</li>
        </ul>
      </li>
      <li><strong>限制 vs 泛化</strong>：子群越小，约束越强，需要的数据越少，但适用范围越窄</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 子集就是子群 → ✅ 必须在群运算下<strong>封闭</strong>（如正方形的"只翻转"不是子群）</li>
      <li>❌ 子群一定比原群小 → ✅ $G$ 本身和 $\{e\}$ 都是平凡子群</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">阿贝尔群 / 非阿贝尔群 (Abelian / Non-Abelian Group) 🔄</h5>
    <p><strong>一句话</strong>：阿贝尔群 = "交换律成立的群"（$g \cdot h = h \cdot g$）；非阿贝尔群 = "顺序很重要的群"。</p>
    
    <p><strong>正式定义</strong>：群 $G$ 是阿贝尔群，如果对所有 $g, h \in G$ 都有 $g \cdot h = h \cdot g$。</p>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>✅ <strong>阿贝尔群：加法</strong>：$2 + 3 = 3 + 2$ → 整数加法、向量加法都是阿贝尔群</li>
      <li>✅ <strong>阿贝尔群：平移</strong>：先向右移2再向上移3 = 先向上移3再向右移2 → $\mathbb{R}^2$ 的平移群是阿贝尔群</li>
      <li>❌ <strong>非阿贝尔群：旋转+平移</strong>：先平移再旋转 ≠ 先旋转再平移 → $SE(2)$ 是非阿贝尔群</li>
      <li>❌ <strong>非阿贝尔群:魔方</strong>：先转顶层再转右侧 ≠ 先转右侧再转顶层 → 魔方群是非阿贝尔的</li>
      <li>❌ <strong>非阿贝尔群：矩阵乘法</strong>：$AB \neq BA$（大部分情况下）</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>计算复杂度</strong>：阿贝尔群的卷积可以用FFT加速，非阿贝尔群不行</li>
      <li><strong>傅里叶分析</strong>：阿贝尔群上的傅里叶变换是1D的，非阿贝尔群上是矩阵值的（更复杂）</li>
      <li><strong>实际例子</strong>：
        <ul>
          <li>平移群 → 阿贝尔 → 标准CNN可以用FFT加速</li>
          <li>$SO(3)$ 旋转群 → 非阿贝尔 → 需要球谐函数、Clebsch-Gordan系数等复杂工具</li>
        </ul>
      </li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 大部分群是阿贝尔的 → ✅ 其实大部分有趣的群都是<strong>非阿贝尔</strong>的！</li>
      <li>❌ 非阿贝尔群很难处理 → ✅ 有专门的工具（如表示论、Clebsch-Gordan系数），但确实比阿贝尔群复杂</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">不可约表示 (Irreducible Representation) 💎</h5>
    <p><strong>一句话</strong>：不可约表示是"不能再分解的最简单的表示"，就像质因数分解里的质数。</p>
    
    <p><strong>正式定义</strong>：群表示 $\rho: G \to \mathbb{R}^{n \times n}$ 是不可约的，如果不存在非平凡的 $G$-不变子空间（即不能分解成更小的表示）。</p>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🎵 <strong>声音的基频</strong>：复杂的声音可以分解成基频的组合 → 基频是"不可约"的</li>
      <li>🌈 <strong>光的颜色</strong>：白光可以分解成红橙黄绿青蓝紫 → 单色光是"不可约"的（在经典物理意义上）</li>
      <li>🔄 <strong>旋转群 $SO(3)$ 的不可约表示</strong>：
        <ul>
          <li>$\ell=0$: 标量（1D）→ 旋转不变</li>
          <li>$\ell=1$: 向量（3D）→ 普通的3D旋转</li>
          <li>$\ell=2$: 5D张量 → 对应球谐函数 $Y_2^m$</li>
          <li>所有高维表示都可以分解成这些"积木"</li>
        </ul>
      </li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>特征空间的分解</strong>：任何 $G$-等变网络的特征空间都可以分解成不可约表示的直和 → 这是设计等变网络的理论基础</li>
      <li><strong>E(3)-等变网络</strong>：
        <ul>
          <li>标量特征（$\ell=0$）：能量、温度等旋转不变量</li>
          <li>向量特征（$\ell=1$）：力、速度等</li>
          <li>高阶张量（$\ell \geq 2$）：应力张量、极化率等</li>
        </ul>
      </li>
      <li><strong>参数效率</strong>：使用不可约表示可以最小化参数数量，同时保持等变性</li>
    </ul>
    
    <p><strong>为什么叫"不可约"</strong>：就像质数不能再因式分解，不可约表示不能再分解成更小的表示。</p>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 不可约表示只有一种 → ✅ 同一个群有无穷多种不可约表示（对应不同的"频率"）</li>
      <li>❌ 不可约表示的维度都一样 → ✅ 维度可以不同（如 $SO(3)$ 的不可约表示维度是 $2\ell+1$）</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">陪集 / 商空间 (Coset / Quotient Space) 📐</h5>
    <p><strong>一句话</strong>：陪集是"子群的平移副本"；商空间是"把等价的东西粘在一起后的空间"。</p>
    
    <p><strong>正式定义</strong>：</p>
    <ul style="margin-left: 1.5rem;">
      <li><strong>左陪集</strong>：给定子群 $H \subseteq G$ 和元素 $g \in G$，左陪集是 $gH = \{gh : h \in H\}$</li>
      <li><strong>商空间</strong>：$G/H = \{gH : g \in G\}$（所有不同的陪集组成的空间）</li>
    </ul>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🕐 <strong>钟表</strong>：$\mathbb{Z}/12\mathbb{Z}$ → 把所有相差12倍数的整数看作相同 → 12小时制</li>
      <li>🌍 <strong>地球上的"纬度圈"</strong>：
        <ul>
          <li>$G = SO(3)$（所有3D旋转），$H = SO(2)$（绕z轴旋转）</li>
          <li>商空间 $SO(3)/SO(2)$ = 球面 $S^2$（每个纬度圈对应一个陪集）</li>
        </ul>
      </li>
      <li>📐 <strong>齐性空间</strong>：
        <ul>
          <li>$SE(3)/SO(3)$ = 3D空间 $\mathbb{R}^3$（固定方向后只剩位置）</li>
          <li>$SE(2)/\mathbb{R}^2$ = 圆 $S^1$（固定位置后只剩方向）</li>
        </ul>
      </li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>齐性空间理论</strong>：很多几何对象可以表示为商空间 $G/H$，这让我们可以在这些空间上定义等变操作</li>
      <li><strong>Steerable CNN</strong>：在 $\mathbb{R}^2 \times SO(2)$ 上定义卷积，然后投影到 $\mathbb{R}^2$</li>
      <li><strong>球面CNN</strong>：球面 $S^2 = SO(3)/SO(2)$，利用这个结构设计球面卷积</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 商空间一定比原空间小 → ✅ 大小可能相同（如 $\mathbb{R}^3 = SE(3)/SO(3)$，两者都是3维）</li>
      <li>❌ 陪集一定是子群 → ✅ 陪集<strong>不是</strong>子群（除非 $gH = H$，即 $g \in H$）</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">形变 (Deformation) 🌊</h5>
    <p><strong>一句话</strong>：形变是"不完全符合对称性的小变化"，比如图片的微小扭曲。</p>
    
    <p><strong>正式定义</strong>：形变是微分同胚 $\tau: \Omega \to \Omega$，可以理解为对域 $\Omega$ 的平滑、可逆的变形。在GDL中，我们关心形变的"复杂度" $c(\tau)$，通常定义为 $c^2(\tau) = \int_\Omega \|\nabla \tau(u)\|^2 du$（Dirichlet能量）。</p>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>📄 <strong>纸张的褶皱</strong>：平整的纸 → 稍微褶皱的纸（不是严格的平移，但"接近"平移）</li>
      <li>🎈 <strong>气球的拉伸</strong>：球形气球 → 稍微拉长的椭球（保持拓扑，但改变度量）</li>
      <li>👤 <strong>人脸的表情</strong>：中性脸 → 微笑（局部形变，不是全局旋转）</li>
      <li>🌊 <strong>流体流动</strong>：水面的波纹（局部的、平滑的位移）</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>形变稳定性 (Deformation Stability)</strong>：$\|f(\rho(\tau)x) - f(x)\| \leq C \cdot c(\tau) \cdot \|x\|$</li>
      <li><strong>为什么需要稳定性而不是不变性？</strong>
        <ul>
          <li>小形变的复合 → 大形变（会改变语义）</li>
          <li>所以不能要求对所有形变不变</li>
          <li>但应该"对小形变敏感度低"</li>
        </ul>
      </li>
      <li><strong>Scattering Transform</strong>：通过多尺度小波+非线性，实现形变稳定性</li>
      <li><strong>数据增强</strong>：随机小形变可以提高泛化能力（elastic deformation）</li>
    </ul>
    
    <p><strong>形变 vs 对称变换</strong>：</p>
    <ul>
      <li><strong>对称变换</strong>（如平移）：$c(g) = 0$，应该完全不变/等变</li>
      <li><strong>小形变</strong>：$c(\tau)$ 很小，应该"几乎"不变（稳定）</li>
      <li><strong>大形变</strong>：$c(\tau)$ 很大，允许改变输出</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 形变 = 任意变换 → ✅ 形变通常指<strong>平滑、可逆</strong>的变换（微分同胚）</li>
      <li>❌ CNN对形变不变 → ✅ CNN对<strong>小</strong>形变<strong>稳定</strong>（不是不变！）</li>
    </ul>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">尺度分离 (Scale Separation) 🔭</h5>
    <p><strong>一句话</strong>：尺度分离是"粗看和细看的信息可以分开处理"，就像看地图可以先看国界再看街道。</p>
    
    <p><strong>正式定义</strong>：如果信号 $x$ 可以分解为不同尺度的成分 $x = \sum_{j} x_j$，其中每个 $x_j$ 主要包含尺度 $2^j$ 附近的信息，则称存在尺度分离。数学上通过小波分解、多分辨率分析实现。</p>
    
    <p><strong>生活例子</strong>：</p>
    <ul>
      <li>🗺️ <strong>地图的多层级</strong>：
        <ul>
          <li>卫星视图：只看大陆、海洋（粗尺度）</li>
          <li>城市视图：看街区、公园（中尺度）</li>
          <li>街道视图：看建筑、商店（细尺度）</li>
        </ul>
      </li>
      <li>👁️ <strong>人类视觉</strong>：
        <ul>
          <li>瞥一眼：看整体形状（粗尺度）</li>
          <li>仔细看：看纹理细节（细尺度）</li>
        </ul>
      </li>
      <li>📸 <strong>图片压缩 (JPEG)</strong>：高频细节可以更大幅度压缩，低频结构必须保留 → 不同尺度的重要性不同</li>
      <li>🌊 <strong>天气系统</strong>：大气环流（千公里尺度）vs 龙卷风（公里尺度）vs 湍流（米尺度）</li>
    </ul>
    
    <p><strong>在 GDL 中为什么重要</strong>：</p>
    <ul>
      <li><strong>CNN的层次结构</strong>：
        <ul>
          <li>浅层：检测边缘、纹理（细尺度）</li>
          <li>中层：检测部件、模式（中尺度）</li>
          <li>深层：检测整体对象（粗尺度）</li>
        </ul>
      </li>
      <li><strong>Pooling</strong>：下采样 = 丢弃细尺度信息，保留粗尺度结构</li>
      <li><strong>克服维度灾难</strong>：
        <ul>
          <li>粗尺度：参数少，覆盖范围大</li>
          <li>细尺度：参数多，但只需要局部信息</li>
          <li>总复杂度：$O(d)$ 而不是 $O(e^d)$</li>
        </ul>
      </li>
      <li><strong>GNN中的图粗化</strong>：通过图池化，逐层得到更粗的图结构</li>
    </ul>
    
    <p><strong>数学工具</strong>：</p>
    <ul>
      <li><strong>小波变换</strong>：$x = \sum_{j,k} \langle x, \psi_{j,k} \rangle \psi_{j,k}$，其中 $j$ 是尺度参数</li>
      <li><strong>Laplacian金字塔</strong>：$x = x_0 + \sum_{j=1}^J (x_j - x_{j-1})$</li>
      <li><strong>傅里叶频率</strong>：高频 ≈ 细尺度，低频 ≈ 粗尺度</li>
    </ul>
    
    <p><strong>常见误解</strong>：</p>
    <ul>
      <li>❌ 尺度分离 = 图片分辨率 → ✅ 是信号<strong>频率内容</strong>的分离，不只是分辨率</li>
      <li>❌ Pooling只是为了降维 → ✅ Pooling实现尺度分离，提取不同层次的特征</li>
      <li>❌ 尺度越细越好 → ✅ 粗尺度特征（如整体形状）往往更robust，细尺度容易过拟合</li>
    </ul>
    
    <p><strong>记忆口诀</strong>："由粗到细，逐层分解；先见森林，再见树木" 🌲🌳🌴</p>
  </div>

  <div class="concept-card" style="margin: 1.5rem 0; padding: 1.2rem; background: rgba(236,72,153,0.06); border-radius: 10px; border: 1px solid rgba(236,72,153,0.2);">
    <h5 style="margin-top: 0; color: #db2777;">🎯 概念关系总图</h5>
    <p><strong>核心逻辑链</strong>：</p>
    <div style="background: rgba(219,39,119,0.1); padding: 1rem; border-radius: 8px; margin: 1rem 0;">
      <p style="margin: 0.5rem 0;"><strong>1. 对称性的数学描述</strong></p>
      <p style="margin-left: 1rem;">群 (Group) → 子群 (选择对称性级别) → 群作用 (作用在数据上) → 群表示 (用矩阵实现)</p>
      
      <p style="margin: 0.5rem 0; margin-top: 1rem;"><strong>2. 网络的设计原则</strong></p>
      <p style="margin-left: 1rem;">等变映射 (中间层) → 不变映射 (最后一层) = 完整架构</p>
      
      <p style="margin: 0.5rem 0; margin-top: 1rem;"><strong>3. 处理不完美的对称性</strong></p>
      <p style="margin-left: 1rem;">形变稳定性 (对小扰动robust) + 尺度分离 (多层次表示) = 克服维度灾难</p>
      
      <p style="margin: 0.5rem 0; margin-top: 1rem;"><strong>4. 高级结构</strong></p>
      <p style="margin-left: 1rem;">同构/自同构 (等价性) → 轨道/稳定子 (等价类) → 陪集/商空间 (商结构) → 不可约表示 (最小单元)</p>
    </div>
    
    <p><strong>实战应用路线图</strong>：</p>
    <ul>
      <li><strong>CNN</strong>：平移群 + 平移等变卷积 + Pooling(尺度分离) → 平移不变分类</li>
      <li><strong>GNN</strong>：置换群 + 置换等变消息传递 + 求和池化 → 置换不变图表示</li>
      <li><strong>E(n)-等变网络</strong>：欧几里得群 $E(n)$ + 不可约表示分解 + 等变线性层 → 旋转+平移等变的分子性质预测</li>
    </ul>
  </div>

</div>
