{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 Ablation Study: Pure PPO vs GNS vs PhysRobot-SV\n",
    "\n",
    "**Self-contained** Colab notebook for the PhysRobot paper ablation.\n",
    "\n",
    "- 3 methods: Pure PPO (~10K), GNS (~5K), PhysRobot-SV (~6K physics + policy)\n",
    "- 500K timesteps x 5 seeds per method\n",
    "- OOD mass sweep: [0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "- All parameters from SPEC.md (single source of truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies\n",
    "%%time\n",
    "!pip install mujoco gymnasium stable-baselines3[extra] torch torch-geometric matplotlib pandas -q\n",
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 2: Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "SAVE_DIR = '/content/drive/MyDrive/physrobot_phase1_ablation'\n",
    "for sub in ['', 'models', 'results', 'logs', 'figures']:\n",
    "    os.makedirs(f'{SAVE_DIR}/{sub}' if sub else SAVE_DIR, exist_ok=True)\n",
    "print(f'Save dir: {SAVE_DIR}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 3: PushBoxEnv (16-dim obs, 2-dim action, per SPEC.md)\n",
    "import numpy as np\n",
    "import mujoco\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "XML = '''<mujoco model=\"push_box\">\n",
    "  <compiler angle=\"degree\" coordinate=\"local\" inertiafromgeom=\"true\"/>\n",
    "  <option timestep=\"0.002\" integrator=\"Euler\" gravity=\"0 0 -9.81\">\n",
    "    <flag warmstart=\"enable\"/>\n",
    "  </option>\n",
    "  <visual>\n",
    "    <global offwidth=\"1280\" offheight=\"720\"/>\n",
    "    <quality shadowsize=\"4096\"/>\n",
    "    <map force=\"0.1\" zfar=\"30\"/>\n",
    "  </visual>\n",
    "  <asset>\n",
    "    <texture builtin=\"gradient\" height=\"100\" rgb1=\"0.3 0.5 0.7\" rgb2=\"0.1 0.2 0.3\" type=\"skybox\" width=\"100\"/>\n",
    "    <texture builtin=\"flat\" height=\"1278\" mark=\"cross\" markrgb=\"1 1 1\" name=\"texgeom\" random=\"0.01\" rgb1=\"0.8 0.6 0.4\" rgb2=\"0.8 0.6 0.4\" type=\"cube\" width=\"127\"/>\n",
    "    <texture builtin=\"checker\" height=\"100\" name=\"texplane\" rgb1=\"0.2 0.2 0.2\" rgb2=\"0.3 0.3 0.3\" type=\"2d\" width=\"100\"/>\n",
    "    <material name=\"MatPlane\" reflectance=\"0.3\" shininess=\"0.5\" specular=\"0.5\" texrepeat=\"3 3\" texture=\"texplane\"/>\n",
    "    <material name=\"geom\" texture=\"texgeom\" texuniform=\"true\"/>\n",
    "  </asset>\n",
    "  <default>\n",
    "    <joint armature=\"0.01\" damping=\"0.1\" limited=\"true\"/>\n",
    "    <geom conaffinity=\"1\" condim=\"3\" contype=\"1\" friction=\"0.5 0.005 0.0001\" margin=\"0.001\" material=\"geom\" rgba=\"0.8 0.6 0.4 1\"/>\n",
    "  </default>\n",
    "  <worldbody>\n",
    "    <light directional=\"true\" diffuse=\"0.8 0.8 0.8\" pos=\"0 0 3\" dir=\"0 0 -1\"/>\n",
    "    <light directional=\"true\" diffuse=\"0.4 0.4 0.4\" pos=\"0 0 3\" dir=\"1 1 -1\"/>\n",
    "    <geom name=\"floor\" type=\"plane\" size=\"3 3 0.1\" rgba=\"0.8 0.8 0.8 1\" material=\"MatPlane\"/>\n",
    "    <body name=\"arm_base\" pos=\"0 0 0.02\">\n",
    "      <geom name=\"base_geom\" type=\"cylinder\" size=\"0.05 0.02\" rgba=\"0.3 0.3 0.3 1\"/>\n",
    "      <body name=\"upper_arm\" pos=\"0 0 0.02\">\n",
    "        <joint name=\"shoulder\" type=\"hinge\" axis=\"0 0 1\" range=\"-180 180\" damping=\"0.5\"/>\n",
    "        <geom name=\"upper_arm_geom\" type=\"capsule\" fromto=\"0 0 0 0.4 0 0\" size=\"0.025\" rgba=\"0.5 0.5 0.8 1\"/>\n",
    "        <body name=\"forearm\" pos=\"0.4 0 0\">\n",
    "          <joint name=\"elbow\" type=\"hinge\" axis=\"0 0 1\" range=\"-180 180\" damping=\"0.5\"/>\n",
    "          <geom name=\"forearm_geom\" type=\"capsule\" fromto=\"0 0 0 0.3 0 0\" size=\"0.025\" rgba=\"0.5 0.5 0.8 1\"/>\n",
    "          <site name=\"endeffector\" pos=\"0.3 0 0\" size=\"0.03\" rgba=\"1 0.5 0 0.8\"/>\n",
    "        </body>\n",
    "      </body>\n",
    "    </body>\n",
    "    <body name=\"box\" pos=\"0.35 0 0.05\">\n",
    "      <freejoint name=\"box_freejoint\"/>\n",
    "      <geom name=\"box_geom\" type=\"box\" size=\"0.05 0.05 0.05\" mass=\"0.5\" rgba=\"0.2 0.8 0.2 1\" friction=\"0.5 0.005 0.0001\"/>\n",
    "      <site name=\"box_center\" pos=\"0 0 0\" size=\"0.01\" rgba=\"0 1 0 1\"/>\n",
    "    </body>\n",
    "    <site name=\"goal\" pos=\"0.5 0.3 0.02\" size=\"0.06\" rgba=\"1 0 0 0.4\" type=\"sphere\"/>\n",
    "  </worldbody>\n",
    "  <actuator>\n",
    "    <motor name=\"shoulder_motor\" joint=\"shoulder\" gear=\"1.0\" ctrllimited=\"true\" ctrlrange=\"-10 10\"/>\n",
    "    <motor name=\"elbow_motor\" joint=\"elbow\" gear=\"1.0\" ctrllimited=\"true\" ctrlrange=\"-10 10\"/>\n",
    "  </actuator>\n",
    "</mujoco>\n",
    "'''\n",
    "\n",
    "\n",
    "class PushBoxEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    PushBox environment per SPEC.md:\n",
    "      - 16-dim obs: [joint_pos(2), joint_vel(2), ee_pos(3), box_pos(3), box_vel(3), goal_pos(3)]\n",
    "      - 2-dim action: [shoulder_torque, elbow_torque] in [-10, 10] Nm\n",
    "      - Success threshold: 0.15 m\n",
    "      - Episode length: 500 steps\n",
    "      - 5 MuJoCo substeps per control step (dt_ctrl = 0.01 s)\n",
    "    \"\"\"\n",
    "    def __init__(self, render_mode=None, box_mass=0.5):\n",
    "        super().__init__()\n",
    "        self.model = mujoco.MjModel.from_xml_string(XML)\n",
    "        self.data = mujoco.MjData(self.model)\n",
    "        self.box_mass = box_mass\n",
    "        self._set_box_mass(box_mass)\n",
    "        self._ee_site_id = mujoco.mj_name2id(\n",
    "            self.model, mujoco.mjtObj.mjOBJ_SITE, 'endeffector'\n",
    "        )\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-10.0, high=10.0, shape=(2,), dtype=np.float32\n",
    "        )\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(16,), dtype=np.float32\n",
    "        )\n",
    "        self.goal_pos = np.array([0.5, 0.3, 0.02])\n",
    "        self.max_episode_steps = 500\n",
    "        self.current_step = 0\n",
    "        self.success_threshold = 0.15\n",
    "        self._prev_dist_box_goal = None\n",
    "        self._prev_dist_ee_box = None\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def _set_box_mass(self, mass):\n",
    "        box_body_id = mujoco.mj_name2id(\n",
    "            self.model, mujoco.mjtObj.mjOBJ_BODY, 'box'\n",
    "        )\n",
    "        self.model.body_mass[box_body_id] = mass\n",
    "\n",
    "    def set_box_mass(self, mass):\n",
    "        self.box_mass = mass\n",
    "        self._set_box_mass(mass)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        mujoco.mj_resetData(self.model, self.data)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.data.qpos[0] = np.random.uniform(-0.5, 0.5)\n",
    "        self.data.qpos[1] = np.random.uniform(-0.5, 0.5)\n",
    "        self.data.qpos[2] = np.random.uniform(0.25, 0.45)\n",
    "        self.data.qpos[3] = np.random.uniform(-0.15, 0.15)\n",
    "        self.data.qpos[4] = 0.05\n",
    "        self.data.qpos[5:9] = [1, 0, 0, 0]\n",
    "        self.data.qvel[:] = 0.0\n",
    "        mujoco.mj_forward(self.model, self.data)\n",
    "        self.current_step = 0\n",
    "        ee_pos = self.data.site_xpos[self._ee_site_id]\n",
    "        box_pos = self.data.qpos[2:5]\n",
    "        self._prev_dist_box_goal = np.linalg.norm(box_pos[:2] - self.goal_pos[:2])\n",
    "        self._prev_dist_ee_box = np.linalg.norm(ee_pos[:2] - box_pos[:2])\n",
    "        return self._get_obs(), self._get_info()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        joint_pos = self.data.qpos[:2].copy()\n",
    "        joint_vel = self.data.qvel[:2].copy()\n",
    "        ee_pos = self.data.site_xpos[self._ee_site_id].copy()\n",
    "        box_pos = self.data.qpos[2:5].copy()\n",
    "        box_vel = self.data.qvel[2:5].copy()\n",
    "        goal_pos = self.goal_pos.copy()\n",
    "        obs = np.concatenate([joint_pos, joint_vel, ee_pos, box_pos, box_vel, goal_pos])\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def _get_info(self):\n",
    "        box_pos = self.data.qpos[2:5]\n",
    "        dist = np.linalg.norm(box_pos[:2] - self.goal_pos[:2])\n",
    "        return {\n",
    "            'distance_to_goal': dist,\n",
    "            'success': dist < self.success_threshold,\n",
    "            'box_mass': self.box_mass,\n",
    "            'timestep': self.current_step,\n",
    "        }\n",
    "\n",
    "    def step(self, action):\n",
    "        self.data.ctrl[:] = action\n",
    "        for _ in range(5):\n",
    "            mujoco.mj_step(self.model, self.data)\n",
    "\n",
    "        ee_pos = self.data.site_xpos[self._ee_site_id].copy()\n",
    "        box_pos = self.data.qpos[2:5].copy()\n",
    "\n",
    "        dist_ee_box = np.linalg.norm(ee_pos[:2] - box_pos[:2])\n",
    "        dist_box_goal = np.linalg.norm(box_pos[:2] - self.goal_pos[:2])\n",
    "\n",
    "        # Progress-based reward (SPEC.md / week1_v2)\n",
    "        reach_progress = self._prev_dist_ee_box - dist_ee_box\n",
    "        self._prev_dist_ee_box = dist_ee_box\n",
    "        push_progress = self._prev_dist_box_goal - dist_box_goal\n",
    "        self._prev_dist_box_goal = dist_box_goal\n",
    "\n",
    "        reward = (\n",
    "            0.5 * (-dist_ee_box)\n",
    "            + 1.0 * (-dist_box_goal)\n",
    "            + 10.0 * reach_progress\n",
    "            + 20.0 * push_progress\n",
    "            - 0.01 * np.sum(action ** 2)\n",
    "        )\n",
    "\n",
    "        success = dist_box_goal < self.success_threshold\n",
    "        if success:\n",
    "            remaining = self.max_episode_steps - self.current_step\n",
    "            reward += 500.0 + remaining * 1.0\n",
    "\n",
    "        self.current_step += 1\n",
    "        terminated = success\n",
    "        truncated = self.current_step >= self.max_episode_steps\n",
    "        return self._get_obs(), reward, terminated, truncated, self._get_info()\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def make_push_box_env(box_mass=0.5):\n",
    "    def _init():\n",
    "        return PushBoxEnv(box_mass=box_mass)\n",
    "    return _init\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "env = PushBoxEnv()\n",
    "obs, info = env.reset()\n",
    "assert obs.shape == (16,), f'Expected 16-dim obs, got {obs.shape}'\n",
    "assert env.action_space.shape == (2,)\n",
    "print(f'Obs: {obs.shape}, Action: {env.action_space.shape}, Threshold: {env.success_threshold}m')\n",
    "env.close()\n",
    "print('[OK] PushBoxEnv ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 4: Agent definitions (Pure PPO, GNS, PhysRobot-SV)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.logger import configure\n",
    "import json\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from torch_geometric.nn import MessagePassing\n",
    "    from torch_geometric.data import Data as PyGData, Batch as PyGBatch\n",
    "    HAS_PYG = True\n",
    "except ImportError:\n",
    "    HAS_PYG = False\n",
    "    print('[WARN] torch_geometric not found; GNS will use fallback MLP.')\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------\n",
    "EPS = 1e-7\n",
    "DEG_EPS = 1e-4\n",
    "\n",
    "\n",
    "def _make_mlp(in_dim, hidden_dim, out_dim):\n",
    "    \"\"\"2-layer MLP with LayerNorm + ReLU (from sv_message_passing.py).\"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_dim, hidden_dim),\n",
    "        nn.LayerNorm(hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, out_dim),\n",
    "    )\n",
    "\n",
    "\n",
    "def count_params(module):\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Logging callback: records per-episode reward + success\n",
    "# ---------------------------------------------------------------\n",
    "class LoggingCallback(BaseCallback):\n",
    "    \"\"\"Tracks episode rewards and successes for learning curves.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ep_rewards = []\n",
    "        self.ep_successes = []\n",
    "        self.ep_timesteps = []\n",
    "        self._current_rewards = None\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        n_envs = self.training_env.num_envs\n",
    "        self._current_rewards = [0.0] * n_envs\n",
    "\n",
    "    def _on_step(self):\n",
    "        rewards = self.locals.get('rewards', [])\n",
    "        dones = self.locals.get('dones', [])\n",
    "        infos = self.locals.get('infos', [{}])\n",
    "        for i in range(len(dones)):\n",
    "            if i < len(rewards):\n",
    "                self._current_rewards[i] += rewards[i]\n",
    "            if dones[i]:\n",
    "                self.ep_rewards.append(self._current_rewards[i])\n",
    "                info = infos[i] if i < len(infos) else {}\n",
    "                self.ep_successes.append(1 if info.get('success', False) else 0)\n",
    "                self.ep_timesteps.append(self.num_timesteps)\n",
    "                self._current_rewards[i] = 0.0\n",
    "        return True\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# AGENT 1: Pure PPO  (~10K params, [64,64] MLP pi + vf)\n",
    "# ===============================================================\n",
    "# Uses SB3 MlpPolicy with net_arch=dict(pi=[64,64], vf=[64,64])\n",
    "# No features extractor beyond default flatten.\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# AGENT 2: GNS  (~5K params, d_h=32, L=1)\n",
    "# ===============================================================\n",
    "\n",
    "def obs_to_graph_batch(observations):\n",
    "    \"\"\"Convert [B,16] obs -> PyG Batch with 2 nodes (ee, box).\"\"\"\n",
    "    B = observations.shape[0]\n",
    "    dev = observations.device\n",
    "    graphs = []\n",
    "    for i in range(B):\n",
    "        o = observations[i]\n",
    "        ee_pos = o[4:7]\n",
    "        ee_vel = torch.zeros(3, device=dev)\n",
    "        box_pos = o[7:10]\n",
    "        box_vel = o[10:13]\n",
    "        positions = torch.stack([ee_pos, box_pos])\n",
    "        velocities = torch.stack([ee_vel, box_vel])\n",
    "        node_feats = torch.cat([positions, velocities], dim=-1)  # [2,6]\n",
    "        edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long, device=dev).t().contiguous()\n",
    "        rel01 = box_pos - ee_pos\n",
    "        rel10 = ee_pos - box_pos\n",
    "        d01 = torch.norm(rel01).unsqueeze(0)\n",
    "        d10 = torch.norm(rel10).unsqueeze(0)\n",
    "        edge_attr = torch.stack([torch.cat([rel01, d01]), torch.cat([rel10, d10])])\n",
    "        g = PyGData(x=node_feats, pos=positions, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        graphs.append(g)\n",
    "    return PyGBatch.from_data_list(graphs)\n",
    "\n",
    "\n",
    "if HAS_PYG:\n",
    "    class GNSGraphLayerV2(MessagePassing):\n",
    "        \"\"\"Single GN message-passing layer. ~2K params.\"\"\"\n",
    "        def __init__(self, node_dim, edge_dim, hidden_dim=32):\n",
    "            super().__init__(aggr='add')\n",
    "            self.edge_mlp = nn.Sequential(\n",
    "                nn.Linear(2 * node_dim + edge_dim, hidden_dim), nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, edge_dim),\n",
    "            )\n",
    "            self.node_mlp = nn.Sequential(\n",
    "                nn.Linear(node_dim + edge_dim, hidden_dim), nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, node_dim),\n",
    "            )\n",
    "\n",
    "        def forward(self, x, edge_index, edge_attr):\n",
    "            return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        def message(self, x_i, x_j, edge_attr):\n",
    "            return self.edge_mlp(torch.cat([x_i, x_j, edge_attr], dim=-1))\n",
    "\n",
    "        def update(self, aggr_out, x):\n",
    "            return self.node_mlp(torch.cat([x, aggr_out], dim=-1))\n",
    "\n",
    "    class GNSFeaturesExtractorV2(BaseFeaturesExtractor):\n",
    "        \"\"\"GNS extractor: node_enc -> 1x GNSGraphLayer -> decoder -> proj. ~5K params.\"\"\"\n",
    "        def __init__(self, observation_space, features_dim=64):\n",
    "            super().__init__(observation_space, features_dim)\n",
    "            hid = 32\n",
    "            edge_dim = 4\n",
    "            self.node_encoder = nn.Sequential(nn.Linear(6, hid), nn.ReLU())\n",
    "            self.edge_encoder = nn.Sequential(nn.Linear(edge_dim, hid), nn.ReLU())\n",
    "            self.gn_layer = GNSGraphLayerV2(hid, hid, hid)\n",
    "            self.decoder = nn.Linear(hid, 3)\n",
    "            self.feature_proj = nn.Sequential(\n",
    "                nn.Linear(3 + 16, features_dim), nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        def forward(self, observations):\n",
    "            graph = obs_to_graph_batch(observations)\n",
    "            x = self.node_encoder(graph.x)\n",
    "            ea = self.edge_encoder(graph.edge_attr)\n",
    "            x = x + self.gn_layer(x, graph.edge_index, ea)\n",
    "            acc = self.decoder(x)\n",
    "            box_acc = acc[1::2]\n",
    "            combined = torch.cat([box_acc, observations], dim=-1)\n",
    "            return self.feature_proj(combined)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# AGENT 3: PhysRobot-SV  (SV message passing from sv_message_passing.py)\n",
    "# ===============================================================\n",
    "\n",
    "def build_edge_frames(pos, vel, src, dst):\n",
    "    \"\"\"\n",
    "    Antisymmetric edge-local ONB {e1, e2, e3}.\n",
    "    From sv_message_passing.py L57-112.\n",
    "    \"\"\"\n",
    "    r_ij = pos[dst] - pos[src]\n",
    "    d_ij = torch.norm(r_ij, dim=-1, keepdim=True)\n",
    "    e1 = r_ij / (d_ij + EPS)\n",
    "\n",
    "    v_rel = vel[dst] - vel[src]\n",
    "    v_par = (v_rel * e1).sum(dim=-1, keepdim=True) * e1\n",
    "    v_perp = v_rel - v_par\n",
    "    v_perp_norm = torch.norm(v_perp, dim=-1, keepdim=True)\n",
    "\n",
    "    non_degenerate = (v_perp_norm > DEG_EPS).float()\n",
    "    e2_vel = v_perp / (v_perp_norm + EPS)\n",
    "\n",
    "    z_hat = torch.tensor([0.0, 0.0, 1.0], device=pos.device).expand_as(e1)\n",
    "    e2_fall_raw = torch.cross(e1, z_hat, dim=-1)\n",
    "    e2_fall_norm = torch.norm(e2_fall_raw, dim=-1, keepdim=True)\n",
    "    use_y = (e2_fall_norm < DEG_EPS).float()\n",
    "    y_hat = torch.tensor([0.0, 1.0, 0.0], device=pos.device).expand_as(e1)\n",
    "    e2_fall_raw2 = torch.cross(e1, y_hat, dim=-1)\n",
    "    e2_fall_raw = (1 - use_y) * e2_fall_raw + use_y * e2_fall_raw2\n",
    "    e2_fall_norm = torch.norm(e2_fall_raw, dim=-1, keepdim=True)\n",
    "    e2_fall = e2_fall_raw / (e2_fall_norm + EPS)\n",
    "\n",
    "    e2 = non_degenerate * e2_vel + (1 - non_degenerate) * e2_fall\n",
    "    e3 = torch.cross(e1, e2, dim=-1)\n",
    "\n",
    "    return e1, e2, e3, r_ij, d_ij\n",
    "\n",
    "\n",
    "class SVMessagePassing(nn.Module):\n",
    "    \"\"\"\n",
    "    One round of SV message passing (undirected-pair approach).\n",
    "    Hard-codes Newton's 3rd law: +F to j, -F to i.\n",
    "    From sv_message_passing.py L110-234.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_dim, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.node_dim = node_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        n_scalar = 5  # d, v_r, v_t, v_b, ||v||\n",
    "        self.force_mlp = _make_mlp(\n",
    "            in_dim=n_scalar + 2 * node_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_dim=3,\n",
    "        )\n",
    "        self.node_update = _make_mlp(\n",
    "            in_dim=node_dim + 3,\n",
    "            hidden_dim=hidden_dim,\n",
    "            out_dim=node_dim,\n",
    "        )\n",
    "\n",
    "    def _extract_undirected_pairs(self, edge_index):\n",
    "        src, dst = edge_index[0], edge_index[1]\n",
    "        mask = src < dst\n",
    "        return torch.stack([src[mask], dst[mask]], dim=0)\n",
    "\n",
    "    def forward_with_forces(self, h, edge_index, pos, vel):\n",
    "        N = h.size(0)\n",
    "        pairs = self._extract_undirected_pairs(edge_index)\n",
    "        pi, pj = pairs[0], pairs[1]\n",
    "\n",
    "        e1, e2, e3, r_ij, d_ij = build_edge_frames(pos, vel, pi, pj)\n",
    "        v_rel = vel[pj] - vel[pi]\n",
    "\n",
    "        v_r = (v_rel * e1).sum(dim=-1, keepdim=True)\n",
    "        v_t = (v_rel * e2).sum(dim=-1, keepdim=True)\n",
    "        v_b = (v_rel * e3).sum(dim=-1, keepdim=True)\n",
    "        v_norm = torch.norm(v_rel, dim=-1, keepdim=True)\n",
    "\n",
    "        scalars_geom = torch.cat([d_ij, v_r, v_t, v_b, v_norm], dim=-1)\n",
    "        h_sum = h[pi] + h[pj]\n",
    "        h_diff_abs = (h[pi] - h[pj]).abs()\n",
    "        scalars = torch.cat([scalars_geom, h_sum, h_diff_abs], dim=-1)\n",
    "\n",
    "        alphas = self.force_mlp(scalars)\n",
    "        alpha1, alpha2, alpha3 = alphas[:, 0:1], alphas[:, 1:2], alphas[:, 2:3]\n",
    "        force_ij = alpha1 * e1 + alpha2 * e2 + alpha3 * e3\n",
    "\n",
    "        F_agg = torch.zeros(N, 3, device=h.device, dtype=h.dtype)\n",
    "        F_agg.scatter_add_(0, pj.unsqueeze(-1).expand_as(force_ij), force_ij)\n",
    "        F_agg.scatter_add_(0, pi.unsqueeze(-1).expand_as(force_ij), -force_ij)\n",
    "\n",
    "        h_input = torch.cat([h, F_agg], dim=-1)\n",
    "        h_new = h + self.node_update(h_input)\n",
    "        return h_new, F_agg\n",
    "\n",
    "\n",
    "class SVPhysicsCore(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics stream: encoder -> L x SVMessagePassing -> forces.\n",
    "    PushBox config: node_input=6, d_h=32, L=1. ~6K params.\n",
    "    From sv_message_passing.py L242-314.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_input_dim=6, hidden_dim=32, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder = _make_mlp(node_input_dim, hidden_dim, hidden_dim)\n",
    "        self.sv_layers = nn.ModuleList([\n",
    "            SVMessagePassing(node_dim=hidden_dim, hidden_dim=hidden_dim)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, positions, velocities, edge_index):\n",
    "        node_features = torch.cat([positions, velocities], dim=-1)\n",
    "        h = self.encoder(node_features)\n",
    "        forces = None\n",
    "        for layer in self.sv_layers:\n",
    "            h, F_agg = layer.forward_with_forces(h, edge_index, positions, velocities)\n",
    "            forces = F_agg\n",
    "        return forces\n",
    "\n",
    "\n",
    "class PhysRobotSVExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    Dual-stream extractor with real SV message passing.\n",
    "    Policy stream: MLP 16->64->64 (ReLU)\n",
    "    Physics stream: SVPhysicsCore (d_h=32, L=1)\n",
    "    Fusion: Linear(64+3, 64) + ReLU, with stop-gradient on physics.\n",
    "    From sv_message_passing.py L340-421.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, features_dim=64):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        self.physics_core = SVPhysicsCore(\n",
    "            node_input_dim=6, hidden_dim=32, n_layers=1,\n",
    "        )\n",
    "        self.policy_stream = nn.Sequential(\n",
    "            nn.Linear(16, 64), nn.ReLU(),\n",
    "            nn.Linear(64, features_dim), nn.ReLU(),\n",
    "        )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(features_dim + 3, features_dim), nn.ReLU(),\n",
    "        )\n",
    "        self._edge_index_2 = torch.tensor(\n",
    "            [[0, 1], [1, 0]], dtype=torch.long\n",
    "        ).t()\n",
    "\n",
    "    def _obs_to_graph(self, obs):\n",
    "        ee_pos = obs[:, 4:7]\n",
    "        box_pos = obs[:, 7:10]\n",
    "        box_vel = obs[:, 10:13]\n",
    "        ee_vel = torch.zeros_like(ee_pos)\n",
    "        return ee_pos, ee_vel, box_pos, box_vel\n",
    "\n",
    "    def forward(self, observations):\n",
    "        B = observations.shape[0]\n",
    "        device = observations.device\n",
    "        z_policy = self.policy_stream(observations)\n",
    "        ee_pos, ee_vel, box_pos, box_vel = self._obs_to_graph(observations)\n",
    "        edge_index = self._edge_index_2.to(device)\n",
    "        box_acc_list = []\n",
    "        for i in range(B):\n",
    "            pos_i = torch.stack([ee_pos[i], box_pos[i]], dim=0)\n",
    "            vel_i = torch.stack([ee_vel[i], box_vel[i]], dim=0)\n",
    "            acc_i = self.physics_core(pos_i, vel_i, edge_index)\n",
    "            box_acc_list.append(acc_i[1])  # box node\n",
    "        z_physics = torch.stack(box_acc_list, dim=0)\n",
    "        z_physics_sg = z_physics.detach()  # stop-gradient\n",
    "        combined = torch.cat([z_policy, z_physics_sg], dim=-1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Param count verification\n",
    "# ---------------------------------------------------------------\n",
    "_tmp_env = DummyVecEnv([make_push_box_env()])\n",
    "\n",
    "# Pure PPO\n",
    "_ppo = PPO('MlpPolicy', _tmp_env, policy_kwargs=dict(\n",
    "    net_arch=dict(pi=[64, 64], vf=[64, 64])), verbose=0)\n",
    "print(f'Pure PPO policy params: {count_params(_ppo.policy):>8,}')\n",
    "\n",
    "# GNS\n",
    "if HAS_PYG:\n",
    "    _gns = PPO('MlpPolicy', _tmp_env, policy_kwargs=dict(\n",
    "        features_extractor_class=GNSFeaturesExtractorV2,\n",
    "        features_extractor_kwargs=dict(features_dim=64),\n",
    "        net_arch=dict(pi=[64, 64], vf=[64, 64])), verbose=0)\n",
    "    print(f'GNS policy params:      {count_params(_gns.policy):>8,}')\n",
    "    del _gns\n",
    "\n",
    "# PhysRobot-SV\n",
    "_sv = PPO('MlpPolicy', _tmp_env, policy_kwargs=dict(\n",
    "    features_extractor_class=PhysRobotSVExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=64),\n",
    "    net_arch=dict(pi=[64, 64], vf=[64, 64])), verbose=0)\n",
    "print(f'PhysRobot-SV params:    {count_params(_sv.policy):>8,}')\n",
    "\n",
    "# Physics core alone\n",
    "_phys = SVPhysicsCore(node_input_dim=6, hidden_dim=32, n_layers=1)\n",
    "print(f'  (physics core only:   {count_params(_phys):>8,})')\n",
    "\n",
    "del _ppo, _sv, _phys\n",
    "_tmp_env.close()\n",
    "print('[OK] All 3 agents defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 5: Training configuration (SPEC.md)\n",
    "METHODS = ['Pure_PPO', 'GNS', 'PhysRobot_SV']\n",
    "SEEDS = [42, 123, 256, 789, 1024]\n",
    "TOTAL_TIMESTEPS = 500_000\n",
    "N_ENVS = 4\n",
    "BOX_MASS_TRAIN = 0.5  # default training mass\n",
    "EVAL_EPISODES = 100\n",
    "EVAL_FREQ = 50_000  # evaluate every 50K steps\n",
    "OOD_MASSES = [0.5, 0.75, 1.0, 1.5, 2.0]\n",
    "\n",
    "# PPO hyperparams (SPEC.md Section 3)\n",
    "PPO_KWARGS = dict(\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.01,\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "print('=== Phase 1 Ablation Config ===')\n",
    "print(f'Methods:    {METHODS}')\n",
    "print(f'Seeds:      {SEEDS}')\n",
    "print(f'Timesteps:  {TOTAL_TIMESTEPS:,}')\n",
    "print(f'Envs:       {N_ENVS}')\n",
    "print(f'OOD masses: {OOD_MASSES}')\n",
    "est_min = len(METHODS) * len(SEEDS) * TOTAL_TIMESTEPS / 200_000 * 5\n",
    "print(f'Est. time:  ~{est_min:.0f} min on T4')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 6: Training loop (3 methods x 5 seeds)\n",
    "%%time\n",
    "all_results = {}  # {method: {seed: {callback, model, train_time}}}\n",
    "\n",
    "\n",
    "def make_model(method, env, seed):\n",
    "    \"\"\"Create PPO model for the given method.\"\"\"\n",
    "    if method == 'Pure_PPO':\n",
    "        policy_kwargs = dict(net_arch=dict(pi=[64, 64], vf=[64, 64]))\n",
    "    elif method == 'GNS':\n",
    "        if HAS_PYG:\n",
    "            policy_kwargs = dict(\n",
    "                features_extractor_class=GNSFeaturesExtractorV2,\n",
    "                features_extractor_kwargs=dict(features_dim=64),\n",
    "                net_arch=dict(pi=[64, 64], vf=[64, 64]),\n",
    "            )\n",
    "        else:\n",
    "            policy_kwargs = dict(net_arch=dict(pi=[64, 64], vf=[64, 64]))\n",
    "    elif method == 'PhysRobot_SV':\n",
    "        policy_kwargs = dict(\n",
    "            features_extractor_class=PhysRobotSVExtractor,\n",
    "            features_extractor_kwargs=dict(features_dim=64),\n",
    "            net_arch=dict(pi=[64, 64], vf=[64, 64]),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: {method}')\n",
    "\n",
    "    model = PPO(\n",
    "        'MlpPolicy', env, seed=seed,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        **PPO_KWARGS,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "for method in METHODS:\n",
    "    all_results[method] = {}\n",
    "    for seed in SEEDS:\n",
    "        tag = f'{method}/seed_{seed}'\n",
    "        print(f'\\n{\"=\"*60}')\n",
    "        print(f'Training {tag} ({TOTAL_TIMESTEPS/1000:.0f}K steps)')\n",
    "        print(f'{\"=\"*60}')\n",
    "\n",
    "        # Build envs\n",
    "        env = DummyVecEnv([make_push_box_env(BOX_MASS_TRAIN) for _ in range(N_ENVS)])\n",
    "\n",
    "        model = make_model(method, env, seed)\n",
    "        cb = LoggingCallback()\n",
    "\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            model.learn(total_timesteps=TOTAL_TIMESTEPS, callback=cb, progress_bar=True)\n",
    "            train_time = time.time() - t0\n",
    "            # Save model\n",
    "            model_path = f'{SAVE_DIR}/models/{method}_seed{seed}'\n",
    "            model.save(model_path)\n",
    "\n",
    "            all_results[method][seed] = {\n",
    "                'ep_rewards': cb.ep_rewards,\n",
    "                'ep_successes': cb.ep_successes,\n",
    "                'ep_timesteps': cb.ep_timesteps,\n",
    "                'train_time': train_time,\n",
    "                'model_path': model_path,\n",
    "            }\n",
    "            n_succ = sum(cb.ep_successes)\n",
    "            n_ep = len(cb.ep_successes)\n",
    "            sr = n_succ / max(n_ep, 1)\n",
    "            print(f'  -> Done in {train_time/60:.1f}m  |  {n_ep} episodes  |  SR={sr:.1%}')\n",
    "\n",
    "        except Exception as e:\n",
    "            train_time = time.time() - t0\n",
    "            print(f'  -> FAILED after {train_time/60:.1f}m: {e}')\n",
    "            import traceback; traceback.print_exc()\n",
    "            all_results[method][seed] = {'error': str(e)}\n",
    "        finally:\n",
    "            env.close()\n",
    "\n",
    "# Save raw data\n",
    "raw_path = f'{SAVE_DIR}/results/all_training_raw.json'\n",
    "_serializable = {}\n",
    "for m in all_results:\n",
    "    _serializable[m] = {}\n",
    "    for s, d in all_results[m].items():\n",
    "        if 'error' in d:\n",
    "            _serializable[m][str(s)] = d\n",
    "        else:\n",
    "            _serializable[m][str(s)] = {\n",
    "                'ep_rewards': [float(x) for x in d['ep_rewards']],\n",
    "                'ep_successes': d['ep_successes'],\n",
    "                'ep_timesteps': d['ep_timesteps'],\n",
    "                'train_time': d['train_time'],\n",
    "            }\n",
    "with open(raw_path, 'w') as f:\n",
    "    json.dump(_serializable, f)\n",
    "print(f'\\nRaw results saved -> {raw_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 7: Evaluation + OOD mass sweep\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "eval_results = {}  # {method: {seed: {mass: {sr, mean_rew, std_rew}}}}\n",
    "\n",
    "for method in METHODS:\n",
    "    eval_results[method] = {}\n",
    "    for seed in SEEDS:\n",
    "        data = all_results[method].get(seed, {})\n",
    "        if 'error' in data or 'model_path' not in data:\n",
    "            print(f'Skipping {method}/seed_{seed} (no model)')\n",
    "            continue\n",
    "\n",
    "        model_path = data['model_path']\n",
    "        model = PPO.load(model_path)\n",
    "\n",
    "        eval_results[method][seed] = {}\n",
    "        for mass in OOD_MASSES:\n",
    "            test_env = PushBoxEnv(box_mass=mass)\n",
    "            rewards_list, successes_list = [], []\n",
    "            for ep_seed in range(10000, 10000 + EVAL_EPISODES):\n",
    "                obs, info = test_env.reset(seed=ep_seed)\n",
    "                done, ep_rew = False, 0.0\n",
    "                while not done:\n",
    "                    action, _ = model.predict(obs, deterministic=True)\n",
    "                    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "                    ep_rew += reward\n",
    "                    done = terminated or truncated\n",
    "                rewards_list.append(ep_rew)\n",
    "                successes_list.append(1 if info.get('success', False) else 0)\n",
    "            test_env.close()\n",
    "\n",
    "            sr = np.mean(successes_list)\n",
    "            eval_results[method][seed][mass] = {\n",
    "                'success_rate': float(sr),\n",
    "                'mean_reward': float(np.mean(rewards_list)),\n",
    "                'std_reward': float(np.std(rewards_list)),\n",
    "            }\n",
    "            tag = '[train]' if mass == BOX_MASS_TRAIN else '[OOD]'\n",
    "            print(f'  {method} seed={seed} mass={mass} {tag}: SR={sr:.1%}')\n",
    "\n",
    "# Save eval results\n",
    "eval_path = f'{SAVE_DIR}/results/eval_ood_results.json'\n",
    "_eval_ser = {}\n",
    "for m in eval_results:\n",
    "    _eval_ser[m] = {}\n",
    "    for s, masses in eval_results[m].items():\n",
    "        _eval_ser[m][str(s)] = {str(k): v for k, v in masses.items()}\n",
    "with open(eval_path, 'w') as f:\n",
    "    json.dump(_eval_ser, f, indent=2)\n",
    "print(f'\\nEval results saved -> {eval_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 8: Figures -- learning curves + OOD bar charts\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "COLORS = {'Pure_PPO': '#4CAF50', 'GNS': '#2196F3', 'PhysRobot_SV': '#FF9800'}\n",
    "LABELS = {'Pure_PPO': 'Pure PPO', 'GNS': 'GNS', 'PhysRobot_SV': 'PhysRobot-SV'}\n",
    "\n",
    "# ------- 1. Learning curves (rolling SR) -------\n",
    "WINDOW = 50  # episodes\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# (a) Rolling success rate vs timesteps\n",
    "ax = axes[0]\n",
    "for method in METHODS:\n",
    "    all_curves = []\n",
    "    for seed in SEEDS:\n",
    "        d = all_results[method].get(seed, {})\n",
    "        if 'error' in d or 'ep_successes' not in d:\n",
    "            continue\n",
    "        succ = np.array(d['ep_successes'], dtype=float)\n",
    "        ts = np.array(d['ep_timesteps'], dtype=float)\n",
    "        if len(succ) < WINDOW:\n",
    "            continue\n",
    "        # Rolling average\n",
    "        roll = np.convolve(succ, np.ones(WINDOW)/WINDOW, mode='valid')\n",
    "        roll_ts = ts[WINDOW-1:]\n",
    "        all_curves.append((roll_ts, roll))\n",
    "\n",
    "    if not all_curves:\n",
    "        continue\n",
    "\n",
    "    # Interpolate to common x-grid for mean/std\n",
    "    x_grid = np.linspace(0, TOTAL_TIMESTEPS, 200)\n",
    "    interp_curves = []\n",
    "    for ts_c, roll_c in all_curves:\n",
    "        interp_y = np.interp(x_grid, ts_c, roll_c, left=roll_c[0], right=roll_c[-1])\n",
    "        interp_curves.append(interp_y)\n",
    "    interp_curves = np.array(interp_curves)\n",
    "    mean_curve = interp_curves.mean(axis=0)\n",
    "    std_curve = interp_curves.std(axis=0)\n",
    "\n",
    "    color = COLORS[method]\n",
    "    ax.plot(x_grid / 1000, mean_curve * 100, label=LABELS[method], color=color, linewidth=2)\n",
    "    ax.fill_between(\n",
    "        x_grid / 1000,\n",
    "        (mean_curve - std_curve) * 100,\n",
    "        (mean_curve + std_curve) * 100,\n",
    "        alpha=0.2, color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Timesteps (K)')\n",
    "ax.set_ylabel('Success Rate (%)')\n",
    "ax.set_title(f'Learning Curves (rolling {WINDOW}-ep SR, mean +/- std over {len(SEEDS)} seeds)')\n",
    "ax.legend()\n",
    "ax.set_ylim(-5, 105)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# (b) Rolling episode reward\n",
    "ax = axes[1]\n",
    "for method in METHODS:\n",
    "    all_curves = []\n",
    "    for seed in SEEDS:\n",
    "        d = all_results[method].get(seed, {})\n",
    "        if 'error' in d or 'ep_rewards' not in d:\n",
    "            continue\n",
    "        rews = np.array(d['ep_rewards'], dtype=float)\n",
    "        ts = np.array(d['ep_timesteps'], dtype=float)\n",
    "        if len(rews) < WINDOW:\n",
    "            continue\n",
    "        roll = np.convolve(rews, np.ones(WINDOW)/WINDOW, mode='valid')\n",
    "        roll_ts = ts[WINDOW-1:]\n",
    "        all_curves.append((roll_ts, roll))\n",
    "\n",
    "    if not all_curves:\n",
    "        continue\n",
    "\n",
    "    x_grid = np.linspace(0, TOTAL_TIMESTEPS, 200)\n",
    "    interp_curves = []\n",
    "    for ts_c, roll_c in all_curves:\n",
    "        interp_y = np.interp(x_grid, ts_c, roll_c, left=roll_c[0], right=roll_c[-1])\n",
    "        interp_curves.append(interp_y)\n",
    "    interp_curves = np.array(interp_curves)\n",
    "    mean_curve = interp_curves.mean(axis=0)\n",
    "    std_curve = interp_curves.std(axis=0)\n",
    "\n",
    "    color = COLORS[method]\n",
    "    ax.plot(x_grid / 1000, mean_curve, label=LABELS[method], color=color, linewidth=2)\n",
    "    ax.fill_between(\n",
    "        x_grid / 1000,\n",
    "        mean_curve - std_curve,\n",
    "        mean_curve + std_curve,\n",
    "        alpha=0.2, color=color,\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Timesteps (K)')\n",
    "ax.set_ylabel('Episode Reward')\n",
    "ax.set_title(f'Learning Curves (rolling {WINDOW}-ep reward, mean +/- std)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{SAVE_DIR}/figures/learning_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: learning_curves.png')\n",
    "\n",
    "\n",
    "# ------- 2. OOD Bar Charts -------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# (a) In-distribution SR comparison (bar chart)\n",
    "ax = axes[0]\n",
    "bar_data = []\n",
    "for method in METHODS:\n",
    "    srs = []\n",
    "    for seed in SEEDS:\n",
    "        if seed in eval_results.get(method, {}):\n",
    "            sr = eval_results[method][seed].get(BOX_MASS_TRAIN, {}).get('success_rate', 0)\n",
    "            srs.append(sr)\n",
    "    if srs:\n",
    "        bar_data.append((method, np.mean(srs), np.std(srs)))\n",
    "    else:\n",
    "        bar_data.append((method, 0, 0))\n",
    "\n",
    "x_pos = np.arange(len(bar_data))\n",
    "means = [d[1] * 100 for d in bar_data]\n",
    "stds = [d[2] * 100 for d in bar_data]\n",
    "colors = [COLORS[d[0]] for d in bar_data]\n",
    "bars = ax.bar(x_pos, means, yerr=stds, capsize=5, color=colors, alpha=0.85)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([LABELS[d[0]] for d in bar_data])\n",
    "ax.set_ylabel('Success Rate (%)')\n",
    "ax.set_title(f'In-Distribution SR (mass={BOX_MASS_TRAIN}, {len(SEEDS)} seeds)')\n",
    "ax.set_ylim(0, 105)\n",
    "for bar, m in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2., bar.get_height() + 2,\n",
    "            f'{m:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# (b) OOD SR vs mass (line plot)\n",
    "ax = axes[1]\n",
    "for method in METHODS:\n",
    "    mass_means = []\n",
    "    mass_stds = []\n",
    "    for mass in OOD_MASSES:\n",
    "        srs = []\n",
    "        for seed in SEEDS:\n",
    "            if seed in eval_results.get(method, {}):\n",
    "                sr = eval_results[method][seed].get(mass, {}).get('success_rate', 0)\n",
    "                srs.append(sr)\n",
    "        if srs:\n",
    "            mass_means.append(np.mean(srs))\n",
    "            mass_stds.append(np.std(srs))\n",
    "        else:\n",
    "            mass_means.append(0)\n",
    "            mass_stds.append(0)\n",
    "\n",
    "    mass_means = np.array(mass_means) * 100\n",
    "    mass_stds = np.array(mass_stds) * 100\n",
    "    color = COLORS[method]\n",
    "    ax.errorbar(\n",
    "        OOD_MASSES, mass_means, yerr=mass_stds,\n",
    "        fmt='o-', label=LABELS[method], color=color,\n",
    "        linewidth=2, markersize=8, capsize=4,\n",
    "    )\n",
    "\n",
    "ax.axvline(x=BOX_MASS_TRAIN, color='gray', linestyle='--', alpha=0.5, label='Training mass')\n",
    "ax.set_xlabel('Box Mass (kg)')\n",
    "ax.set_ylabel('Success Rate (%)')\n",
    "ax.set_title(f'OOD Generalization (mass sweep, {len(SEEDS)} seeds)')\n",
    "ax.legend()\n",
    "ax.set_ylim(-5, 105)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{SAVE_DIR}/figures/ood_bar_charts.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: ood_bar_charts.png')\n",
    "\n",
    "\n",
    "# ------- 3. Summary table -------\n",
    "print('\\n' + '=' * 70)\n",
    "print('SUMMARY TABLE')\n",
    "print('=' * 70)\n",
    "header = f'{\"Method\":<16} {\"ID SR (%)\":<12} {\"OOD-1.0 (%)\":<12} {\"OOD-2.0 (%)\":<12} {\"Time (min)\":<12}'\n",
    "print(header)\n",
    "print('-' * 70)\n",
    "for method in METHODS:\n",
    "    id_srs, ood1_srs, ood2_srs, times = [], [], [], []\n",
    "    for seed in SEEDS:\n",
    "        d = all_results[method].get(seed, {})\n",
    "        if 'train_time' in d:\n",
    "            times.append(d['train_time'])\n",
    "        if seed in eval_results.get(method, {}):\n",
    "            id_srs.append(eval_results[method][seed].get(BOX_MASS_TRAIN, {}).get('success_rate', 0))\n",
    "            ood1_srs.append(eval_results[method][seed].get(1.0, {}).get('success_rate', 0))\n",
    "            ood2_srs.append(eval_results[method][seed].get(2.0, {}).get('success_rate', 0))\n",
    "\n",
    "    def fmt(arr):\n",
    "        if not arr:\n",
    "            return 'N/A'\n",
    "        return f'{np.mean(arr)*100:.1f} +/- {np.std(arr)*100:.1f}'\n",
    "\n",
    "    t_str = f'{np.mean(times)/60:.1f}' if times else 'N/A'\n",
    "    print(f'{LABELS[method]:<16} {fmt(id_srs):<12} {fmt(ood1_srs):<12} {fmt(ood2_srs):<12} {t_str:<12}')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cell 9: Save everything to Drive\n",
    "import shutil\n",
    "\n",
    "# Final summary JSON\n",
    "summary = {\n",
    "    'config': {\n",
    "        'methods': METHODS,\n",
    "        'seeds': SEEDS,\n",
    "        'total_timesteps': TOTAL_TIMESTEPS,\n",
    "        'n_envs': N_ENVS,\n",
    "        'box_mass_train': BOX_MASS_TRAIN,\n",
    "        'eval_episodes': EVAL_EPISODES,\n",
    "        'ood_masses': OOD_MASSES,\n",
    "        'ppo_kwargs': {k: v for k, v in PPO_KWARGS.items() if k != 'verbose'},\n",
    "    },\n",
    "    'eval_results': _eval_ser,\n",
    "}\n",
    "summary_path = f'{SAVE_DIR}/results/phase1_ablation_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print('=== Files saved to Google Drive ===')\n",
    "for root, dirs, files in os.walk(SAVE_DIR):\n",
    "    level = root.replace(SAVE_DIR, '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    sub_indent = '  ' * (level + 1)\n",
    "    for f in sorted(files):\n",
    "        fpath = os.path.join(root, f)\n",
    "        size_kb = os.path.getsize(fpath) / 1024\n",
    "        print(f'{sub_indent}{f}  ({size_kb:.1f} KB)')\n",
    "\n",
    "print(f'\\nDone. All results at: {SAVE_DIR}')\n"
   ]
  }
 ]
}